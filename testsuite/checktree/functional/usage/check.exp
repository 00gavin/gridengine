#!/vol2/TCL_TK/glinux/bin/expect
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2001 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__


#****** functional/usage ***************************************
#
#  NAME
#     function -- test if usage is reported correctly
#
#  FUNCTION
#     This test monitors and checks the job usage reported by SGE 
#    (cpu and mem).
#
#     The following job types are run:
#     - single CPU job
#     - tightly integrated parallel job
#     - loosely integrated parallel job
#        - with job_is_first_task = TRUE
#        - with job_is_first_task = FALSE
#
#     The following usage related settings are tested:
#     - "normal" usage reporting
#     - reserved usage (execd_params acct_reserved_usage and 
#                       sharetree_reserved_usage)
#
#     The following submit commands are used:
#     - qsub
#     - qrsh (with command)
#
#  NOTES
#     - we should also check array jobs
#     - we should also check parallel array jobs
#     - we should have additional submit methods (qsh, qlogin, qrsh without 
#       command)
#
#  BUGS
#     - "normal" usage tests are still missing
#***************************************************************************

# define global variable in this namespace
global check_name 
global check_category 
global check_description 
global check_needs
global check_functions 
global check_errno 
global check_errstr 
global check_highest_level
global check_init_level_procedure
global check_root_access_needs
global env

#set check_root_access_needs "yes"


# define a level initialization procedure:
set check_init_level_procedure "usage_init_level"

# define test's name and run level descriptions
set check_name            "usage"
set check_category        "COMPATIBILITY SYSTEM"
set check_highest_level   1
set check_description(0)  "check reserved usage of jobs submitted with qsub"
set check_description(1)  "check reserved usage of jobs submitted with qrsh"

# define test's dependencies
set check_needs           "init_core_system" 


# define test's procedure order
set check_functions ""
lappend check_functions "usage_setup"
lappend check_functions "usage_single"
lappend check_functions "usage_tight"
lappend check_functions "usage_loose1"
lappend check_functions "usage_loose2"
lappend check_functions "usage_cleanup"

proc usage_init_level {} {
   global CHECK_ACT_LEVEL
   global submit_command reserved_usage

   switch -- $CHECK_ACT_LEVEL {
      "0" { 
         set submit_command qsub
         set reserved_usage 1
         return 0    
      } 
      "1" {
         set submit_command qrsh
         set reserved_usage 1
         return 0
      }
      "2" { 
         set submit_command qsub
         set reserved_usage 0
         return 0    
      } 
      "3" {
         set submit_command qrsh
         set reserved_usage 0
         return 0
      }
   } 

   return -1  ;# no other level 
}

# -------- local test procedures: initialization------------------------------

global submit_command

proc usage_setup  {} {
   global ts_config
   global reserved_usage saved_config

   # modify config and remember old values
   get_config config
   if {[info exists saved_config]} {
      unset saved_config
   }
   if { $ts_config(gridengine_version) == 53 } {
      foreach attrib "load_report_time execd_params schedd_params" {
         set saved_config($attrib) $config($attrib)
      }
      set new_config(schedd_params) "$config(schedd_params) flush_submit_secs=0"

   } else {
      foreach attrib "load_report_time execd_params" {
         set saved_config($attrib) $config($attrib)
      }
      set my_schedd_conf(flush_submit_sec) "1"
      set_schedd_config my_schedd_conf 
   }

   set new_config(load_report_time) "0:0:5"
   
   if {$reserved_usage} {
      set new_config(execd_params) "$config(execd_params) acct_reserved_usage=1 sharetree_reserved_usage=1"
   }
   set_config new_config
   after 15000

   # create parallel environments
   set pe(pe_name)            tight
   set pe(slots)              5
   set pe(user_lists)         none
   set pe(xuser_lists)        none
   set pe(start_proc_args)    none
   set pe(stop_proc_args)     none
   set pe(allocation_rule)    "\$round_robin"
   set pe(control_slaves)     TRUE
   set pe(job_is_first_task)  FALSE

   add_pe pe

   set pe(pe_name)            loose1
   set pe(control_slaves)     FALSE

   add_pe pe

   set pe(pe_name)            loose2
   set pe(job_is_first_task)  TRUE

   add_pe pe

   set queue_list ""
   foreach host $ts_config(execd_hosts) {
      append queue_list "$host.q "
   }
   assign_queues_with_pe_object $queue_list tight
   assign_queues_with_pe_object $queue_list loose1
   assign_queues_with_pe_object $queue_list loose2
   
   # set memory limits
   if {$reserved_usage} {
      set queue_conf(h_vmem) "100M"
      foreach queue $queue_list {
         set_queue $queue queue_conf
      }
   }

   set_error 0 "ok"
}

proc usage_cleanup  {} {
   global ts_config
   global reserved_usage saved_config

   # reset config
   set_config saved_config
   if {$ts_config(gridengine_version) == 53} {
      reset_schedd_config;
   }


   
   after 15000

   # remove pe's
   del_pe tight
   del_pe loose1
   del_pe loose2

   # reset memory limits
   if {$reserved_usage} {
      set queue_conf(h_vmem) "INFINITY"
      foreach host $ts_config(execd_hosts) {
         set_queue $host.q queue_conf
      }
   }

   set_error 0 "ok"
}

# -------- local test procedures: utilities --------------------------
proc usage_monitor_job {id started_var finished_var jobid_var info_var {my_timeout 180} {timeout_error 1}} {
   global ts_config
   global CHECK_OUTPUT

   upvar $started_var  started
   upvar $finished_var finished
   upvar $jobid_var    jobid
   upvar $info_var     info

   set ret "unknown"

   set sp_id [lindex $id 1]
   set timeout $my_timeout
   
   expect_user {
      -i $sp_id timeout {
         if {$timeout_error} {
            add_proc_error usage_monitor -1 "timeout waiting for tasks output"
            set ret "timeout"
         } else {
            set ret "task running"
         }
      }
      -i $sp_id full_buffer {
         add_proc_error usage_monitor -1 "buffer overflow please increment CHECK_EXPECT_MATCH_MAX_BUFFER value"
         set ret "error"
      }
      -i $sp_id eof {
         set ret "eof"
      }
      # workaround for a feature lacking in expect:
      # We have to parse complete lines.
      # expect_user ensures only that expect will parse input up to a newline,
      # but there seems to be no way to tell expect we want to examine each
      # individual line.
      -i $sp_id "?*" {
         #puts $CHECK_OUTPUT "entered default branch, data: $expect_out(0,string)"
         foreach line [split $expect_out(0,string) "\n"] {
            if {[string length [string trim $line]] > 0} {
               #puts $CHECK_OUTPUT "processing line: $line"
               switch -glob $line {
                  "starting with method *" {
                     incr started
                     puts $CHECK_OUTPUT "usage script started"
                     set ret "task started"
                  }
                  "petask ??? with pid ???????? started on host*" {
                     set task [lindex $line 1]
                     lappend info(tasks) $task
                     set info($task,pid) [lindex $line 4]
                     set info($task,host) [lindex $line 8]
                     incr started
                     puts $CHECK_OUTPUT "task $task started, total started: $started"
                     set ret "task started"
                  }
                  "petask ??? with pid ???????? finished*" {
                     set task [lindex $line 1]
                     incr finished
                     puts $CHECK_OUTPUT "task $task finished, total finished: $finished"
                     set ret "task finished"
                  }
                  "master task started with job id ?????? and pid*" {
                     set jobid [lindex $line 6]
                     lappend info(tasks) master
                     set info(master,pid) [lindex $line 9]
                     set info(master,host) $ts_config(master_host)
                     puts $CHECK_OUTPUT "job $jobid started"
                     set ret "master started"
                  }
                  "master task submitted all sub tasks*" {
                     puts $CHECK_OUTPUT "master task submitted all tasks"
                     set ret "master submitted"
                  }
                  "master task exiting*" {
                     puts $CHECK_OUTPUT "job $jobid exited"
                     set ret "master finished"
                  }
                  "NSLOTS ??? NHOSTS ??? NQUEUES*" {
                     set ret "task running"
                  }
                  default {
                     puts $CHECK_OUTPUT "skipping unexpected job output $line"
                  }
               }
            }
         }
      }
   }

   return $ret
}

proc usage_job_finished {job_state} {
   global CHECK_OUTPUT

   switch -exact $job_state {
      "timeout" -
      "eof" -
      "master finished" -
      "error" {
         set job_finished 1
      }
      
      "unknown" -
      "task started" -
      "task running" -
      "task finished" -
      "master started" -
      "master submitted" {
         set job_finished 0
      }

      default {
         set job_finished 1
      }
   }

   return $job_finished
}


# JG: TODO: this is the same as large_cluster_parse_cpu
#           move the function somewhere in tcl_files
proc usage_parse_cpu {s_cpu} {
   set l_cpu [split $s_cpu ":"]
   set cpu 0

   while {[llength $l_cpu] > 0} {
      scan [lindex $l_cpu 0] "%02d" part
      
      switch [llength $l_cpu] {
         1 {
            incr cpu $part
         }
         2 {
            incr cpu [expr $part * 60]
         }
         3 {
            incr cpu [expr $part * 3600]
         }
         default {
            add_proc_error "usage_parse_cpu" -1 "cannot parse cpu time $s_cpu"
         }
      }

      set l_cpu [lreplace $l_cpu 0 0]
   }

   return $cpu
}

# JG: TODO: for online usage take the max of current qstat and former qstat - with tightly integrated jobs, the qstat -j usage can decline
proc usage_check {jobid qstat_j_info slots} {
   global CHECK_OUTPUT

   upvar $qstat_j_info online_info

   # get online usage
   foreach name [array names online_info] {
      if {[string compare [lindex $name 0] "usage"] == 0} {
         set usage_list [split $online_info($name) ","]
         set value_list [split [lindex $usage_list 0] "="]
         set online_cpu [usage_parse_cpu [lindex $value_list 1]]
         set value_list [split [lindex $usage_list 1] "="]
         set online_mem [lindex [lindex $value_list 1] 0]
         puts $CHECK_OUTPUT "online_cpu = $online_cpu, online_mem = $online_mem"
      }
   }

   # get accounting record
   get_qacct $jobid
   set acct_cpu $qacct_info(cpu)
   set acct_mem $qacct_info(mem)
   puts $CHECK_OUTPUT "acct_cpu = $acct_cpu, acct_mem = $acct_mem"

   # calculate expected usage
   # JG: TODO: not yet perfect for parallel jobs: we have to check the 
   #           memory limit for each queue we have jobs running in
   #           and set different memory limits for different queues
   set wallclock $qacct_info(ru_wallclock)
   set expected_cpu [expr $wallclock * $slots]
   set expected_mem [expr $wallclock * 100.0 * $slots / 1024]
   puts $CHECK_OUTPUT "expected_cpu = $expected_cpu, expected_mem = $expected_mem"

   # compare usage
   set result {}
   # online cpu
   if {[expr abs($online_cpu - $expected_cpu)] > [expr $expected_cpu / 10]} {
      lappend result "online cpu usage ($online_cpu) differs more than 10% from expected usage ($expected_cpu)"
   }
   # online mem
   if {[expr abs($online_mem - $expected_mem)] > [expr $expected_mem / 10]} {
      lappend result "online memory usage ($online_mem) differs more than 10% from expected usage ($expected_mem)"
   }
   # accounting cpu
   if {[expr abs($acct_cpu - $expected_cpu)] > [expr $expected_cpu / 50]} {
      lappend result "accounting cpu usage ($acct_cpu) differs more than 2% from expected usage ($expected_cpu)"
   }
   # accounting mem
   if {[expr abs($acct_mem - $expected_mem)] > [expr $expected_mem / 50]} {
      lappend result "accounting memory usage ($acct_mem) differs more than 2% from expected usage ($expected_mem)"
   }

   return $result
}

proc usage_monitor_check {id test_name slots} {
   global CHECK_OUTPUT

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   set my_timeout 180
   set timeout_error 1
   if [info exists qstat_j_info] {
      unset qstat_j_info
   }
   set now [clock seconds]
   set end [expr $now + 100]
   while {$job_finished == 0 && $now < $end} {
      set job_state [usage_monitor_job $id started finished jobid info $my_timeout $timeout_error]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [usage_job_finished $job_state]

      if {$started > 0} {
         set my_timeout 1
         set timeout_error 0
         get_qstat_j_info $jobid
      }

      set now [clock seconds]
   }

   close_spawn_process $id
   wait_for_jobend $jobid usage 60 0 1

   if {!$job_finished} {
      add_proc_error test_name -1 "job terminated abnormally"
   } else {
      set error_list [usage_check $jobid qstat_j_info $slots]

      foreach error $error_list {
         add_proc_error $test_name -1 $error
      }
   }

   set_error 0 "ok"
}

# -------- local test procedures: tests ------------------------------
proc usage_single {} {
   global ts_config
   global CHECK_OUTPUT
   global CHECK_SCRIPT_FILE_DIR
   global submit_command
   puts $CHECK_OUTPUT "usage: single cpu job submitted with $submit_command"

   set id [submit_with_method $submit_command "-N usage -q $ts_config(master_host).q" "$ts_config(testsuite_root_dir)/$CHECK_SCRIPT_FILE_DIR/usage.sh" "sleep 60"]

   usage_monitor_check $id "usage_single" 1
   set_error 0 "ok"
}

proc usage_tight {} {
   global ts_config
   global CHECK_OUTPUT
   global CHECK_SCRIPT_FILE_DIR
   global submit_command
   puts $CHECK_OUTPUT "usage: tightly integrated parallel job submitted with $submit_command"

   set id [submit_with_method $submit_command "-pe tight 4 -N usage -masterq $ts_config(master_host).q" "$ts_config(testsuite_root_dir)/$CHECK_SCRIPT_FILE_DIR/pe_job.sh" "$ts_config(testsuite_root_dir)/$CHECK_SCRIPT_FILE_DIR/pe_task.sh 1 60"]

   usage_monitor_check $id "usage_tight" 5
   set_error 0 "ok"
}

proc usage_loose {pe expected_slots} {
   global ts_config
   global CHECK_OUTPUT
   global CHECK_SCRIPT_FILE_DIR
   global submit_command
   puts $CHECK_OUTPUT "usage: parallel job in pe $pe submitted with $submit_command"

   set id [submit_with_method $submit_command "-N usage -pe $pe 4 -masterq $ts_config(master_host).q" "$ts_config(testsuite_root_dir)/$CHECK_SCRIPT_FILE_DIR/usage.sh" "sleep 60"]

   usage_monitor_check $id "usage_loose" $expected_slots
   set_error 0 "ok"
}

proc usage_loose1 {} {
   usage_loose loose1 5

   set_error 0 "ok"
}

proc usage_loose2 {} {
   usage_loose loose2 4

   set_error 0 "ok"
}
