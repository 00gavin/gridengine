#!/vol2/TCL_TK/glinux/bin/expect
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2001 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__

# define global variable in this namespace
global check_name 
global check_category 
global check_description 
global check_needs
global check_functions 
global check_errno 
global check_errstr 
global check_highest_level
global check_init_level_procedure
global check_root_access_needs
global env

#set check_root_access_needs "yes"


# define a level initialization procedure:
set check_init_level_procedure "tight_integration_init_level"

# define test's name and run level descriptions
set check_name            "tight_integration"
set check_category        "COMPATIBILITY SYSTEM"
set check_highest_level   0
set check_description(0)  "check tightly integrated parallel jobs submitted with qsub"
set check_description(1)  "check tightly integrated parallel jobs submitted with qrsh"

# define test's dependencies
set check_needs           "init_core_system" 


# define test's procedure order
set check_functions ""
lappend check_functions "tight_integration_setup"
lappend check_functions "tight_integration_function"
lappend check_functions "tight_integration_iz_578";# env vars NSLOTS and NHOSTS
lappend check_functions "tight_integration_master_killed"
lappend check_functions "tight_integration_slave_killed"
lappend check_functions "tight_integration_iz_575";# wallclock limit for tasks
lappend check_functions "tight_integration_massive"
lappend check_functions "tight_integration_cleanup"

# constants to be used by the tight integration test
global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS 
global TIGHT_INTEGRATION_FUNCTIONAL_DURATION
global TIGHT_INTEGRATION_MASSIVE_SLOTS
global TIGHT_INTEGRATION_MASSIVE_DURATION

set TIGHT_INTEGRATION_FUNCTIONAL_SLOTS 5
set TIGHT_INTEGRATION_FUNCTIONAL_DURATION 10
set TIGHT_INTEGRATION_MASSIVE_SLOTS 200
set TIGHT_INTEGRATION_MASSIVE_DURATION 120

proc tight_integration_init_level {} {
   global CHECK_ACT_LEVEL
   global submit_command

   switch -- $CHECK_ACT_LEVEL {
      "0" { 
         set submit_command qsub
         return 0    
      } 
      "1" {
         set submit_command qrsh
         return 0
      }
   } 

   return -1  ;# no other level 
}

# -------- local test procedures: initialization------------------------------

global submit_command

proc tight_integration_setup  {} {
   global CHECK_PRODUCT_ROOT CHECK_CORE_EXECD TIGHT_INTEGRATION_MASSIVE_SLOTS

   # create parallel environment
   set pe(pe_name)            tight
   set pe(slots)              1000
   set pe(user_lists)         none
   set pe(xuser_lists)        none
   set pe(start_proc_args)    none
   set pe(stop_proc_args)     none
   set pe(allocation_rule)    "\$round_robin"
   set pe(control_slaves)     TRUE
   set pe(job_is_first_task)  FALSE

   add_pe pe

   set queue_list ""
   foreach host $CHECK_CORE_EXECD {
      append queue_list "$host.q "
   }
   assign_queues_with_pe_object $queue_list tight
   set_error 0 "ok"
}

proc tight_integration_cleanup  {} {
   global CHECK_PRODUCT_TYPE

   # workaround: in sgeee a job still exists in qmaster after it exited for some time
   #             therefore the pe cannot be deleted
   del_pe tight

   set_error 0 "ok"
}

# -------- local test procedures: utilities --------------------------
proc tight_integration_submit {cwd options script args} {
   global CHECK_OUTPUT CHECK_HOST CHECK_USER CHECK_PRODUCT_ROOT
   global submit_command file_procedure_logfile_wait_sp_id
  
   # preprocessing args - it is treated as list for some reason - options not.
   set job_args [lindex $args 0]
   foreach arg [lrange $args 1 end] {
      append job_args " $arg"
   }
   
  
   switch -exact $submit_command {
      qsub {
         puts $CHECK_OUTPUT "submitting job using qsub, reading from job output file"
         # create job output file
         set job_output_file "$cwd/check.out"
         catch {exec touch $job_output_file} output
         # initialize tail to logfile
         init_logfile_wait $CHECK_HOST $job_output_file
         # submit job
         submit_job "-o $job_output_file -j y $options $script $job_args" 1 30 "" "" $cwd
         # return global file handle
         set sid $file_procedure_logfile_wait_sp_id
      }

      qrsh {
         puts $CHECK_OUTPUT "submitting job using qrsh, reading from stdout/stderr"
         set command "/bin/sh -c \\\"cd $cwd;$CHECK_PRODUCT_ROOT/bin/[resolve_arch $CHECK_HOST]/qrsh -noshell $options ./$script $job_args\\\""
         set sid [uplevel 1 open_spawn_process "\"$command\""]
      }

      default {
         set sid ""
         add_proc_error tight_integration_submit -1 "unknown submit method $submit_command"
      }
   }

   puts $CHECK_OUTPUT "submitted job, sid = $sid"
   return $sid
}

proc tight_integration_monitor {id started_var finished_var jobid_var info_var {iz_578 0}} {
   global CHECK_OUTPUT CHECK_HOST

   upvar $started_var  started
   upvar $finished_var finished
   upvar $jobid_var    jobid
   upvar $info_var     info

   set ret "unknown"

   set sp_id [lindex $id 1]
   set timeout 180

   
   expect_user {
      -i $sp_id timeout {
         add_proc_error tight_integration_monitor -1 "timeout waiting for tasks output"
         set ret "timeout"
      }
      -i $sp_id full_buffer {
         add_proc_error tight_integration_monitor -1 "buffer overflow please increment CHECK_EXPECT_MATCH_MAX_BUFFER value"
         set ret "error"
      }
      -i $sp_id eof {
         set ret "eof"
      }
      # workaround for a feature lacking in expect:
      # We have to parse complete lines.
      # expect_user ensures only that expect will parse input up to a newline,
      # but there seems to be no way to tell expect we want to examine each
      # individual line.
      -i $sp_id "?*" {
         #puts $CHECK_OUTPUT "entered default branch, data: $expect_out(0,string)"
         foreach line [split $expect_out(0,string) "\n"] {
            if {[string length [string trim $line]] > 0} {
               #puts $CHECK_OUTPUT "processing line: $line"
               switch -glob $line {
                  "petask ??? with pid ???????? started on host*" {
                     set task [lindex $line 1]
                     lappend info(tasks) $task
                     set info($task,pid) [lindex $line 4]
                     set info($task,host) [lindex $line 8]
                     incr started
                     puts $CHECK_OUTPUT "task $task started, total started: $started"
                     set ret "task started"
                  }
                  "petask ??? with pid ???????? finished*" {
                     set task [lindex $line 1]
                     incr finished
                     puts $CHECK_OUTPUT "task $task finished, total finished: $finished"
                     set ret "task finished"
                  }
                  "master task started with job id ?????? and pid*" {
                     set jobid [lindex $line 6]
                     lappend info(tasks) master
                     set info(master,pid) [lindex $line 9]
                     set info(master,host) $CHECK_HOST
                     puts $CHECK_OUTPUT "job $jobid started"
                     set ret "master started"
                  }
                  "master task submitted all sub tasks*" {
                     puts $CHECK_OUTPUT "master task submitted all tasks"
                     set ret "master submitted"
                  }
                  "master task exiting*" {
                     puts $CHECK_OUTPUT "job $jobid exited"
                     set ret "master finished"
                  }
                  "NSLOTS ??? NHOSTS ??? NQUEUES*" {
                     if {$iz_578} {
                        set nslots  [lindex $line 1]
                        set nhosts  [lindex $line 3]
                        set nqueues [lindex $line 5]
                        puts $CHECK_OUTPUT "nslots = $nslots, nhosts = $nhosts, nqueues = $nqueues"
                        if {$nslots == 0 || $nhosts == 0 || $nqueues == 0} {
                           add_proc_error tight_integration_monitor -1 "invalid environment setting for NSLOTS, NHOSTS, NQUEUES for pe task (Issue 578 present): $line"
                           set ret "error"
                           break
                        }
                     }
                     set ret "task running"
                  }
                  default {
                     add_proc_error tight_integration_monitor -1 "unexpected job output $line"
                     set ret "error"
                  }
               }
            }
         }
      }
   }

   return $ret
}

proc tight_integration_job_finished {job_state} {
   global CHECK_OUTPUT

   switch -exact $job_state {
      "unknown" -
      "timeout" -
      "eof" -
      "master finished" -
      "error" {
         set job_finished 1
      }
      
      "task started" -
      "task running" -
      "task finished" -
      "master started" -
      "master submitted" {
         set job_finished 0
      }

      default {
         set job_finished 1
      }
   }

   return $job_finished
}

# -------- local test procedures: tests ------------------------------
proc tight_integration_function {} {
   global CHECK_OUTPUT CHECK_ACTUAL_TEST_PATH CHECK_HOST
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   puts $CHECK_OUTPUT "tight_integration: functional test"

   set id [tight_integration_submit $CHECK_ACTUAL_TEST_PATH "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $CHECK_HOST.q -cwd -N tightf" pe_job.sh "./sleep.sh 1 $TIGHT_INTEGRATION_FUNCTIONAL_DURATION"]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   if {$started != $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      add_proc_error tight_integration_functional -1 "only $started tasks out of $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS were started successfully"
   }

   if {$finished != $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      add_proc_error tight_integration_functional -1 "only $finished tasks out of $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS ran through successfully"
   }

   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1


   set_error 0 "ok"
}

# check if tasks are killed when they hit a wallclock limit
proc tight_integration_iz_575 {} {
   global CHECK_OUTPUT CHECK_ACTUAL_TEST_PATH CHECK_HOST CHECK_USER 
   global CHECK_CORE_EXECD
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   puts $CHECK_OUTPUT "tight_integration: iz 575 task wallclock limit"

   if {[resolve_version] < 3} {
      add_proc_error "tight_integration_iz_575" -3 "iz 575 does not run in 5.3 systems"
      set_error 0 "ok"
      return
   }

   # set wallclock limit on one slave queue
   if {[llength $CHECK_CORE_EXECD] < 2} {
      add_proc_error "tight_integration_iz_575" -3 "iz 575 test needs at least 2 execution hosts"
      set_error 0 "ok"
      return
   }

   # set wallclock limit on all slave queues
   set queue_list {}
   foreach host $CHECK_CORE_EXECD {
      if {[string compare $host $CHECK_HOST] != 0} {
         lappend queue_list "$host.q"
      }
   }

   set queue_conf(h_rt) "0:0:30"
   foreach queue $queue_list {
      set_queue $queue queue_conf
   }

   # submit job
   set id [tight_integration_submit $CHECK_ACTUAL_TEST_PATH "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $CHECK_HOST.q -cwd -N tightf" pe_job.sh "./sleep.sh 1 3600"]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0

   # wait until all tasks are started
   while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   # if startup was ok
   if {$job_finished == 0} {
      # job has to go into deleted state after rt limit - allow for 5s delay
      if {[wait_for_job_state $jobid "dr" 35] == -1} {
         if {[is_job_running $jobid tightf] == -1} {
            puts $CHECK_OUTPUT "didn't see dr state, but job vanished - OK!"
         } else {
            add_proc_error "tight_integration_iz_575" -1 "slave tasks should have been killed due to runtime limit and set the job into dr state - issue 575 present"
            delete_job $jobid
         }
      }
   }

   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1

   # reset queue runtime limit
   set queue_conf(h_rt) "INFINITY"
   foreach queue $queue_list {
      set_queue $queue queue_conf
   }

   set_error 0 "ok"
}

# check NSLOTS, NHOSTS, NQUEUES for tasks
proc tight_integration_iz_578 {} {
   global CHECK_OUTPUT CHECK_ACTUAL_TEST_PATH CHECK_HOST
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   puts $CHECK_OUTPUT "tight_integration: Issue 578 NSLOTS NHOSTS NQUEUES"

   set id [tight_integration_submit $CHECK_ACTUAL_TEST_PATH "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $CHECK_HOST.q -cwd -N tightf" pe_job.sh "./sleep.sh 1 $TIGHT_INTEGRATION_FUNCTIONAL_DURATION"]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id started finished jobid info 1]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1


   set_error 0 "ok"
}

# master task killed -> job has to be deleted
proc tight_integration_master_killed {} {
   global CHECK_OUTPUT CHECK_ACTUAL_TEST_PATH CHECK_HOST CHECK_USER
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   puts $CHECK_OUTPUT "tight_integration: master task killed - issue 579"

   set id [tight_integration_submit $CHECK_ACTUAL_TEST_PATH "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $CHECK_HOST.q -cwd -N tightf" pe_job.sh "./sleep.sh 1 3600"]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0

   # wait until all tasks are started
   while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   # if startup was ok
   if {$job_finished == 0} {
      # wait for job to be running
      wait_for_job_state $jobid "r" 60

      # kill pid of master task and wait some seconds
      puts $CHECK_OUTPUT "killing master task: pid $info(master,pid) on host $info(master,host)"
      start_remote_prog $info(master,host) $CHECK_USER kill "-9 $info(master,pid)"

      if {[wait_for_job_state $jobid "dr" 60] == -1} {
         if {[is_job_running $jobid tightf] == -1} {
            puts $CHECK_OUTPUT "didn't see dr state, but job vanished - OK!"
         } else {
            add_proc_error "tight_integration_master_killed" -1 "failed master task does not cause the job to be deleted (issue 579 present)"
            delete_job $jobid
         }
      }
   }

   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1

   set_error 0 "ok"
}

# slave task killed -> job has to be deleted
proc tight_integration_slave_killed {} {
   global CHECK_OUTPUT CHECK_ACTUAL_TEST_PATH CHECK_HOST CHECK_USER
   global TIGHT_INTEGRATION_FUNCTIONAL_SLOTS TIGHT_INTEGRATION_FUNCTIONAL_DURATION
   puts $CHECK_OUTPUT "tight_integration: slave task killed"

   set id [tight_integration_submit $CHECK_ACTUAL_TEST_PATH "-pe tight $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS -masterq $CHECK_HOST.q -cwd -N tightf" pe_job.sh "./sleep.sh 1 3600"]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0

   # wait until all tasks are started
   while {$job_finished == 0 && $started < $TIGHT_INTEGRATION_FUNCTIONAL_SLOTS} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      puts $CHECK_OUTPUT "job state: $job_state"
      set job_finished [tight_integration_job_finished $job_state]
   }

   # if startup was ok
   if {$job_finished == 0} {
      # wait for job to be running
      wait_for_job_state $jobid "r" 60

      # kill pid of master task and wait some seconds
      # we take task 1: if we have more than one host, it will be on a slave host
      puts $CHECK_OUTPUT "killing slave task: process group $info(1,pid) on host $info(1,host)"
      start_remote_prog $info(1,host) $CHECK_USER kill "-9 -$info(1,pid)"

      if {[wait_for_job_state $jobid "dr" 60] == -1} {
         if {[is_job_running $jobid tightf] == -1} {
            puts $CHECK_OUTPUT "didn't see dr state, but job vanished - OK!"
         } else {
            add_proc_error "tight_integration_slave_killed" -1 "failed slave task does not cause the job to be deleted"
            delete_job $jobid
         }
      }
   }

   close_spawn_process $id

   wait_for_jobend $jobid tightf 60 0 1

   set_error 0 "ok"
}

proc tight_integration_massive {} {
   global CHECK_OUTPUT CHECK_ACTUAL_TEST_PATH CHECK_CORE_EXECD CHECK_HOST
   global TIGHT_INTEGRATION_MASSIVE_SLOTS TIGHT_INTEGRATION_MASSIVE_DURATION
   puts $CHECK_OUTPUT "tight_integration: massive parallel test"

   # check if test can run at all in this cluster
   set total_slots 0
   foreach host $CHECK_CORE_EXECD {
      get_queue "$host.q" queue_conf
      incr total_slots $queue_conf(slots)
   }
   if {$total_slots < [expr $TIGHT_INTEGRATION_MASSIVE_SLOTS + 1]} {
      add_proc_error tight_integration_massive -3 "test cannot run massive parallel job with $TIGHT_INTEGRATION_MASSIVE_SLOTS tasks + the master task - cluster only has $total_slots slots"
      set_error 0 "ok"
      return
   }

   set id [tight_integration_submit $CHECK_ACTUAL_TEST_PATH "-pe tight $TIGHT_INTEGRATION_MASSIVE_SLOTS -masterq $CHECK_HOST.q -cwd -N tightm" pe_job.sh "./sleep.sh 1 $TIGHT_INTEGRATION_MASSIVE_DURATION"]

   set started 0
   set finished 0
   set jobid 0
   set job_finished 0
   
   while {$job_finished == 0} {
      set job_state [tight_integration_monitor $id started finished jobid info]
      set job_finished [tight_integration_job_finished $job_state]
   }

   if {$started != $TIGHT_INTEGRATION_MASSIVE_SLOTS} {
      add_proc_error tight_integration_massive -1 "only $started tasks out of $TIGHT_INTEGRATION_MASSIVE_SLOTS were started successfully"
   }

   if {$finished != $TIGHT_INTEGRATION_MASSIVE_SLOTS} {
      add_proc_error tight_integration_massive -1 "only $finished tasks out of $TIGHT_INTEGRATION_MASSIVE_SLOTS ran through successfully"
   }

   close_spawn_process $id

   wait_for_jobend $jobid tightm 300 0 1

   set_error 0 "ok"
}
