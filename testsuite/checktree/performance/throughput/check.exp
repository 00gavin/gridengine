#!/vol2/TCL_TK/glinux/bin/expect --
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2001 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__

# Define the global veriables to give them back
global check_name check_description check_needs check_functions check_errno check_errstr check_highest_level
global check_init_level_procedure check_category

set check_init_level_procedure "init_level"
set check_category            "PERFORMANCE VERIFIED"
set check_name                "throughput"
set check_description(0)      "Functional test, submit 100 jobs with enabled queues"
set check_description(1)      "Functional test, submit 100 jobs with disabled queues"
set check_description(2)      "Functional test, submit 50 of 100 jobs with disabled queues"
set check_description(3)      "Functional test with sharetree, 100 jobs"
set check_description(100)    "submit 3000 jobs with enabled queues"
set check_description(101)    "submit 3000 jobs with disabled queues"
set check_description(102)    "submit 1500 of 3000 jobs with disabled queues"
set check_description(103)    "with sharetree, 3000 jobs"
set check_description(200)    "submit 30000 jobs with enabled queues"
set check_description(201)    "submit 30000 jobs with disabled queues"
set check_description(202)    "submit 15000 of 30000 jobs with disabled queues"
set check_description(203)    "with sharetree, 30000 jobs"
set check_description(300)    "submit 300000 jobs with enabled queues"
set check_description(301)    "submit 300000 jobs with disabled queues"
set check_description(302)    "submit 150000 of 300000 jobs with disabled queues"
set check_description(303)    "with sharetree, 300000 jobs"

set check_needs               "init_core_system"      ;# dependencies of this check (name of other check)

set check_functions           ""
lappend check_functions       "setup_queues"          ;# functions to call (in order)
lappend check_functions       "run_throughput_test"
lappend check_functions       "cleanup_queues"
#set check_functions          "compare_dump_data_file"

set check_highest_level       303

global nr_queues  nr_slots
global queue_list
global host_list
global enable_queues_job_count 
global end_job_count
global global_job_run_time
global stored_configuration FLUSH_SUBMIT_SEC FLUSH_FINISH_SEC run_throughput_test_SCHEDULE_INTERVAL
global throughput_subdir
global throughput_sharetree

set queue_list ""
set host_list ""
set throughput_subdir ""

proc init_level {} {
   global ts_config
   global CHECK_ACT_LEVEL CHECK_PRODUCT_TYPE
   global end_job_count                      ;# number of jobs
   global enable_queues_job_count             ;# after with job, enable queues
   global nr_queues                            ;# nr of queues on each host
   global nr_slots                            ;# nr of slots on each queue
   global global_job_run_time                  ;# job sleep parameter
   global FLUSH_SUBMIT_SEC                    ;# -1 or 0,1,2,3 ...
   global FLUSH_FINISH_SEC                    ;# -1 or 0,1,2,3 ...
   global run_throughput_test_SCHEDULE_INTERVAL             ;# 00:00:30 ...
   global throughput_subdir             ;# subdirectory in protocols/throughput/
   global throughput_sharetree
   global host_list

    # paramters for all tests
   set run_throughput_test_SCHEDULE_INTERVAL        00:00:15
   set global_job_run_time      5            ;# job sleep parameter
   set nr_queues                10            ;# nr of queues on each host
   set nr_slots                 5           ;# nr of slots on each queue
   set enable_queues_job_count  0         ;# after witch job, enable queues
   set FLUSH_SUBMIT_SEC         1             ;# -1 or 0,1,2,3 ...
   set FLUSH_FINISH_SEC         1             ;# -1 or 0,1,2,3 ...

   # host_list for all levels
   set host_list {}
   foreach host $ts_config(execd_hosts) {
      if { [string compare $host $ts_config(master_host)] != 0 } { 
         lappend host_list $host
      }
   }

   # setup levels
   set major_level [expr $CHECK_ACT_LEVEL / 100]
   set minor_level [expr $CHECK_ACT_LEVEL % 100]
  
   switch -- $major_level {
      "0" {
         set job_count 90
      }
      "1" {
         set job_count 3000
      }
      "2" {
         set job_count 30000
      }
      "3" {
         set job_count 300000
      }
      default {
         return -1
      }
   }

   switch -- $minor_level {
      "0" {
         # enable queues after all jobs have been submitted
         set end_job_count            $job_count
         set enable_queues_job_count  $job_count
         set throughput_sharetree     0
         set throughput_subdir        "disabled"
         return 0
      }
      "1" {
         # have queues enabled during whole submit process
         set end_job_count            $job_count
         set enable_queues_job_count  0
         set throughput_sharetree     0
         set throughput_subdir        "enabled"
         return 0
      }
      "2" {
         # enable queues after half of the jobs have been submitted
         set end_job_count            $job_count
         set enable_queues_job_count  [expr $job_count / 2]
         set throughput_sharetree     0
         set throughput_subdir        "mixed"
         return 0
      }
      "3" {
         # test with sharetree, enable queues after all jobs have been submitted
         if { $CHECK_PRODUCT_TYPE == "sge" } {
            return -1
         } 
         set end_job_count            $job_count
         set enable_queues_job_count  $job_count
         set throughput_sharetree     1
         set throughput_subdir        "sharetree"
         return 0
      }
      default {
         return -1
      }
   }

   return -1
}

proc throughput_set_share_tree {} {
   global ts_config
   global CHECK_HOST CHECK_OUTPUT

   set s_tree ""  
   lappend s_tree "id=0"
   lappend s_tree "name=Root"
   lappend s_tree "type=0"
   lappend s_tree "shares=1"
   lappend s_tree "childnodes=1,4"
   lappend s_tree "id=1"
   lappend s_tree "name=node1"
   lappend s_tree "type=0"
   lappend s_tree "shares=8000"
   lappend s_tree "childnodes=2,3"
   lappend s_tree "id=2"
   lappend s_tree "name=project1"
   lappend s_tree "type=0"
   lappend s_tree "shares=4000"
   lappend s_tree "childnodes=NONE"
   lappend s_tree "id=3"
   lappend s_tree "name=project2"
   lappend s_tree "type=0"
   lappend s_tree "shares=6000"
   lappend s_tree "childnodes=NONE"
   lappend s_tree "id=4"
   lappend s_tree "name=node2"
   lappend s_tree "type=0"
   lappend s_tree "shares=2000"
   lappend s_tree "childnodes=5"
   lappend s_tree "id=5"
   lappend s_tree "name=project3"
   lappend s_tree "type=0"
   lappend s_tree "shares=10000"
   lappend s_tree "childnodes=NONE"
   return $s_tree
}

proc throughput_setup_sharetree {} {
   global ts_config
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH
   global CHECK_HOST

   puts $CHECK_OUTPUT "setup sharetree ..."

   puts $CHECK_OUTPUT "   adding projects ..."
   set prj_setup(name) "project1"
   add_prj prj_setup

   set prj_setup(name) "project2"
   add_prj prj_setup

   set prj_setup(name) "project3"
   add_prj prj_setup

   # vi commands
   set vi_commands "i" 
   set s_tree [throughput_set_share_tree]
   foreach elem $s_tree {
      lappend vi_commands "${elem}\n"
   } 
   lappend vi_commands [format "%c" 27]
   lappend  vi_commands "dddddddddddd"
  
   # delete a possibly existing sharetree
   set catch_return [ catch {  
      eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf -dstree" 
   } result ] 
 
   set CHANGED_SHARETREE [translate $CHECK_HOST 1 0 0 [sge_macro MSG_TREE_CHANGEDSHARETREE]]
   set CAN_T_READ [translate $CHECK_HOST 1 0 0 [sge_macro MSG_QCONF_CANTREADSHARETREEX_S] "*"]

   # create new sharetree
   set result [ handle_vi_edit "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-astree" $vi_commands $CHANGED_SHARETREE $CAN_T_READ ]  
   if { $result != 0 } {
      add_proc_error "throughput_setup_sharetree" -1 "could not add sharetree (error: $result)"
   }

   # setup policy weighting for sharetree
   get_schedd_config my_config 

   if { $ts_config(gridengine_version) == 53 } {
  
   } else {
      set my_config(weight_ticket) "1.0"
      set my_config(weight_waiting_time) "0.0"
   }

   set my_config(weight_tickets_share) "10000"
   set my_config(usage_weight_list)    "cpu=1,mem=0,io=0"
   set my_config(job_load_adjustments) "none"
   set_schedd_config my_config
}
proc throughput_cleanup_sharetree {} {
   global ts_config
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH

   puts $CHECK_OUTPUT "cleanup sharetree ..."

   # reset scheduler config
   reset_schedd_config

   # delete sharetree
   set catch_return [ catch {  
      eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf -dstree" 
   } result ]

   puts "qconf -dstree result: $result"
   puts "qconf -dstree exit value: $catch_return "

   # remove projects
   puts $CHECK_OUTPUT "   removing projects ..."
   del_prj "project1"
   del_prj "project2"
   del_prj "project3"
}

proc setup_queues {} {
   global ts_config
   global CHECK_OUTPUT
   global CHECK_HOST CHECK_SOURCE_DIR
   global nr_queues queue_list host_list  nr_slots
   global stored_configuration FLUSH_SUBMIT_SEC FLUSH_FINISH_SEC run_throughput_test_SCHEDULE_INTERVAL
   global throughput_sharetree

   if { [llength $ts_config(execd_hosts)] <= 1 } {
      set_error -3 "need more than one host for this test"
      return -3
   }

   # setup global configuration
   if { [info exists stored_configuration] } {
      unset stored_configuration
   }
   get_config stored_configuration
   set myconfig(loglevel)         "log_warning"

   # setup scheduler configuration
   set my_schedd_params "PROFILE=1"

   if { $ts_config(gridengine_version) == 53 } {
      if { [string compare "none" $stored_configuration(schedd_params)] != 0 } {
         append my_schedd_params ",$stored_configuration(schedd_params)"
      }
      if { $FLUSH_SUBMIT_SEC == -1 && $FLUSH_FINISH_SEC == -1 } {
         set myconfig(schedd_params)    "$my_schedd_params"
      } else {
         set myconfig(schedd_params)    "$my_schedd_params,FLUSH_SUBMIT_SEC=${FLUSH_SUBMIT_SEC},FLUSH_FINISH_SEC=${FLUSH_FINISH_SEC}"
      }
   } else {
      get_schedd_config stored_schedd_config
      if { [string compare "none" $stored_schedd_config(params)] != 0 } {
         append my_schedd_params ",$stored_schedd_config(params)"
      }
      set my_schedd_config(params)      "$my_schedd_params"
      if { $FLUSH_SUBMIT_SEC > 0} {
         set my_schedd_config(flush_submit_sec) "$FLUSH_SUBMIT_SEC"
      }
      if { $FLUSH_FINISH_SEC > 0} {
         set my_schedd_config(flush_finish_sec) "$FLUSH_FINISH_SEC"
      }
      set my_schedd_config(load_adjustment_decay_time) "0:0:0"
      set my_schedd_config(job_load_adjustments) "none"
   } 
  
   set my_execd_params "SHARETREE_RESERVED_USAGE=true"
   if { [string compare "none" $stored_configuration(execd_params)] != 0 } {
      append my_execd_params ",$stored_configuration(execd_params)"
   }
   set myconfig(execd_params) "$my_execd_params"

   set_config myconfig
 
   # disable all default queues and create host_list:
   set queue_list {}
   foreach host $ts_config(execd_hosts) {
      lappend queue_list [get_queue_instance "all.q" $host]
   }
   disable_queue $queue_list

   set max_u_jobs_parameter [expr ( [llength $host_list] * $nr_queues  * $nr_slots )]
   set my_schedd_config(schedule_interval)    "$run_throughput_test_SCHEDULE_INTERVAL"
   set my_schedd_config(job_load_adjustments) "none"
   set my_schedd_config(schedd_job_info)      "false"
   set my_schedd_config(maxujobs)             $max_u_jobs_parameter 
   set_schedd_config my_schedd_config

   # now setup submit queues for hosts in host_list:
   # set queue_list:
   set queue_list {}

   # this is the queue configuration 
   set change_array(slots) $nr_slots
   set change_array(load_thresholds) "np_load_avg=11.75"

   # create a certain number of queues
   for {set i 0} {$i < $nr_queues} {incr i} {
      set qname tp_${i}
      add_queue $qname $host_list change_array 1

      # build queue_list containing a list of all queue instances
      foreach host $host_list {
         lappend queue_list [get_queue_instance $qname $host]
      }
   }

   # Create an additional interactive only queue.
   # This verifies IZ 1087 (and is a more realistic scenario)
   unset change_array
   set change_array(qtype) INTERACTIVE
   add_queue interactive "@allhosts" change_array 1
   
   puts $CHECK_OUTPUT "using [llength $host_list] hosts to submit jobs"

   if { $throughput_sharetree == 1 } {
      throughput_setup_sharetree
   }

   set_error 0 "ok"
}

proc cleanup_queues {} {
   global ts_config
   global CHECK_OUTPUT
   global host_list queue_list CHECK_ARCH  CHECK_PRODUCT_ROOT
   global stored_configuration throughput_sharetree nr_queues

   if { [llength $ts_config(execd_hosts)] <= 1 } {
      set_error -3 "need more than one host for this test"
      return -3
   }

   # delete all jobs
   set catch_result [delete_all_jobs]

   # after this we can cleanup the system (no jobs registered at qmaster)
   wait_for_end_of_all_jobs 120

   # remove sharetree
   if { $throughput_sharetree == 1 } {
      throughput_cleanup_sharetree
   }

   # reset configurations
   reset_schedd_config
   set_config stored_configuration

   puts $CHECK_OUTPUT "deleting queues"
   for {set i 0} {$i < $nr_queues} {incr i} {
      set qname tp_${i}
      del_queue $qname $host_list 0 1
   }

   puts $CHECK_OUTPUT "enabling default queues"
   set queue_list {}
   foreach host $ts_config(execd_hosts) {
      lappend queue_list [get_queue_instance "all.q" $host]
   }
   enable_queue $queue_list

   del_queue interactive "@allhosts" 0 1
   
   set_error 0 "ok"
}

proc get_event_client_time { string  } {
   global ts_config
   set ecl_time_start [string first "(" $string]
   incr ecl_time_start 1
   set ecl_time_end [string first ")" $string]
   incr ecl_time_end -1
   set data [string range $string $ecl_time_start $ecl_time_end]
   set data [split $data ":"]
   foreach elem $data {
      set ecl_time_start [string first "ECL_TIME=" $elem]
      if { $ecl_time_start >= 0 } {
         incr ecl_time_start 9
         return [ string range $elem $ecl_time_start end]
      }
   }
   return -1
}

proc run_throughput_test {} {
   global ts_config
   global CHECK_OUTPUT CHECK_USER CHECK_PRODUCT_ROOT CHECK_HOST CHECK_ARCH
   global queue_list CHECK_TESTSUITE_ROOT CHECK_SCRIPT_FILE_DIR
   global enable_queues_job_count CHECK_SOURCE_DIR 
   global end_job_count host_list CHECK_FIRST_FOREIGN_SYSTEM_USER
   global throughput_sharetree
   global global_job_run_time

   if { [llength $ts_config(execd_hosts)] <= 1 } {
      set_error -3 "need more than one host for this test"
      return -3
   }

   # prepare results array
   clean_current_system_status results_list result job_data schedd_data

   # evaluate path to qevent binary
   set up_arch [resolve_build_arch $CHECK_HOST]
   set event_client_bin $CHECK_SOURCE_DIR/$up_arch/qevent
   if { [file isfile $event_client_bin] != 1 } {
      set_error -3 "could not open event client binary: $event_client_bin"
      return -3
   }
   puts $CHECK_OUTPUT "using event client: $event_client_bin"

   # start event client (if compiled) 
   set event_client_sid [ open_remote_spawn_process $CHECK_HOST "ts_def_con2" $event_client_bin ""]
   set event_client_id [lindex $event_client_sid 1]

   set timeout 30
   set is_old_version 0

   while { 1 } {
      expect {
         -i $event_client_id full_buffer {
            add_proc_error "run_throughput_test" -1 "expect full_buffer error (3)"
            return -1
         }
         -i $event_client_id timeout {
            puts $CHECK_OUTPUT "timeout starting event client"
            break;
         }
         -i $event_client_id eof {
            puts $CHECK_OUTPUT "eof from event client"
            break;
         }
         -i $event_client_id "ECL_STATE" {
            puts $CHECK_OUTPUT "old qevent version"
            set is_old_version 1
            break;
         }
         -i $event_client_id -- "ts|*testsuite" {
            puts $CHECK_OUTPUT "new qevent version"
            set is_old_version 0
            break;
         }
      }
   }

   if { $is_old_version == 0 } {
      close_spawn_process $event_client_sid
      puts $CHECK_OUTPUT "starting event client with -ts option ..."
      # start event client with -ts option
      set event_client_sid [ open_remote_spawn_process $CHECK_HOST "ts_def_con2" $event_client_bin "-ts"]
      set event_client_id [lindex $event_client_sid 1]
   }

   # open scheduler messages file
   puts $CHECK_OUTPUT "opening scheduler messages file (tail)"
   set schedd_messages_file [check_schedd_messages 2]
   set schedd_messages_sid [ open_remote_spawn_process $CHECK_HOST "ts_def_con" "tail" "-f $schedd_messages_file"]
   set schedd_messages_id [lindex $schedd_messages_sid 1]

   # disable queues if enable_queues_job_count is set
   if { $enable_queues_job_count > 0 } {
      set are_enabled 0
      puts $CHECK_OUTPUT "disabling all queues"
      disable_queue $queue_list
   } else {
      set are_enabled 1
   }
   
   # prepare job arguments 
   set my_job "$ts_config(product_root)/examples/jobs/sleeper.sh"

   # open shell on each execd host, used for submitting jobs
   set spawn_list ""
   set remote_spawn_list ""

   # start submitter (expect script)
   foreach host $host_list {
      set expect_bin [get_binary_path $host "expect"]
      puts $CHECK_OUTPUT "starting submitter process on host $host"
      set id [ open_remote_spawn_process $host $CHECK_USER "$expect_bin" "-f $ts_config(testsuite_root_dir)/scripts/submitter.tcl $ts_config(product_root) $host" ]
      lappend spawn_list [ lindex $id 1 ]
      lappend remote_spawn_list $id
   }
   
   set timeout 60
   set error 0
   set num_submitters 0
   set next_submitter_list {}

   set my_timeout [ expr ( [timestamp] + 300 ) ]
   set submit_options "-o /dev/null -j y"
   set submit_script "$ts_config(product_root)/examples/jobs/sleeper.sh $global_job_run_time"

   # wait for startup message from each submitter, used for submitting jobs
   # then set options
   # then set script file
   # if everything succeeded, accept this submitter
   log_user 0
   while { $num_submitters < [llength $host_list] } {
      expect_user {
         -i $spawn_list full_buffer {
            set error 1
            add_proc_error "run_throughput_test" -1 "expect full_buffer error (1)"
         }
         -i $spawn_list timeout {
            set error 1
            add_proc_error "run_throughput_test" -1 "timeout while waiting for remote shell"
         }
         -i $spawn_list eof {
            set spawn_id $expect_out(spawn_id)
            set host_nr [lsearch $spawn_list $spawn_id]
            set host_name [lindex $host_list $host_nr]
            set error 1
            add_proc_error "run_throughput_test" -1 "got eof from host $host_name\n$expect_out(0,string)"
         }
         -i $spawn_list -- "*\n" {
            set spawn_id $expect_out(spawn_id)
            set host_nr [lsearch $spawn_list $spawn_id]
            set host_name [lindex $host_list $host_nr]
            set output $expect_out(0,string) 
            set output [ split $output "\n" ]
            foreach line $output {
               puts $CHECK_OUTPUT $line
               switch -glob -- $line {
                  "SUBMITTER*" {
                     puts $CHECK_OUTPUT "submitter started on host $host_name"
                     puts $CHECK_OUTPUT "setting options for submitter on host $host_name: $submit_options"
                     send -i $spawn_id "OPTIONS $submit_options\n"
                  }
                  "OPTIONS OK*" {
                     puts $CHECK_OUTPUT "setting submit script for submitter on host $host_name: $submit_script"
                     send -i $spawn_id "SCRIPT $submit_script\n"
                  }
                  "SCRIPT OK*" {
                     incr num_submitters 1
                     lappend next_submitter_list $host_name
                     puts $CHECK_OUTPUT "submitter ready to submit on host $host_name"
                  }
                  "ERROR:*" {
                     set error 1
                     add_proc_error "run_throughput_test" -1 "got error from host $host_name: $line"
                  }
               }
            }
         }
      }

      # Wait a maximum time for all submitters to respond.
      # After this time, give up.
      # In case of errors, give up.
      if { $error || [timestamp] > $my_timeout  } {
          foreach elem $remote_spawn_list {
             close_spawn_process $elem
          }
          set_error -1 "could not enable all host connections"
          return -1
       }
   }

   # variables set not in main loop for speed reasons
   set event_and_msg_id_list $event_client_id
   lappend event_and_msg_id_list $schedd_messages_id

   # job list where job start event was faster than submit
   set job_buffer_data_index 0
   set job_buffer_data ""
   set max_errors 10
   set resend_buffer ""
   set last_job_id 0

   set current_output_line 0

   foreach host $host_list {
      set host_submit_count($host) 0
   }

   set sent_jobs 0
   set schedd_nr 0
   set resend_list {}

   set timeout 120

   # here the throughput test starts
   set error 0
   log_user 0
   while { ! $error && $result(jobs_done) < $end_job_count } {
      # submit jobs as long as we have submitters ready and jobs to send
      while { [llength $next_submitter_list] > 0 && \
              ([llength $resend_list] > 0 || $sent_jobs < $end_job_count) } {
         # get first host in next_submitter_list and submit job on that host
         set sub_host   [lindex $next_submitter_list 0 ]       
         set next_submitter_list [lrange $next_submitter_list 1 end]

         set host_index [lsearch $host_list $sub_host]

         # if we have an invalid submit host, skip it
         if { $host_index < 0 } {
            continue
         }

         # build submit command     
         # if we don't have to resend an old job, send new job
         if { [llength $resend_list] > 0 } {
            set next_submit_command [lindex $resend_list 0]
            set resend_list [lrange $resend_list 1 end]
            # submit command has form <send_id> <command>, parse it
            set send_id [lindex $next_submit_command 0]
            set next_submit_command [lindex $next_submit_command 1 end]
         } else {
            if { $throughput_sharetree == 1 } {
               set numb [ expr ( ( $sent_jobs  % 3 ) + 1 )]
               set next_submit_command "SUBMIT 1 -P project${numb}"
            } else { 
               set next_submit_command "SUBMIT 1"
            }
            set send_id $sent_jobs
            incr sent_jobs
         }

         # remember submit command; in case of errors, we have to resend it
         set sent_commands($sub_host) "$send_id $next_submit_command"

         # send submit command
         set spawn_id [lindex $spawn_list $host_index]
         send -i $spawn_id "$next_submit_command\n"

         # store info about sent job
         set job_data($send_id,state) "submit"
         set job_data($send_id,job_id) "-"
         set job_data($send_id,submit_start_time) [timestamp]
         set job_data($send_id,submit_end_time) 0
         set job_data($send_id,run_start_time) 0
         set job_data($send_id,run_end_time) 0

         # some statistics
         incr host_submit_count($sub_host)
      }

      # wait for job submit success for all execd hosts and event client reports
      # in case of errors, we stop the test
      expect_user {
         -i $spawn_list full_buffer {
            add_proc_error "run_throughput_test" -1 "expect full_buffer error (2)"
            set error 1
         }
         -i $spawn_list timeout {
            puts $CHECK_OUTPUT "---->>>>>>>>> got timeout while waiting for submitted jobs"
            add_proc_error "run_throughput_test" -1 "got timeout while waiting for submitted jobs"
            set error 1
         }
         -i $spawn_list eof {
            set spawn_id $expect_out(spawn_id)
            set host_nr [lsearch $spawn_list $spawn_id]
            set host_name [lindex $host_list $host_nr]
            add_proc_error "run_throughput_test" -1 "$host_name EOF : $expect_out(buffer)"
            set error 1
         }
        -i $spawn_list "*\n" {
            set spawn_id $expect_out(spawn_id)
            set host_nr [lsearch $spawn_list $spawn_id]
            set host_name [lindex $host_list $host_nr]
            set output $expect_out(0,string) 
            set output [ split $output "\n" ]
            foreach line $output {
               set line [string trim $line]
               #puts $CHECK_OUTPUT $line
               switch -glob -- $line {
                  "SUBMIT OK*" {
                     # get submission data
                     set submitjob_jobid [lindex $line 2]
                     set submitjob_time  [lindex $line 3]
                     set submitjob_start [lindex $line 4]
                     set submitjob_end   [lindex $line 5]

                     # clear remembered submit command
                     unset sent_commands($host_name)

                     # store submission data

                     # get index of this job in the job_data array
                     # there are cases, where the JOB_ADD event will be received before
                     # the SUBMIT OK. In this case, the job already has an index and has
                     # already been counted as submitted.
                     if { [info exists job_data($submitjob_jobid)] } {
                        set job_index $job_data($submitjob_jobid)
                     } else {
                        set job_index $result(jobs_submitted)
                        incr result(jobs_submitted)

                        set last_job_id $submitjob_jobid

                        # doubly linked data job_id <-> job_index
                        set job_data(job_index,job_id) $submitjob_jobid
                        set job_data($submitjob_jobid) $job_index

                        set job_data($job_index,state) "pending"
                     }

                     set job_data($job_index,submit_time) $submitjob_time
                     set job_data($job_index,submit_start_time) $submitjob_start
                     set job_data($job_index,submit_end_time) $submitjob_end


                     # this host now can take the next submit command
                     lappend next_submitter_list $host_name
                  }
                  "SUBMIT FAILED*" {
                     # schedule submit for resending
                     if { [info exists sent_commands($host_name)] } {
                        lappend resend_list $sent_commands($host_name)
                     }
                     puts $CHECK_OUTPUT "submission on host $host_name failed"
                  }
                  default {
                     # puts $CHECK_OUTPUT "unexpected output (submitter): |$line|"
                  }
               }
            }
         }

         # here we expect event client
         -i $event_and_msg_id_list full_buffer {
            add_proc_error "run_throughput_test" -1 "expect full_buffer error (3)"
            set error 1
         }
         -i $event_and_msg_id_list eof {
            add_proc_error "run_throughput_test" "-1" "unexpected EOF"
            set error 1
         }
         -i $event_and_msg_id_list "_exit_status_" {
            add_proc_error "run_throughput_test" "-1" "unexpected _exit_status_"
            set error 1
         }
         -i $event_and_msg_id_list "*\n" {
            set output $expect_out(0,string) 
            set output [ split $output "\n" ]
            foreach line $output {
               set line [string trim $line]
               #puts $CHECK_OUTPUT $line

               switch -glob -- $line {
                  "JOB_ADD*" {
                     # evaluate job_id
                     set job_s_pos [string first "(" $line]
                     incr job_s_pos 1
                     set job_e_pos [string first ")" $line]
                     incr job_e_pos -1

                     set event_data [string range $line $job_s_pos $job_e_pos]
                     set event_data [split $event_data ":"]
                     set job_id [lindex $event_data 0] 
                     set help_pos [string first "." $job_id]
                     incr help_pos -1
                     set job_id [string range $job_id 0 $help_pos]

                     # evaluate project_name
                     set project_name [lindex $event_data 2]
                     set help_pos [string first "=" $project_name]
                     incr help_pos 1
                     set project_name [string range $project_name $help_pos end]

                     # get index of this job in the job_data array
                     # there are cases, where the JOB_ADD event will be received before
                     # the SUBMIT OK. In this case, assign the job an index and count it
                     # as submitted.
                     set sub_id [get_submit_id_from_job_id job_data $job_id]
                     if { $sub_id < 0 } {
                        set sub_id $result(jobs_submitted)
                        incr result(jobs_submitted)

                        set last_job_id $job_id

                        # doubly linked data job_id <-> job_index
                        set job_data(sub_id,job_id) $job_id
                        set job_data($job_id) $sub_id

                        set job_data($sub_id,state) "pending"
                     }

                     # store project (only number)
                     set job_data($sub_id,project) [string index $project_name 7]
                  }

                  "JOB_START*" {
                     # evaluate job_id
                     set job_s_pos [string first "(" $line]
                     incr job_s_pos 1
                     set job_e_pos [string first "." $line]
                     incr job_e_pos -1
                     set job_id [string range $line $job_s_pos $job_e_pos]

                     incr result(jobs_running)

                     set sub_id [get_submit_id_from_job_id job_data $job_id]
                     if { $sub_id >= 0 } {
                        set job_data($sub_id,run_start_time) [get_event_client_time $line]
                        set job_data($sub_id,state) "running"
                     }
                  }

                  "JOB_FINISH*" {
                     # evaluate job_id
                     set job_s_pos [string first "(" $line]
                     incr job_s_pos 1
                     set job_e_pos [string first "." $line]
                     incr job_e_pos -1
                     set job_id [string range $line $job_s_pos $job_e_pos]

                     # store data
                     incr result(jobs_done) 1
                     incr result(jobs_running) -1

                     set sub_id [get_submit_id_from_job_id job_data $job_id]
                     if { $sub_id >= 0 } {
                        set job_data($sub_id,run_end_time) [get_event_client_time $line]
                        set job_data($sub_id,state) "done"
                     }
                  }

                  "*scheduled in*" {

#  Mon Dec 16 15:01:05 2002|schedd|es-ergb01-01|I|scheduled in 0.000 s: 0 fast, 0 complex, 0 orders, 4 H, 4 Q, 13 QA, 0 J, 2 C, 1 ACL, 1 PE, 1 CONF, 0 U, 1 D, 1 PRJ, 0 ST, 1 CKPT, 0 RU

#new                                                  0      1   2    3   4   5 6 7     8  9
#  Wed Feb 12 10:53:06 2003|schedd|es-ergb01-01|I|scheduled in 0.010 (u 0.010 + s 0.000 = 0.010): 0 fast, 0 complex, 0 orders, 5 H, 30 Q, 34 QA, 0 J(qw), 0 J(r), 0 J(x), 2 C, 1 ACL, 1 PE, 1 CONF, 0 U, 1 D, 1 PRJ, 0 ST, 1 CKPT, 0 RU

# newest
#  Mon Jul 21 15:29:35 2003|schedd|es-ergb01-01|I|PROF: scheduled in 0.000 (u 0.000 + s 0.000 = 0.000): 0 fast, 0 complex, 0 orders, 4 H, 0 Q, 3 QA, 0 J(qw), 0 J(r), 0 J(s), 0 J(h), 0 J(e), 0 J(x), 0 J(all), 3 C, 1 ACL, 1 PE, 1 CONF, 0 U, 0 D, 0 PRJ, 0 ST, 1 CKPT, 0 RU

                     set st_pos [string first "|I|" $line ]
                     incr st_pos 3
                     set schedd_string [ string range $line $st_pos end ]
                     if { [ string compare "PROF:" [lindex $schedd_string 0]] == 0 } {
                        set schedd_string [ string range $schedd_string 6 end ]
                     }

                     if { [ string compare "in" [lindex $schedd_string 1 ]] != 0 } {
                        foreach elem $remote_spawn_list {
                           close_spawn_process $elem
                        }
                        close_spawn_process $event_client_sid
                        close_spawn_process $schedd_messages_sid
                        set_error -1 "format error for orders (1)"
                        return -1
                     }
                     set schedd_time [ lindex $schedd_string 2 ]   ;# this is wall clock time
                     if { [string match "*orders*" [lindex $schedd_string 9]] == 0 } {
                        set schedd_time [ lindex $schedd_string 9 ]  ;# this is system + user time (plus "):" )
                        set schedd_time_length [string length $schedd_time]
                        incr schedd_time_length -3
                        set schedd_time [ string range $schedd_time 0 $schedd_time_length ]
                     }

                      
                     for { set s_index 0 } { $s_index < [llength $schedd_string] } { incr s_index 1 } {
                        if { [string compare [lindex $schedd_string $s_index] "orders," ] == 0  } {
                           break
                        }
                     }
                      
                     if { [ string compare "orders," [lindex $schedd_string $s_index ]] != 0 } {
                        foreach elem $remote_spawn_list {
                           close_spawn_process $elem
                        }
                        close_spawn_process $event_client_sid
                        close_spawn_process $schedd_messages_sid
                        set_error -1 "format error for orders (2)"
                        return -1
                     }
                     incr s_index -1
                     set orders_value [ lindex $schedd_string $s_index ]
                     set schedd_data($schedd_nr,system_time)   [timestamp] 
                     set schedd_data($schedd_nr,schedd_time)   $schedd_time
                     set schedd_data($schedd_nr,schedd_orders) $orders_value
                     set schedd_data(count) $schedd_nr
                     incr schedd_nr 1
                     continue
                  }
                  default {
                     # puts $CHECK_OUTPUT "unexpected output (qevent/tail): |$line|"
                  }
               }
            }
         }
      }

      # update system status
      # we have one slot per queue !
      set jobs_running $result(jobs_running)
      set jobs_run_pend         [ expr ( $result(jobs_submitted) - $result(jobs_done)    ) ]
      set result(jobs_pending)  [ expr ( $jobs_run_pend          - $jobs_running ) ]
      set result(free_slots)    [ expr ( $result(total_slots)    - $jobs_running ) ]
      set result(queues_enabled) $are_enabled
      
      # tasks to be done once a minute
      set time_now [timestamp]
      if { $result(test_run_time) != $time_now } {
         show_current_system_status result job_data schedd_data
         flush $CHECK_OUTPUT

         # enable queues when $enable_queues_job_count is reached
         if { ! $are_enabled && $result(jobs_submitted) >= $enable_queues_job_count } {
            set are_enabled 1
            enable_queue $queue_list
            catch { exec "$ts_config(product_root)/bin/$CHECK_ARCH/qconf" "-tsm" } catch_result
            puts $CHECK_OUTPUT $catch_result
         }

      }
      set result(test_run_time) $time_now
      save_current_system_status results_list result
   } 
   log_user 1

   # make submitters quit
   foreach elem $remote_spawn_list {
      send -i [lindex $elem 1] "QUIT\n"
   }
   after 1000

   # close connections to submitters
   foreach elem $remote_spawn_list {
      close_spawn_process $elem
   }

   # close qevent and tail to schedd messages file
   close_spawn_process $event_client_sid
   close_spawn_process $schedd_messages_sid

   # cleanup jobs
   delete_all_jobs
   wait_for_jobend $last_job_id leeper 60 0 1

   # create reports
   create_reports results_list job_data schedd_data

   set_error 0 "ok"
}

proc get_submit_id_from_job_id { job_array_name job_id } {
   global ts_config
   global CHECK_OUTPUT
   upvar $job_array_name jobs
   
   if { [info exists jobs($job_id)] == 0 } {
#      puts $CHECK_OUTPUT "job $job_id not existing"
      return -1
   }

   return $jobs($job_id)
}

proc save_current_system_status { results_array array_name } {
   global ts_config
   global CHECK_OUTPUT

   upvar $array_name data
   upvar $results_array results

   set count $results(count)
   set names [array names data]
   foreach name $names {
      set results($count,$name) $data($name)
   }
   incr results(count) 1
}

proc compare_dump_directory { dir } {
   global ts_config
   global CHECK_OUTPUT

   set files [get_file_names $dir "saved_run*"]
   set first_data 0
   set test_info "FLUSH_FINISH_SEC"
   lappend test_info "FLUSH_SUBMIT_SEC"
   lappend test_info "SCHEDULE_INTERVAL"
   lappend test_info "enable_queues_job_count"
   lappend test_info "end_job_count"
   lappend test_info "global_job_run_time"
   lappend test_info "hostlist"
   lappend test_info "nr_of_local_spool_directories"
   lappend test_info "nr_queues"
   lappend test_info "nr_slots_per_queue"

   set test_data "avg_run"
   lappend test_data "avg_schedd_time"
   lappend test_data "avg_submit"
   lappend test_data "utilization"
   lappend test_data "submits_per_second"
   lappend test_data "jobs_per_second"
   lappend test_data "total_submit_time"
   lappend test_data "total_run_time"

   foreach data $test_data {
      set nr [lsearch $test_data $data]
      set xy_rows($nr,drawmode) "linespoints"
      set xy_rows($nr,title) $data
      set xy_rows($nr,show) 0
      set sum($data) 0.0000
   }


   set count 0
   foreach file $files {
      if { [string first "old" $file ] > 0 } {
         continue
      }
      if { [string first "_vs_" $file ] > 0 } {
         continue
      }

      set test_info_file $dir/${file}_dir/test_results_array.dat
#      puts $CHECK_OUTPUT "file: $test_info_file\n"
      read_array_from_file $test_info_file "test settings" test_settings
      read_array_from_file $test_info_file "test results"  test_results

      if { $first_data == 0 } {
         foreach info  $test_info {
            set defaults($info) $test_settings($info)
         }
      }
      set ignore 0
      foreach info  $test_info {
         if { [ string compare $defaults($info) $test_settings($info) ] != 0 } {
            puts $CHECK_OUTPUT "ignoring file $file: $defaults($info) for $info setting not $defaults($info)"
            set ignore 1
         } 
      }

      if { $ignore == 0 } {
         # here we have the data
         foreach data $test_data {
#            puts $CHECK_OUTPUT "($count=$file) $data: $test_results($data)" 
            set nr [lsearch $test_data $data]

            # x value: (nr of file )
            set xy_rows($nr,$count,x) $count
            set xy_rows($nr,$count,y) $test_results($data)
            set sum($data) [ expr ( $sum($data) + $test_results($data)) ]
         }
         incr count 1
      }
      incr first_data 1
   }
   set plot_data(xlabel) "nr"
   set plot_data(ylabel) "values"
   
   foreach data $test_data {
      set nr [lsearch $test_data $data]
      set calc_avg [expr ( $sum($data) / $count )]
      puts $CHECK_OUTPUT "avg. $data: $calc_avg"
   }

   foreach data $test_data {
      set nr [lsearch $test_data $data]
      set plot_data(title) "historical - $data"
      set plot_data(output_file) "$dir/$data.gif"
      set xy_rows($nr,show) 1
      create_gnuplot_xy_gif plot_data xy_rows
      set xy_rows($nr,show) 0
   }
}

# directory of file1 is used to save results
proc compare_dump_data_file { file1 file2 } {
   global ts_config
   global CHECK_OUTPUT 

   if { [file isfile $file1] != 1 } {
      puts $CHECK_OUTPUT "no file $file1"
      return -1
   }
   if { [file isfile $file2] != 1 } {
      puts $CHECK_OUTPUT "no file $file2"
      return -1
   }


   # first analyse the files (if not existent)
   analyse_dump_data_file $file1 
   analyse_dump_data_file $file2
   
   # create output directory
   set sub_dir1 [file tail $file1]
   set sub_dir2 [file tail $file2]
   set sub_dir "${sub_dir1}_vs_${sub_dir2}"
   set dir_name [file dirname $file1]
   set output_dir $dir_name/${sub_dir}_dir
   puts $CHECK_OUTPUT "file: [file tail $file1]"
   puts $CHECK_OUTPUT "file: [file tail $file2]"
   puts $CHECK_OUTPUT "generating report in directory: $output_dir"
   file mkdir $output_dir
   puts $CHECK_OUTPUT "please wait ..."

   # read in test configuration files
   read_array_from_file $file1 "test configuration" test_config1
   read_array_from_file $file2 "test configuration" test_config2


   set content ""
   set error 0
   set job_count1 $test_config1(end_job_count)
   set job_count2 $test_config2(end_job_count)
   if { $job_count1 != $job_count2 } {
      incr error 1
      append content [create_html_text "The to projects have different job count"]
   }
 
   set enable_queue_job_count1 $test_config1(enable_queues_job_count)
   set enable_queue_job_count2 $test_config2(enable_queues_job_count)
   if { $enable_queue_job_count1 != $enable_queue_job_count2 } {
      incr error 1
      append content [create_html_text "The queue enable threshold values are different"]
   }

   set global_job_run_time1 $test_config1(global_job_run_time) 
   set global_job_run_time2 $test_config2(global_job_run_time)
   if { $global_job_run_time1 != $global_job_run_time2 } {
      incr error 1
      append content [create_html_text "The to test runs have different job run time"]
   }

   set nr_queues1 $test_config1(nr_queues)
   set nr_queues2 $test_config2(nr_queues)
   set nr_slots_per_queue1 $test_config1(nr_slots_per_queue)
   set nr_slots_per_queue2 $test_config2(nr_slots_per_queue)
   set hostslots1 [ expr ( $nr_queues1 * $nr_slots_per_queue1 ) ]
   set hostslots2 [ expr ( $nr_queues2 * $nr_slots_per_queue2 ) ]

   if { $hostslots1 != $hostslots2 } {
      incr error 1
      append content [create_html_text "The number of slots on each host is different"]
   }
   


   set FLUSH_SUBMIT_SEC1 $test_config1(FLUSH_SUBMIT_SEC)
   set FLUSH_SUBMIT_SEC2 $test_config2(FLUSH_SUBMIT_SEC)
   if { $FLUSH_SUBMIT_SEC1  != $FLUSH_SUBMIT_SEC2 } {
      incr error 1
      append content [create_html_text "The test runs have different FLUSH_SUBMIT_SEC times"]
   }

  
   set FLUSH_FINISH_SEC1 $test_config1(FLUSH_FINISH_SEC)
   set FLUSH_FINISH_SEC2 $test_config2(FLUSH_FINISH_SEC)
   if { $FLUSH_FINISH_SEC1 != $FLUSH_FINISH_SEC2 } {
      incr error 1
      append content [create_html_text "The test runs have different FLUSH_FINISH_SEC times"]
   }

  
   set SCHEDULE_INTERVAL1 $test_config1(SCHEDULE_INTERVAL)
   set SCHEDULE_INTERVAL2 $test_config2(SCHEDULE_INTERVAL)
   if { $SCHEDULE_INTERVAL1 != $SCHEDULE_INTERVAL2 } {
      incr error 1
      append content [create_html_text "The test runs have different SCHEDULE_INTERVAL values"]
   }
  
   read_array_from_file $file1 "execd list" host_list1
   read_array_from_file $file2 "execd list" host_list2
   set nr 0
   set execd_list1 ""
   set qmaster1 [lindex $host_list1(host_list) 0]
   foreach elem $host_list1(host_list) {
      if { $elem == $qmaster1 } {
         continue
      }
      if { $elem == "global" } {
         continue
      }
      lappend execd_list1 $elem
   }
   set nr 0
   set execd_list2 ""
   set qmaster2 [lindex $host_list2(host_list) 0]
   foreach elem $host_list2(host_list) {
      if { $elem == $qmaster2 } {
         continue
      }
      if { $elem == "global" } {
         continue
      }
      lappend execd_list2 $elem
   }

   # qmaster, execd_list, host_list
   if { [string compare $host_list1(host_list) $host_list2(host_list)] != 0 } {
      incr error 1
      append content [create_html_text "The test runs have different host list settings"]
   }

   read_array_from_file "${file1}_dir/test_results_array.dat" "test settings" test_settings1
   read_array_from_file "${file2}_dir/test_results_array.dat" "test settings" test_settings2
  
   puts $CHECK_OUTPUT "A spool directories: $test_settings1(nr_of_local_spool_directories)"
   puts $CHECK_OUTPUT "B spool directories: $test_settings2(nr_of_local_spool_directories)"
   if { $test_settings1(nr_of_local_spool_directories) != $test_settings2(nr_of_local_spool_directories) } {
      incr error 1
      append content [create_html_text "The execd have different count of local spool directories"]
   }

   
   if { $error != 0 } {
      append content [create_html_text "Can't compare the two test scenarios !!!"]
      generate_html_file $output_dir/index.html "$test_config1(gridengine_version) (A) from $test_config1(test_date)<br>vs<br>$test_config2(gridengine_version) (B) from $test_config2(test_date)" $content
      return -1
   }

   # ok, we can compare the two scenarios !!!
   set text ""
   append text "The Grid Engine throughput test runs submits sleeper jobs to each execd host in the "
   append text "cluster. No job is submitted from master host. This test report compares two testsuite "
   append text "runs and shows only the divergent test values. Both testsuite Grid Engine clusters had "
   append text "following settings:"
   append content [ create_html_text $text ]

   set test "Grid Engine version A"
   set table($test) "$test_config1(gridengine_version)"
   set test "Grid Engine version B"
   set table($test) "$test_config2(gridengine_version)"

   set test "Nr. of Execution daemons"
   set table($test) [create_html_link [llength $execd_list1] "#Execd list"]

   set test "Master/Scheduler host"
   set table($test) "$qmaster1"

   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   if { $test_config1(enable_queues_job_count) == 0 } {
      set text ""
      append text "There was no threshold value for enabling queues in the tests. So all queues was "
      append text "enabled when testsuite started to submit jobs." 
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "There was a threshold value for enabling queues in the tests. So all queues was "
      append text "disabled when testsuite started to submit jobs. As the pending job count reached " 
      append text "a count of $test_config1(enable_queues_job_count) the testsuite enabled all cluster "
      append text "queues."
      append content [ create_html_text $text ]
   }
   append content [ create_html_text "" ]

   set text ""
   append text "The Grid Engine system A had $test_config1(nr_queues) queues with $test_config1(nr_slots_per_queue) "
   append text "slots on each host (=[ expr ( $test_config1(nr_queues) * $test_config1(nr_slots_per_queue) * [llength $execd_list1]  )] "
   append text "slots)." 
   append content [ create_html_text $text ]
   set text ""
   append content [ create_html_text "" ]
   append text "The Grid Engine system B had $test_config2(nr_queues) queues with $test_config2(nr_slots_per_queue) "
   append text "slots on each host (=[ expr ( $test_config2(nr_queues) * $test_config2(nr_slots_per_queue) * [llength $execd_list2]  )] "
   append text "slots)." 
   append content [ create_html_text $text ]
   set text ""
   append content [ create_html_text "" ]
   append text "The testsuite subitted $test_config1(end_job_count) sleeper jobs to the systems. Each job had " 
   append text "a sleep time of $test_config1(global_job_run_time) seconds."
   append content [ create_html_text $text ]
   append content [ create_html_text "" ]


   if { $test_config1(FLUSH_SUBMIT_SEC) == -1 } {
      set text ""
      append text "The FLUSH_SUBMIT_SEC parameters were turned off."
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "The FLUSH_SUBMIT_SEC parameters were set to $test_config1(FLUSH_SUBMIT_SEC) seconds."
      append content [ create_html_text $text ]
   }
 
   append content [ create_html_text "" ]
   if { $test_config1(FLUSH_FINISH_SEC) == -1 } {
      set text ""
      append text "The FLUSH_FINISH_SEC parameters were turned off."
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "The FLUSH_FINISH_SEC parameter were set to $test_config1(FLUSH_FINISH_SEC) seconds."
      append content [ create_html_text $text ]
   }

   append content [ create_html_text "" ]
   set text ""
   append text "The schedule interval parameters were set to $test_config1(SCHEDULE_INTERVAL)"
   append content [ create_html_text $text ]
   
   read_file $file1 file_data1
   read_file $file2 file_data2

   puts $CHECK_OUTPUT "reading online data of test A"
   read_array_from_file_data file_data1 "online data"    results1
   puts $CHECK_OUTPUT "reading job data of test A"
   read_array_from_file_data file_data1 "job data"       jobs1
   puts $CHECK_OUTPUT "reading scheduler data of test A"
   read_array_from_file_data file_data1 "scheduler data" schedd1
   puts $CHECK_OUTPUT "reading online data of test B"
   read_array_from_file_data file_data2 "online data"    results2
   puts $CHECK_OUTPUT "reading job data of test B"
   read_array_from_file_data file_data2 "job data"       jobs2
   puts $CHECK_OUTPUT "reading scheduler data of test B"
   read_array_from_file_data file_data2 "scheduler data" schedd2
   

# --  1  set test "Total run time"
# --   set test_data(total_run_time) $cluster_results(total_run_time)
# --  2  set test "Total submit time"
# --   set test_data(total_submit_time) $cluster_results(total_submit_time)
# --  3  set test "Submits per second"
# --   set test_data(submits_per_second)  $cluster_results(submits_per_second)
# --  4  set test "Jobs per second"
# --   set test_data(jobs_per_second) $cluster_results(jobs_per_second)
# --  5  set test "Utilization (Slot allocation)"
# --   set test_data(utilization)  $cluster_results(utilization)
# --  6  set test "Average Submit time"
# --   set test_data(avg_submit) $avg_values(avg_submit)
# --  7  set test "Average run/transfer time"
# --   set test_data(avg_run) $avg_values(avg_run)
# --  8  set test "Average scheduler calculation time"
# --   set test_data(avg_schedd_time) $avg_schedd_values(avg_schedd_time)


   read_array_from_file "${file1}_dir/test_results_array.dat" "test results" test_data1
   read_array_from_file "${file2}_dir/test_results_array.dat" "test results" test_data2
   

   #   A absolut  |  B absolut | B compared to A (in %) 
   set table(COLS) 4
   set table(ROWS) 9
   set table(1,BGCOLOR) "#FFFFFF"
   set table(1,FNCOLOR) "#000000"
   set table(1,1) ""
   set table(1,2) "A<br>($test_config1(gridengine_version))"
   set table(1,3) "B<br>($test_config2(gridengine_version))"
   set table(1,4) "B compared to A (in %)"

   set row_names "dummy dummy"
   lappend row_names "Total run time"
   lappend row_names "Total submit time"
   lappend row_names "Submits per second"
   lappend row_names "Jobs per second"
   lappend row_names "Utilization (Slot allocation)"  
   lappend row_names "Average Submit time"
   lappend row_names "Average run/transfer time"
   lappend row_names "Average scheduler calculation time"

   set A "dummy dummy"
   lappend A $test_data1(total_run_time)
   lappend A $test_data1(total_submit_time)
   lappend A $test_data1(submits_per_second)
   lappend A $test_data1(jobs_per_second)
   lappend A $test_data1(utilization)
   lappend A $test_data1(avg_submit)
   lappend A $test_data1(avg_run)
   lappend A $test_data1(avg_schedd_time)
   set B "dummy dummy"
   lappend B $test_data2(total_run_time)
   lappend B $test_data2(total_submit_time)
   lappend B $test_data2(submits_per_second)
   lappend B $test_data2(jobs_per_second)
   lappend B $test_data2(utilization)
   lappend B $test_data2(avg_submit)
   lappend B $test_data2(avg_run)
   lappend B $test_data2(avg_schedd_time)


   for { set row 2} { $row <= 9 } { incr row 1} {
      set table($row,BGCOLOR) "#FFFFFF"
      set table($row,FNCOLOR) "#000000"
      set table($row,1) [lindex $row_names $row]
      set a [lindex $A $row]
      set b [lindex $B $row]
      set table($row,2) [format "%.3f" $a]
      set table($row,3) [format "%.3f" $b]

      # a is 100%
      set one_percent [ expr ( $a / 100.000  ) ]
      set b_in_percent [ expr ( $b / $one_percent ) ]      
      set diff [ expr ( abs ( 100.000 - $b_in_percent ) ) ]

      set good  "#00FF00"  ;# green
      set bad   "#FF0000"  ;# red
      set good_s "B beats A"
      set bad_s  "B underlies A"

      if { $row == 4 || $row == 5 || $row == 6 } {
         set help $good
         set good $bad
         set bad $help
         set help $good_s
         set good_s $bad_s
         set bad_s $help
         
      }
     

      if { $b_in_percent > 100 } {
         set table($row,4,FNCOLOR) $bad    ;# red
         set arrow $bad_s
      } else {
         set table($row,4,FNCOLOR) $good    ;# green
         set arrow $good_s
      }
      if { $b_in_percent == 100.00 } {
         set table($row,4,FNCOLOR) "#000000"
         set arrow "B equals A"
      }
      
      set table($row,4) "[format "%.3f" $b_in_percent]%<br>(difference: [format "%.3f" $diff]%)<br>($arrow)"

   }
   append content [ create_html_table table 1 CENTER]


   # links to other documents
   append content [ create_html_text "" ]
   append content [create_html_link "   (1) Running job analysis" "running_jobs.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (2) Job time analysis" "job_times.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (3) Job distribution analysis" "job_distribution.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (4) Pending job analysis" "pending_jobs.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (5) Scheduler calculation time analysis" "schedd_calc_time.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (6) Scheduler job order analysis" "schedd_orders.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (7) All charts in one html document" "all_charts.html"]



  
   # apendix
   append content [ create_html_text "" ]
   append content "<hr WIDTH=\"100%\">"
   append content [ create_html_text "Appendix" 1]
   append content "<hr WIDTH=\"100%\">"
   
   # host architecture list
   append content [create_html_target "Execd list"]
   append content [create_html_text "The test runs used the following execution hosts:"]
   unset table
   set table(Hostname) "Architecture"
   foreach host $execd_list1 {
      set table($host) [resolve_arch $host]
   }
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]


   
   generate_html_file $output_dir/index.html "$test_config1(gridengine_version) (A) from $test_config1(test_date)<br>file: $file1<br>vs<br>$test_config2(gridengine_version) (B) from $test_config2(test_date)<br>file: $file2" $content

   # generate chart files ------------------------------------------------
   set content ""
   append content ""
   append content [create_html_image "Running jobs" "running_jobs.gif"]
   set title "$test_config1(gridengine_version) (A) from $test_config1(test_date)<br>vs<br>$test_config2(gridengine_version) (B) from $test_config2(test_date)"
   generate_html_file $output_dir/running_jobs.html $title $content
   
   set content ""
   append content ""
   append content [create_html_image "Job times" "job_times.gif"]
   generate_html_file $output_dir/job_times.html $title $content

   set content ""
   append content ""
   append content [create_html_image "Job distribution" "job_distribution.gif"]
   generate_html_file $output_dir/job_distribution.html $title $content


   set content ""
   append content ""
   append content [create_html_image "Pending jobs" "pending_jobs.gif"]
   generate_html_file $output_dir/pending_jobs.html $title $content

   set content ""
   append content ""
   append content [create_html_image "Scheduler times" "schedd_calc_time.gif"]
   generate_html_file $output_dir/schedd_calc_time.html $title $content

   set content ""
   append content ""
   append content [create_html_image "Scheduler orders" "schedd_orders.gif"]
   generate_html_file $output_dir/schedd_orders.html $title $content

   set content ""
   append content ""
   append content [create_html_image "Running jobs" "running_jobs.gif"]
   append content [create_html_image "Job times" "job_times.gif"]
   append content [create_html_image "Job distribution" "job_distribution.gif"]
   append content [create_html_image "Pending jobs" "pending_jobs.gif"]
   append content [create_html_image "Scheduler times" "schedd_calc_time.gif"]
   append content [create_html_image "Scheduler orders" "schedd_orders.gif"]
   generate_html_file $output_dir/all_charts.html $title $content


   # plot diagrams
   # get functions for test run  and schedd data
       #  1) test run
       calculate_test_run_xy_rows results1 xy_rows 0
       #  2) schedd run
       set test_start $results1(0,test_run_time)
       calculate_schedd_run_xy_rows schedd1 xy_rows $test_start 0
       #  3) job submit times and job run times
       calculate_submit_run_xy_rows jobs1 xy_rows $test_start 0

       #  1) test run
       calculate_test_run_xy_rows results2 xy_rows 11
       #  2) schedd run
       set test_start $results2(0,test_run_time)
       calculate_schedd_run_xy_rows schedd2 xy_rows $test_start 11
       #  3) job submit times and job run times
       calculate_submit_run_xy_rows jobs2 xy_rows $test_start 11




       set plot_data(xlabel) "time\[s\]"
       set plot_data(ylabel) "values"

       set plot_data(title) "Throughput test results - running jobs"
       set plot_data(output_file) "$output_dir/running_jobs.gif"
       set xy_rows(0,show) 1     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 1     ;# total system slots
       set xy_rows(5,show) 1     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution

       set start 11
       set xy_rows($start,show) 1     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 1     ;# total system slots
       incr start 1
       set xy_rows($start,show) 1     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows



       set plot_data(title) "Throughput test results - pending jobs"
       set plot_data(output_file) "$output_dir/pending_jobs.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 1     ;# pending jobs
       set xy_rows(2,show) 1     ;# jobs done
       set xy_rows(3,show) 1     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution


       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 1     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 1     ;# jobs done
       incr start 1
       set xy_rows($start,show) 1     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - schedd calculation time"
       set plot_data(output_file) "$output_dir/schedd_calc_time.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 1     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution

       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 1     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows


       set plot_data(title) "Throughput test results - schedd orders"
       set plot_data(output_file) "$output_dir/schedd_orders.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 1     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution

       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 1     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - job times"
       set plot_data(output_file) "$output_dir/job_times.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 1     ;# job submit time
       set xy_rows(9,show) 1     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution

       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 1     ;# job submit time
       incr start 1
       set xy_rows($start,show) 1     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows
   
       set plot_data(title) "Throughput test results - job distribution"
       set plot_data(output_file) "$output_dir/job_distribution.gif"
       set plot_data(xlabel) "job time\[s\]"
       set plot_data(ylabel) "number of jobs"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 1     ;# job distribution

       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 1     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows


   return 0

}

proc analyse_dump_data_file { file { force 0 } } {
   global ts_config
   global CHECK_OUTPUT
   global throughput_sharetree
   
   set sub_dir [file tail $file]
   set dir_name [file dirname $file] 
   set output_dir $dir_name/${sub_dir}_dir
   puts $CHECK_OUTPUT "file: [file tail $file]"
   puts $CHECK_OUTPUT "generating report in directory: $output_dir"
   if { [file isdirectory $output_dir] && $force == 0 } {
      puts $CHECK_OUTPUT "existing analyse directory found. Use force option to re-analyse data file."
      return
   }
   if { [file isdirectory $output_dir] && $force != 0 } {
      puts $CHECK_OUTPUT "forcing re-analyse ..."
   }
   
   file mkdir $output_dir
  
   puts $CHECK_OUTPUT "please wait ..."
   read_array_from_file $file "online data"    results
   read_array_from_file $file "job data"       jobs
   read_array_from_file $file "scheduler data" schedd
   read_array_from_file $file "test configuration" test_config
   read_array_from_file $file "execd list" host_list
   puts $CHECK_OUTPUT "Test date:          $test_config(test_date)"
   puts $CHECK_OUTPUT "gridengine version: $test_config(gridengine_version)"

   read_array_from_file $file "schedd config" schedd_config
   

   
   # job results
   calculate_average_cluster_times results cluster_results $output_dir/cluster_times.txt
   calculate_average_job_times jobs avg_values $output_dir/job_times.txt
   calculate_average_schedd_times schedd avg_schedd_values $output_dir/schedd_times.txt

   

   set nr 0
   set execd_list ""
   set qmaster [lindex $host_list(host_list) 0]
   foreach elem $host_list(host_list) {
      if { $elem == $qmaster } {
         continue
      }
      if { $elem == "global" } {
         continue
      }
      lappend execd_list $elem
   }

   set content ""
   set text ""
   append text "The Grid Engine throughput test runs submits sleeper jobs to each execd host in the "
   append text "cluster. No job is submitted from master host. The testsuite Grid Engine cluster had "
   append text "following settings:"
   append content [ create_html_text $text ]

   set test "Grid Engine version"
   set table($test) "$test_config(gridengine_version)"
   set test "Nr. of Execution daemons"
   set table($test) [create_html_link [llength $execd_list] "#Execd list"]
   set test "Master/Scheduler host"
   set table($test) "$qmaster"
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   # 
   if { $test_config(enable_queues_job_count) == 0 } {
      set text ""
      append text "There was no threshold value for enabling queues in the test. So all queues was "
      append text "enabled when testsuite started to submit jobs." 
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "There was a threshold value for enabling queues in the test. So all queues was "
      append text "disabled when testsuite started to submit jobs. As the pending job count reached " 
      append text "a count of $test_config(enable_queues_job_count) the testsuite enabled all cluster "
      append text "queues."
      append content [ create_html_text $text ]
   }
   append content [ create_html_text "" ]
   set text ""
   append text "The Grid Engine system had $test_config(nr_queues) queues with $test_config(nr_slots_per_queue) "
   append text "slots on each host (=[ expr ( $test_config(nr_queues) * $test_config(nr_slots_per_queue) * [llength $execd_list]  )] "
   append text "slots). The testsuite subitted $test_config(end_job_count) sleeper jobs to the system. Each job had " 
   append text "a sleep time of $test_config(global_job_run_time) seconds."
   append content [ create_html_text $text ]
   
   append content [ create_html_text "" ]
   if { $test_config(FLUSH_SUBMIT_SEC) == -1 } {
      set text ""
      append text "The FLUSH_SUBMIT_SEC parameter was turned off."
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "The FLUSH_SUBMIT_SEC parameter was set to $test_config(FLUSH_SUBMIT_SEC) seconds."
      append content [ create_html_text $text ]
   }
 
   append content [ create_html_text "" ]
   if { $test_config(FLUSH_FINISH_SEC) == -1 } {
      set text ""
      append text "The FLUSH_FINISH_SEC parameter was turned off."
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "The FLUSH_FINISH_SEC parameter was set to $test_config(FLUSH_FINISH_SEC) seconds."
      append content [ create_html_text $text ]
   }

   append content [ create_html_text "" ]
   set text ""
   append text "The schedule interval parameter was set to $cluster_results(schedule_interval)"
   append content [ create_html_text $text ]
   



   puts $CHECK_OUTPUT "total run time     : $cluster_results(total_run_time)"
   puts $CHECK_OUTPUT "total jobs done    : $cluster_results(total_jobs_done)"
   puts $CHECK_OUTPUT "total submit time  : $cluster_results(total_submit_time)"
   puts $CHECK_OUTPUT "submits per second : $cluster_results(submits_per_second)"
   puts $CHECK_OUTPUT "jobs per second    : $cluster_results(jobs_per_second)"
   puts $CHECK_OUTPUT "avg. slots free    : $cluster_results(avg_slots_free)"
   puts $CHECK_OUTPUT "total slots        : $cluster_results(total_slots)"
   puts $CHECK_OUTPUT "utilization        : $cluster_results(utilization)"
   puts $CHECK_OUTPUT "job sleep time     : $cluster_results(jobs_sleep_time)"
   puts $CHECK_OUTPUT "queue enable value : $cluster_results(queue_enable_value)"
   puts $CHECK_OUTPUT "flush submit sec   : $cluster_results(flush_submit_sec)"
   puts $CHECK_OUTPUT "flush finish sec   : $cluster_results(flush_finish_sec)"
   puts $CHECK_OUTPUT "schedule interval  : $cluster_results(schedule_interval)"
   puts $CHECK_OUTPUT ""
   puts $CHECK_OUTPUT "avg. submit       (count=$avg_values(jobs_submit))   : $avg_values(avg_submit) "
   puts $CHECK_OUTPUT "avg. run/transfer (count=$avg_values(jobs_run))   : $avg_values(avg_run)    "
   puts $CHECK_OUTPUT ""
   puts $CHECK_OUTPUT "avg. schedd time (count=$avg_schedd_values(nr_of_schedd_runs))   : $avg_schedd_values(avg_schedd_time)"

   

   append content [ create_html_text "" ]
  
   unset table
   set test "Total run time"
   set table($test) $cluster_results(total_run_time)
   set test_data(total_run_time) $cluster_results(total_run_time)


   set test "Total submit time"
   set table($test) $cluster_results(total_submit_time)
   set test_data(total_submit_time) $cluster_results(total_submit_time)

   set test "Submits per second"
   set table($test) $cluster_results(submits_per_second)
   set test_data(submits_per_second)  $cluster_results(submits_per_second)

   set test "Jobs per second"
   set table($test) $cluster_results(jobs_per_second)
   set test_data(jobs_per_second) $cluster_results(jobs_per_second)

   set test "Utilization (Slot allocation)"
   set table($test) $cluster_results(utilization)
   set test_data(utilization)  $cluster_results(utilization)


   set test "Average Submit time"
   set table($test) $avg_values(avg_submit)
   set test_data(avg_submit) $avg_values(avg_submit)
  
   set test "Average run/transfer time"
   set table($test) $avg_values(avg_run)
   set test_data(avg_run) $avg_values(avg_run)

   set test "Average scheduler calculation time"
   set table($test) $avg_schedd_values(avg_schedd_time)
   set test_data(avg_schedd_time) $avg_schedd_values(avg_schedd_time)

   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   spool_array_to_file $output_dir/test_results_array.dat "test results" test_data



   # links to other documents
   append content [ create_html_text "" ]
   append content [create_html_link "   (1) Running job analysis" "running_jobs.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (2) Job time analysis" "job_times.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (3) Job time analysis" "job_distribution.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (4) Pending job analysis" "pending_jobs.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (5) Scheduler calculation time analysis" "schedd_calc_time.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (6) Scheduler job order analysis" "schedd_orders.html"]
   append content [ create_html_text "" ]
   if { $throughput_sharetree == 1 }  {
      append content [create_html_link "   (7) Running project job analysis" "project_jobs.html"]
      append content [ create_html_text "" ]
      append content [create_html_link "   (8) All charts in one html document" "all_charts.html"]
   } else {
      append content [create_html_link "   (7) All charts in one html document" "all_charts.html"]
   }

   # links to data
   append content [ create_html_text "" ]
   append content [ create_html_text "" ]
   append content [ create_html_text "Links to test data:" ]
   
   append content [ create_html_text "" ]
   append content [create_html_link "   Cluster Time data" "cluster_times.txt"]
   append content [ create_html_text "" ]
   append content [create_html_link "   Job Time data" "job_times.txt"]
   append content [ create_html_text "" ]
   append content [create_html_link "   Scheduler Time data" "schedd_times.txt"]

   
   # links to object dumps
   append content [ create_html_text "" ]
   append content [ create_html_text "" ]
   append content [ create_html_text "Links to configuration data:" ]

   append content [ create_html_text "" ]
   append content [create_html_link "   Testsuite configuration" "#test_config"]

   append content [ create_html_text "" ]
   append content [create_html_link "   Testsuite scheduler configuration" "#schedd_config"]

   foreach execd $host_list(host_list) { 
      append content [ create_html_text "" ]
      append content [create_html_link "   Execution host $execd" "#execd $execd"]

      append content [ create_html_text "" ]
      append content [create_html_link "   Configuration for host $execd" "#config execd $execd"]
   }


   # apendix
   append content [ create_html_text "" ]
   append content "<hr WIDTH=\"100%\">"
   append content [ create_html_text "Appendix" 1]
   append content "<hr WIDTH=\"100%\">"

   # host architecture list
   append content [create_html_target "Execd list"]
   append content [create_html_text "The test run used the following execution hosts:"]
   unset table
   set table(Hostname) "Architecture"
   foreach host $execd_list {
      set table($host) [resolve_arch $host]
   }
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]


   # test_config
   append content [create_html_target "test_config"]
   append content [create_html_text "Testsuite configration data:"]
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file test_config test_config
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   # schedd_config
   append content [create_html_target "schedd_config"]
   append content [create_html_text "Cluster scheduler configuration file:"]
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file schedd_config schedd_config  
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   # configurations
   set nr_of_local_spool_directories 0

   foreach execd $host_list(host_list) { 
      read_array_from_file $file "execd $execd" execd_array
      append content [create_html_target "execd $execd"]
      append content [create_html_text "Execd $execd:"]
      set tmp_file [get_tmp_file_name]
      spool_array_to_file $tmp_file execd_array execd_array
      append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]
      unset execd_array

      read_array_from_file $file "config execd $execd" config_array

      if { $execd != "global" } {
         if { [info exists config_array(execd_spool_dir)] } {
            incr nr_of_local_spool_directories 1
         }
      }


      append content [create_html_target "config execd $execd"]
      append content [create_html_text "Execd configuration for $execd:"]
      set tmp_file [get_tmp_file_name]
      spool_array_to_file $tmp_file config_array config_array
      append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]
      unset config_array
   }
   



   generate_html_file $output_dir/index.html "Testsuite Throughput Test Status Report from $test_config(test_date)" $content

   # spool addition test information into test_results_array.dat
   set info_data(end_job_count) $test_config(end_job_count)
   set info_data(enable_queues_job_count)  $test_config(enable_queues_job_count)
   set info_data(global_job_run_time) $test_config(global_job_run_time)
   set info_data(nr_queues) $test_config(nr_queues)
   set info_data(nr_slots_per_queue) $test_config(nr_slots_per_queue)
   set info_data(FLUSH_SUBMIT_SEC) $test_config(FLUSH_SUBMIT_SEC)
   set info_data(FLUSH_FINISH_SEC) $test_config(FLUSH_FINISH_SEC)
   set info_data(SCHEDULE_INTERVAL) $test_config(SCHEDULE_INTERVAL)
   set info_data(hostlist) $host_list(host_list)
   set info_data(nr_of_local_spool_directories) $nr_of_local_spool_directories   
   spool_array_to_file $output_dir/test_results_array.dat "test settings" info_data


   

   # generate chart files
   set content ""
   append content ""
   append content [create_html_image "Running jobs" "running_jobs.gif"]
   generate_html_file $output_dir/running_jobs.html "$test_config(gridengine_version) from $test_config(test_date)" $content

   if { $throughput_sharetree == 1 }  {
      set content ""
      append content ""
      append content [create_html_image "Running project jobs" "project_jobs.gif"]
      generate_html_file $output_dir/project_jobs.html "$test_config(gridengine_version) from $test_config(test_date)" $content
   }
   
   set content ""
   append content ""
   append content [create_html_image "Job times" "job_times.gif"]
   generate_html_file $output_dir/job_times.html "$test_config(gridengine_version) from $test_config(test_date)" $content
 
    set content ""
   append content ""
   append content [create_html_image "Job distribution" "job_distribution.gif"]
   generate_html_file $output_dir/job_distribution.html "$test_config(gridengine_version) from $test_config(test_date)" $content


   set content ""
   append content ""
   append content [create_html_image "Pending jobs" "pending_jobs.gif"]
   generate_html_file $output_dir/pending_jobs.html "$test_config(gridengine_version) from $test_config(test_date)" $content

   set content ""
   append content ""
   append content [create_html_image "Scheduler times" "schedd_calc_time.gif"]
   generate_html_file $output_dir/schedd_calc_time.html "$test_config(gridengine_version) from $test_config(test_date)" $content

   set content ""
   append content ""
   append content [create_html_image "Scheduler orders" "schedd_orders.gif"]
   generate_html_file $output_dir/schedd_orders.html "$test_config(gridengine_version) from $test_config(test_date)" $content

   set content ""
   append content ""
   append content [create_html_image "Running jobs" "running_jobs.gif"]
   append content [create_html_image "Job times" "job_times.gif"]
   append content [create_html_image "Job distribution" "job_distribution.gif"]
   append content [create_html_image "Pending jobs" "pending_jobs.gif"]
   append content [create_html_image "Scheduler times" "schedd_calc_time.gif"]
   append content [create_html_image "Scheduler orders" "schedd_orders.gif"]
   if { $throughput_sharetree == 1 }  {
      append content [create_html_image "Running project jobs" "project_jobs.gif"]
   }
   generate_html_file $output_dir/all_charts.html "$test_config(gridengine_version) from $test_config(test_date)" $content


   # plot diagrams
   # get functions for test run  and schedd data
       # 1) test run
       calculate_test_run_xy_rows results xy_rows 0
       # 2) schedd run
       set test_start $results(0,test_run_time)
       calculate_schedd_run_xy_rows schedd xy_rows $test_start 0
       # 3) job submit times and job run times
       calculate_submit_run_xy_rows jobs xy_rows $test_start 0

       # 4) optional: calculate project times 
       if { $throughput_sharetree == 1 }  {
          calculate_project_run_xy_rows results jobs xy_rows 0
       }

       set plot_data(xlabel) "time\[s\]"
       set plot_data(ylabel) "values"

       set plot_data(title) "Throughput test results - running jobs"
       set plot_data(output_file) "$output_dir/running_jobs.gif"
       set xy_rows(0,show)  1     ;# running jobs
       set xy_rows(1,show)  0     ;# pending jobs
       set xy_rows(2,show)  0     ;# jobs done
       set xy_rows(3,show)  0     ;# jobs subitted
       set xy_rows(4,show)  1     ;# total system slots
       set xy_rows(5,show)  1     ;# free system slots
       set xy_rows(6,show)  0     ;# schedduler calculation time
       set xy_rows(7,show)  0     ;# schedd orders
       set xy_rows(8,show)  0     ;# job submit time
       set xy_rows(9,show)  0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution
       set xy_rows(11,show) 0     ;# running jobs project 1
       set xy_rows(12,show) 0     ;# running jobs project 2
       set xy_rows(13,show) 0     ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows
        


       set plot_data(title) "Throughput test results - pending jobs"
       set plot_data(output_file) "$output_dir/pending_jobs.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 1     ;# pending jobs
       set xy_rows(2,show) 1     ;# jobs done
       set xy_rows(3,show) 1     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0    ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - schedd calculation time"
       set plot_data(output_file) "$output_dir/schedd_calc_time.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 1     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - schedd orders"
       set plot_data(output_file) "$output_dir/schedd_orders.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 1     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - job times"
       set plot_data(output_file) "$output_dir/job_times.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 1     ;# job submit time
       set xy_rows(9,show) 1     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - job distribution"
       set plot_data(output_file) "$output_dir/job_distribution.gif"
       set plot_data(xlabel) "job time\[s\]"
       set plot_data(ylabel) "number of jobs"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 1    ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows


       if { $throughput_sharetree == 1 }  {
         set plot_data(xlabel) "time\[s\]"
         set plot_data(ylabel) "jobs done\[%\]"
         set plot_data(title) "Throughput test results - project jobs"
         set plot_data(output_file) "$output_dir/project_jobs.gif"
         set xy_rows(0,show)  0     ;# running jobs
         set xy_rows(1,show)  0     ;# pending jobs
         set xy_rows(2,show)  0     ;# jobs done
         set xy_rows(3,show)  0     ;# jobs subitted
         set xy_rows(4,show)  0     ;# total system slots
         set xy_rows(5,show)  0     ;# free system slots
         set xy_rows(6,show)  0     ;# schedduler calculation time
         set xy_rows(7,show)  0     ;# schedd orders
         set xy_rows(8,show)  0     ;# job submit time
         set xy_rows(9,show)  0     ;# job run time
         set xy_rows(10,show) 0     ;# job distribution
         set xy_rows(11,show) 1     ;# running jobs project 1
         set xy_rows(12,show) 1     ;# running jobs project 2
         set xy_rows(13,show) 1     ;# running jobs project 3
         create_gnuplot_xy_gif plot_data xy_rows
       }
}


proc calculate_schedd_run_xy_rows { results_array_name row_array_name test_start start_numb } {
   global ts_config
   
   upvar $results_array_name schedd
   upvar $row_array_name xy_rows


   set add_info " A"
   if { $start_numb != 0 } {
      set add_info " B"
   }

       set pos1 [ expr ( $start_numb + 6 ) ]
       set pos2 [ expr ( $start_numb + 7 ) ]

        #  2) schedd run
       if { $schedd(count) > 0 } {
          set xy_rows($pos1,drawmode) "lines"
          set xy_rows($pos1,title) "schedduler calculation time $add_info"

          set xy_rows($pos2,drawmode) "lines"
          set xy_rows($pos2,title) "schedd orders $add_info"

          set last $schedd(count)
          # core data: job_run_time
          for { set i 0 } { $i <= $last } { incr i 1 } {
             set x_time        [ expr ( $schedd($i,system_time) - $test_start) ]  ;# test run time in seconds
             
             #   x->time y->schedd_time
             set xy_rows($pos1,$i,x) $x_time
             set xy_rows($pos1,$i,y) $schedd($i,schedd_time)

             #   x->time y->schedd_orders
             set xy_rows($pos2,$i,x) $x_time
             set xy_rows($pos2,$i,y) $schedd($i,schedd_orders)

          }
       }
   
   
}
proc calculate_submit_run_xy_rows { results_array_name row_array_name test_start start_numb} {
   global ts_config

   upvar $results_array_name jobs
   upvar $row_array_name xy_rows

   set pos1 [ expr ( $start_numb + 8 ) ]
   set pos2 [ expr ( $start_numb + 9 ) ]
   set pos3 [ expr ( $start_numb + 10) ]

   set add_info " A"
   if { $start_numb != 0 } {
      set add_info " B"
   }


       #  3) job submit times and job run times
       set xy_rows($pos1,drawmode) "points"
       set xy_rows($pos1,title) "job submit time $add_info"

       set xy_rows($pos2,drawmode) "points"
       set xy_rows($pos2,title) "job run time $add_info"
 
       set xy_rows($pos3,drawmode) "linespoints" ;#"points"
       set xy_rows($pos3,title) "job run time distribution $add_info"


       set job 0

       set min_run_time 100000
       set max_run_time 0
       if { [info exists run_time_values ] } {
          unset run_time_values
       }       
       while { [info exists jobs($job,job_id) ] } {

          set normalized_submit_end_time [ expr ( $jobs($job,submit_end_time) - $test_start ) ]
          set normalized_run_end_time    [ expr ( $jobs($job,run_end_time)    - $test_start ) ]

          #set submit_time [ expr ( $jobs($job,submit_end_time) - $jobs($job,submit_start_time) ) ]
          set submit_time [expr $jobs($job,submit_time) / 1000.0]
          set run_time    [ expr ( $jobs($job,run_end_time)    - $jobs($job,run_start_time)    ) ]                    

          #   x->time y->submit_time
          set xy_rows($pos1,$job,x) $normalized_submit_end_time
          set xy_rows($pos1,$job,y) $submit_time

          #   x->time y->run_time
          set xy_rows($pos2,$job,x) $normalized_run_end_time
          set xy_rows($pos2,$job,y) $run_time
          if { $min_run_time > $run_time } {
             set min_run_time $run_time
          }
          if { $max_run_time < $run_time } {
             set max_run_time $run_time
          }
          if { [info exists run_time_values($run_time)] } {
             incr run_time_values($run_time) 1
          } else {
             set run_time_values($run_time) 1
          }
          incr job 1
       }
   
       set counter 0
       for { set i $min_run_time } { $i <= $max_run_time } { incr i 1 } {
          if { [ info exists run_time_values($i)] } {
             #   x->job time y->number of jobs with that runtime
             set xy_rows($pos3,$counter,x) $i
             set xy_rows($pos3,$counter,y) $run_time_values($i)
             incr counter 1
          }
       }
}


proc calculate_project_run_xy_rows { results_array_name job_array_name row_array_name start_numb } {
   global ts_config

   global CHECK_OUTPUT
   upvar $results_array_name results
   upvar $job_array_name jobs
   upvar $row_array_name xy_rows

   set pos1 [ expr ( $start_numb + 11 ) ]
   set pos2 [ expr ( $start_numb + 12 ) ]
   set pos3 [ expr ( $start_numb + 13 ) ]

   set add_info " A"
   if { $start_numb != 0 } {
      set add_info " B"
   }


       if { $results(count) > 0 } {
          set xy_rows($pos1,drawmode) "lines"
          set xy_rows($pos1,title) "running jobs project1 (32 %) $add_info"

          set xy_rows($pos2,drawmode) "lines"
          set xy_rows($pos2,title) "running jobs project2 (48 %) $add_info"

          set xy_rows($pos3,drawmode) "lines"
          set xy_rows($pos3,title) "running jobs project3 (20 %) $add_info"

          set last $results(count)
          incr last -1

          set test_start $results(0,test_run_time)

          set job 0
          set jobs_p1 0
          set jobs_p2 0
          set jobs_p3 0
          set help_list ""
          while { [info exists jobs($job,job_id) ] } {

             set normalized_run_end_time    [ expr ( $jobs($job,run_end_time) - $test_start ) ]
             set job_project $jobs($job,project)

             if { [info exists help($normalized_run_end_time,p1)] == 0 } {
                set help($normalized_run_end_time,p1) 0
             }
             if { [info exists help($normalized_run_end_time,p2)] == 0 } {
                set help($normalized_run_end_time,p2) 0
             }
             if { [info exists help($normalized_run_end_time,p3)] == 0 } {
                set help($normalized_run_end_time,p3) 0
             }

             if { $job_project == 1 } {
                
                incr help($normalized_run_end_time,p1) 1
             }
             if { $job_project == 2 } {
                incr help($normalized_run_end_time,p2) 1

             }
             if { $job_project == 3 } {
                incr help($normalized_run_end_time,p3) 1
             }
             if { [lsearch $help_list $normalized_run_end_time] < 0  } {
                lappend help_list $normalized_run_end_time
             }
             incr job 1
          }
          set all_jobs $job

          set job 0
          set help_sort [lsort -integer $help_list]
          set jobs_p1 0
          set jobs_p2 0
          set jobs_p3 0

          foreach elem $help_sort {
             incr jobs_p1 $help($elem,p1)
             incr jobs_p2 $help($elem,p2)
             incr jobs_p3 $help($elem,p3)
             set current_job_count [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3 ) ]

             set one_percent [ expr ( $current_job_count / 100.00 ) ]
             set p1_p [ expr ( $jobs_p1 / $one_percent ) ]
             set p2_p [ expr ( $jobs_p2 / $one_percent ) ]
             set p3_p [ expr ( $jobs_p3 / $one_percent ) ]

             #puts $CHECK_OUTPUT $elem
             # project 1
             set xy_rows($pos1,$job,x) $elem
             set xy_rows($pos1,$job,y) $p1_p
             # project 2
             set xy_rows($pos2,$job,x) $elem 
             set xy_rows($pos2,$job,y) $p2_p
             # project 3
             set xy_rows($pos3,$job,x) $elem 
             set xy_rows($pos3,$job,y) $p3_p
             incr job 1
          }
          #puts $CHECK_OUTPUT "all_jobs=$all_jobs, [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3 ) ]"
          if { [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3 ) ] != $all_jobs } {
             add_proc_error "calculate_project_run_xy_rows" -1 "error job count all_jobs=$all_jobs, not [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3 ) ]"
          }

# ---          for { set i 0 } { $i <= $last } { incr i 1 } {
# ---             set x_time        [ expr ( $results($i,test_run_time) - $test_start) ]  ;# test run time in seconds
# ---            
# ---             set jobs_p1 0
# ---             set jobs_p2 0
# ---             set jobs_p3 0
# ---             foreach jb $running_job_ids {
# ---                set sub_id [get_submit_id_from_job_id jobs $jb]
# ---                set job_project $jobs($sub_id,project)
# ---                if { $job_project == 1 } {
# ---                   incr jobs_p1 1
# ---                }
# ---                if { $job_project == 2 } {
# ---                   incr jobs_p2 1
# ---                }
# ---                if { $job_project == 3 } {
# ---                   incr jobs_p3 1
# ---                }
# ---             }
# ---
# ---             if { [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3  ) ] != $results($i,jobs_running)  } {
# ---                add_proc_error "calculate_project_run_xy_rows" -1 "error: number of running jobs sum error"
# ---             }
# ---             set one_percent [ expr ( (0.000 + $results($i,jobs_running)) / 100 ) ]
# ---             set p1_p [ expr ( $jobs_p1 *  $one_percent  ) ]
# ---             set p2_p [ expr ( $jobs_p2 *  $one_percent  ) ]
# ---             set p3_p [ expr ( $jobs_p3 *  $one_percent  ) ]
# ---
# ---
# ---             # project 1
# ---             set xy_rows($pos1,$pro_pos_1,x) $x_time
# ---             set xy_rows($pos1,$pro_pos_1,y) $p1_p ;# $results($i,jobs_running)
# ---             incr pro_pos_1 1
# ---
# ---             # project 2
# ---             set xy_rows($pos2,$pro_pos_2,x) $x_time
# ---             set xy_rows($pos2,$pro_pos_2,y) $p2_p ;# $results($i,jobs_running)
# ---             incr pro_pos_2 1
# ---
# ---             # project 3
# ---             set xy_rows($pos3,$pro_pos_3,x) $x_time
# ---             set xy_rows($pos3,$pro_pos_3,y) $p3_p ;# $results($i,jobs_running)
# ---             incr pro_pos_3 1
# ---          }
       }
}



proc calculate_test_run_xy_rows { results_array_name row_array_name start_numb } {
   global ts_config

   upvar $results_array_name results
   upvar $row_array_name xy_rows

   set pos1 $start_numb 
   set pos2 [ expr ( $start_numb + 1 ) ]
   set pos3 [ expr ( $start_numb + 2 ) ]
   set pos4 [ expr ( $start_numb + 3 ) ]
   set pos5 [ expr ( $start_numb + 4 ) ]
   set pos6 [ expr ( $start_numb + 5 ) ]

   set add_info " A"
   if { $start_numb != 0 } {
      set add_info " B"
   }


   #  1) test run
       if { $results(count) > 0 } {
          set xy_rows($pos1,drawmode) "lines"
          set xy_rows($pos1,title) "running jobs $add_info"

          set xy_rows($pos2,drawmode) "lines"
          set xy_rows($pos2,title) "pending jobs $add_info"

          set xy_rows($pos3,drawmode) "lines"
          set xy_rows($pos3,title) "jobs done $add_info"

          set xy_rows($pos4,drawmode) "lines"
          set xy_rows($pos4,title) "jobs subitted $add_info"

          set xy_rows($pos5,drawmode) "lines"
          set xy_rows($pos5,title) "total system slots $add_info"

          set xy_rows($pos6,drawmode) "lines"
          set xy_rows($pos6,title) "free system slots $add_info"


          set last $results(count)
          incr last -1

          set test_start $results(0,test_run_time)
          # core data: job_run_time
          for { set i 0 } { $i <= $last } { incr i 1 } {
             set x_time        [ expr ( $results($i,test_run_time) - $test_start) ]  ;# test run time in seconds
             
             #   x->time y->jobs_running                                 
             set xy_rows($pos1,$i,x) $x_time
             set xy_rows($pos1,$i,y) $results($i,jobs_running)

             #   x->time y->jobs_pending
             set xy_rows($pos2,$i,x) $x_time
             set xy_rows($pos2,$i,y) $results($i,jobs_pending)

             #   x->time y->jobs_done
             set xy_rows($pos3,$i,x) $x_time
             set xy_rows($pos3,$i,y) $results($i,jobs_done)

             #   x->time y->jobs_submitted
             set xy_rows($pos4,$i,x) $x_time
             set xy_rows($pos4,$i,y) $results($i,jobs_submitted)

             #   x->time y->total_slots
             set xy_rows($pos5,$i,x) $x_time
             set xy_rows($pos5,$i,y) $results($i,total_slots)

             #   x->time y->free_slots
             set xy_rows($pos6,$i,x) $x_time
             set xy_rows($pos6,$i,y) $results($i,free_slots)
          }
       }
   
}

proc create_reports { results_array job_array_name schedd_array_name} {
   global ts_config
   global ts_host_config
   global CHECK_OUTPUT CHECK_PROTOCOL_DIR check_name throughput_subdir
   global CHECK_HOST CHECK_USER
   global end_job_count                 ;# number of jobs
   global enable_queues_job_count         ;# after with job, enable queues
   global nr_queues                       ;# nr of queues on each host
   global nr_slots
   global global_job_run_time            ;# job sleep parameter
   global FLUSH_SUBMIT_SEC              ;# -1 or 0,1,2,3 ...
   global FLUSH_FINISH_SEC             ;# -1 or 0,1,2,3 ...
   global run_throughput_test_SCHEDULE_INTERVAL        ;# 00:00:30 ...

   upvar $job_array_name jobs
   upvar $results_array results
   upvar $schedd_array_name schedd

   set nr_of_execd_hosts [llength $ts_config(execd_hosts)]
   incr nr_of_execd_hosts -1

   set have_local_spool_dir 0
   foreach elem $ts_config(execd_hosts) {
      set spool_dir ""
      if { [info exists ts_host_config($elem,spooldir)] } {
         set spool_dir $ts_host_config($elem,spooldir)
      }
      puts $CHECK_OUTPUT "spooldir on host $elem: $spool_dir"
      if { $spool_dir != "" } {
         set have_local_spool_dir 1
      }
   }
  
   if { $have_local_spool_dir == 1 } {
      set prot_output_dir "$CHECK_PROTOCOL_DIR/$check_name/$throughput_subdir/local_spool/_${nr_of_execd_hosts}_execds/_${end_job_count}_jobs"

   } else {
      set prot_output_dir "$CHECK_PROTOCOL_DIR/$check_name/$throughput_subdir/_${nr_of_execd_hosts}_execds/_${end_job_count}_jobs"

   }

   puts $CHECK_OUTPUT "saving report in directory:"
   puts $CHECK_OUTPUT $prot_output_dir
   file mkdir $prot_output_dir

   set files [get_file_names $prot_output_dir "saved_run*"]
   # saved_run.x
   set run_nr 1
   foreach file $files {
      puts $CHECK_OUTPUT "file: $file"
      set act_run [file extension $file]
      set act_run [string range $act_run 1 end]
      puts $CHECK_OUTPUT "act-run: $act_run"
      if { [ string is integer $act_run ] } {
      if { $act_run >= $run_nr } {
         set run_nr $act_run
         incr run_nr 1
      }
      }
   } 
   set prot_output_file "${prot_output_dir}/saved_run.${run_nr}"
   puts $CHECK_OUTPUT "using filename:"
   puts $CHECK_OUTPUT $prot_output_file


   # execd configuration for each host
   set host_list $ts_config(execd_hosts)
   lappend host_list "global"
   set h_list_array(host_list) $host_list
   spool_array_to_file $prot_output_file "execd list" h_list_array

   set nr_of_local_spool_directories 0
   foreach execd $host_list {
      get_exechost execd_array $execd
      spool_array_to_file $prot_output_file "execd $execd" execd_array
      unset execd_array

      get_config config_array $execd
      spool_array_to_file $prot_output_file "config execd $execd" config_array
      if { [info exists config_array(execd_spool_dir)] } {
         incr nr_of_local_spool_directories 1
      }
      unset config_array
   }
   
   # save scheduler configuration into file
   get_schedd_config schedd_config
   spool_array_to_file $prot_output_file "schedd config" schedd_config

   # set test configuration
   set test_config(end_job_count)           $end_job_count            ;# number of jobs
   set test_config(enable_queues_job_count) $enable_queues_job_count  ;# after with job, enable queues
   set test_config(nr_queues)               $nr_queues                ;# nr of queues on each host
   set test_config(nr_slots_per_queue)      $nr_slots                 ;# nr of slots per queue
   set test_config(global_job_run_time)     $global_job_run_time      ;# job sleep parameter
   set test_config(FLUSH_SUBMIT_SEC)        $FLUSH_SUBMIT_SEC         ;# -1 or 0,1,2,3 ...
   set test_config(FLUSH_FINISH_SEC)        $FLUSH_FINISH_SEC         ;# -1 or 0,1,2,3 ...
   set test_config(SCHEDULE_INTERVAL)       $run_throughput_test_SCHEDULE_INTERVAL        ;# 00:00:30 ...
   set test_config(gridengine_version)      [get_version_info]
   set test_config(test_date)               [exec date]
   
   spool_array_to_file $prot_output_file "test configuration" test_config

   # spool everything to file (without comment line)
   spool_array_to_file $prot_output_file "online data"    results 0
   spool_array_to_file $prot_output_file "job data"       jobs    0
   spool_array_to_file $prot_output_file "scheduler data" schedd  0

   catch { file delete ${prot_output_file}.old }

   # job results
   calculate_average_cluster_times results cluster_results
   puts $CHECK_OUTPUT "total run time     : $cluster_results(total_run_time)"
   puts $CHECK_OUTPUT "total jobs done    : $cluster_results(total_jobs_done)"
   puts $CHECK_OUTPUT "total submit time  : $cluster_results(total_submit_time)"
   puts $CHECK_OUTPUT "submits per second : $cluster_results(submits_per_second)"
   puts $CHECK_OUTPUT "jobs per second    : $cluster_results(jobs_per_second)"
   puts $CHECK_OUTPUT "avg. slots free    : $cluster_results(avg_slots_free)"
   puts $CHECK_OUTPUT "total slots        : $cluster_results(total_slots)"
   puts $CHECK_OUTPUT "utilization        : $cluster_results(utilization)"
   puts $CHECK_OUTPUT "job sleep time     : $cluster_results(jobs_sleep_time)"
   puts $CHECK_OUTPUT "queue enable value : $cluster_results(queue_enable_value)"
   puts $CHECK_OUTPUT "flush submit sec   : $cluster_results(flush_submit_sec)"
   puts $CHECK_OUTPUT "flush finish sec   : $cluster_results(flush_finish_sec)"
   puts $CHECK_OUTPUT "schedule interval  : $cluster_results(schedule_interval)"


   calculate_average_job_times jobs avg_values
   puts $CHECK_OUTPUT ""
   puts $CHECK_OUTPUT "avg. submit       (count=$avg_values(jobs_submit))   : $avg_values(avg_submit) "
   puts $CHECK_OUTPUT "avg. run/transfer (count=$avg_values(jobs_run))   : $avg_values(avg_run)    "

   calculate_average_schedd_times schedd avg_schedd_values
   puts $CHECK_OUTPUT ""
   puts $CHECK_OUTPUT "avg. schedd time (count=$avg_schedd_values(nr_of_schedd_runs))   : $avg_schedd_values(avg_schedd_time)"

   analyse_dump_data_file $prot_output_file 1
   compare_dump_directory $prot_output_dir
#   puts $CHECK_OUTPUT "do gzip $prot_output_file ..."
#   puts $CHECK_OUTPUT [start_remote_prog $CHECK_HOST $CHECK_USER gzip $prot_output_file prg_exit_state 60 0 "" 1 0 0]
   
   
}

proc calculate_average_cluster_times { results_array cluster_results_array { dump_file "" } } {
   global ts_config

   global CHECK_OUTPUT enable_queues_job_count
   global FLUSH_SUBMIT_SEC FLUSH_FINISH_SEC run_throughput_test_SCHEDULE_INTERVAL
   upvar $results_array cluster
   upvar $cluster_results_array result

   set result(total_run_time)    0    ;#
   set result(total_jobs_done)   0    ;#
   set result(total_submit_time) 0    ;#
   set result(submits_per_second) 0   ;#
   set result(jobs_per_second) 0      ;#
   set result(utilization) 0          ;#
   set result(jobs_sleep_time)  0      ;#
   set result(queue_enable_value) $enable_queues_job_count    ;#
   set result(flush_submit_sec) $FLUSH_SUBMIT_SEC
   set result(flush_finish_sec) $FLUSH_FINISH_SEC
   set result(schedule_interval) $run_throughput_test_SCHEDULE_INTERVAL

   if { $cluster(count) > 0 } {
      set result(avg_slots_free)    $cluster(0,total_slots)  ;# avg_slots_free
      set result(total_slots)       $cluster(0,total_slots)     ;# total_slots
      set result(jobs_sleep_time)   $cluster(0,job_run_time) ;#
   } else {
      set result(avg_slots_free) 0
      set result(total_slots) 0
      return -1
   }

   if { $dump_file != "" } {
      set dump_file [open $dump_file w]
      
      puts $dump_file "nr|jobs_done|jobs_running|jobs_pending|jobs_submitted|total_slots|free_slots|job_run_time|test_run_time"
   }
   
   set last $cluster(count)
   incr last -1

   # calculate
   set result(total_run_time)    [ expr ($cluster($last,test_run_time)  - $cluster(0,test_run_time) ) ]
   set result(total_jobs_done)   $cluster($last,jobs_done)

   # pass 1
   set highest_submit_count 0
   set samples 0
   set sum_free_slots [expr double(0)]
   for { set i 0 } { $i <= $last } { incr i 1 } {
      if { $cluster($i,jobs_submitted) > $highest_submit_count } {
         set highest_submit_count $cluster($i,jobs_submitted)
      
      }
      # utilization (free jobs) will only be taken into account while
      # - queues are enabled
      # - there are pending jobs
      if { $cluster($i,queues_enabled) == 1 && $cluster($i,jobs_pending) > 0 } {
         set sum_free_slots [expr $sum_free_slots + double($cluster($i,free_slots))]
         incr samples
         # puts $CHECK_OUTPUT "$samples\t$sum_free_slots"
      }
      # spool data to file
      if { $dump_file != "" } {
         set line "$i|$cluster($i,jobs_done)|$cluster($i,jobs_running)|$cluster($i,jobs_pending)|$cluster($i,jobs_submitted)|$cluster($i,total_slots)|$cluster($i,free_slots)|$cluster($i,job_run_time)|$cluster($i,test_run_time)"
         puts $dump_file $line
      }
   }

   if { $dump_file != "" } {
      close $dump_file
   }

   if { $samples > 0 } {
      set result(avg_slots_free) [ expr $sum_free_slots / double($samples) ]
   }

   # pass 2
   for { set i $last } { $i >= 0 } { incr i -1 } {
      if { $cluster($i,jobs_submitted) == $highest_submit_count } {
         # this is the last submit job
         set result(total_submit_time) [ expr ($cluster($i,test_run_time)  - $cluster(0,test_run_time) ) ]
      }
   }
   
   if { $result(total_submit_time) > 0 } { 
      set result(submits_per_second) [ expr ( ${highest_submit_count}.00 / $result(total_submit_time) ) ]
   }

   if { $result(total_run_time) > 0 } {
      set result(jobs_per_second) [ expr ( $result(total_jobs_done).00 / $result(total_run_time) ) ]
   }

   set result(utilization) [ expr 100.0 * (double($result(total_slots)) - $result(avg_slots_free)) / double($result(total_slots)) ]
   puts $CHECK_OUTPUT "total_slots    = $result(total_slots)"
   puts $CHECK_OUTPUT "avg_slots_free = $result(avg_slots_free)"


#   puts $CHECK_OUTPUT ""
#   puts $CHECK_OUTPUT "total run time     : $result(total_run_time)"
#   puts $CHECK_OUTPUT "total jobs done    : $result(total_jobs_done)"
#   puts $CHECK_OUTPUT "total submit time  : $result(total_submit_time)"
#   puts $CHECK_OUTPUT "submits per second : $result(submits_per_second)"
#   puts $CHECK_OUTPUT "jobs per second    : $result(jobs_per_second)"
#   puts $CHECK_OUTPUT "avg. slots free    : $result(avg_slots_free)"
#   puts $CHECK_OUTPUT "total slots        : $result(total_slots)"
#   puts $CHECK_OUTPUT "utilization        : $result(utilization)"
#   puts $CHECK_OUTPUT "job sleep time     : $result(jobs_sleep_time)"
#   puts $CHECK_OUTPUT "queue enable value : $result(queue_enable_value)"
#   puts $CHECK_OUTPUT "flush submit sec   : $result(flush_submit_sec)"
#   puts $CHECK_OUTPUT "flush finish sec   : $result(flush_finish_sec)"
#   puts $CHECK_OUTPUT "schedule interval  : $result(schedule_interval)"
   return 0
}

proc calculate_average_job_times { job_array_name job_results_array { dump_file "" }} {
   global ts_config

   global CHECK_OUTPUT
   upvar $job_array_name jobs
   upvar $job_results_array result
   
   set submit_sum [expr double(0)]
   set run_sum [expr double(0)]
   set submit_job_count  0
   set run_job_count 0
   set job 0
   if { $dump_file != "" } {
      set dump_file [open $dump_file w]
      puts $dump_file "nr|jobid|submit_time|run_time|state|submit_start|submit_finish|run_start|run_finish"
   }
   while { [info exists jobs($job,job_id) ] } {
      set submit_time 0
      set run_time 0
      if { $jobs($job,submit_end_time) > 0 && $jobs($job,submit_start_time) > 0 } {
         incr submit_job_count 1
         #set submit_time [ expr ( $jobs($job,submit_end_time) - $jobs($job,submit_start_time) ) ]
         set submit_time [expr double($jobs($job,submit_time)) / 1000.0]
      }
      if { $jobs($job,run_end_time) > 0 && $jobs($job,run_start_time) > 0 } {
         incr run_job_count 1
         set run_time    [ expr ( $jobs($job,run_end_time)    - $jobs($job,run_start_time)    ) ]
#         puts $CHECK_OUTPUT "job_run_time: $run_time"
      }
      set job_id $jobs($job,job_id)

      # add job times
      set submit_sum [expr $submit_sum + $submit_time]
      set run_sum [expr $run_sum + double($run_time)]

      # spool data to file
      if { $dump_file != "" } {
         set line "$job|$jobs($job,job_id)|$submit_time|$run_time|$jobs($job,state)|$jobs($job,submit_start_time)|$jobs($job,submit_end_time)|$jobs($job,run_start_time)|$jobs($job,run_end_time)"
         puts $dump_file $line
      }
      incr job 1
   }
   if { $dump_file != "" } {
      close $dump_file
   }

   # calculate average
   set result(avg_submit)  0                       ;# avg submit time in seconds
   set result(avg_run)     0                       ;# avg run time in seconds
   set result(jobs_submit) $submit_job_count
   set result(jobs_run)    $run_job_count
   if { $submit_job_count > 0 } {
      set result(avg_submit) [ expr ${submit_sum} / double($submit_job_count) ]
   }
   if { $run_job_count > 0 } {
      set result(avg_run)    [ expr ${run_sum} / double($run_job_count) ]
   }
}


proc calculate_average_schedd_times { schedd_array_name schedd_results_array { dump_file "" }} {
   global ts_config

   global CHECK_OUTPUT
   upvar $schedd_array_name schedd_array
   upvar $schedd_results_array result
   
   set schedd 0
   set schedd_time_sum 0
   if { $dump_file != "" } {
      set dump_file [open $dump_file w]
      puts $dump_file "nr|system_time|schedd_time|schedd_orders"
   }

   while { [info exists schedd_array($schedd,schedd_time) ] } {
      set schedd_id_run_time $schedd_array($schedd,schedd_time)

      # add schedd times
      set schedd_time_sum [ expr ( $schedd_time_sum + $schedd_id_run_time ) ]

      if { $dump_file != "" } {
         set line "$schedd|$schedd_array($schedd,system_time)|$schedd_array($schedd,schedd_time)|$schedd_array($schedd,schedd_orders)"
         puts $dump_file $line
      }

      incr schedd 1
   }

   if { $dump_file != "" } {
      close $dump_file
   }


   # calculate average
   set result(avg_schedd_time) 0
   set result(nr_of_schedd_runs) $schedd
   if { $schedd > 0 } {
      set result(avg_schedd_time) [ expr (  ( ($schedd_time_sum + 0.00 ) ) / $schedd ) ]
   }
}


proc show_current_system_status { array_name job_array_name schedd_array_name } {
   global ts_config

   global CHECK_OUTPUT

   upvar $array_name data
   upvar $job_array_name jobs
   upvar $schedd_array_name schedd

   # string for queue status
   if { $data(queues_enabled) == 1 } {
      set queue_status "enabled"
   } else {
      set queue_status "disabled"
   }

   clear_screen
   puts $CHECK_OUTPUT "queue status     : $queue_status"
   puts $CHECK_OUTPUT "jobs_done        : $data(jobs_done)" 
   puts $CHECK_OUTPUT "jobs_running     : $data(jobs_running)"
   puts $CHECK_OUTPUT "jobs_pending     : $data(jobs_pending)"
   puts $CHECK_OUTPUT "jobs_submitted   : $data(jobs_submitted)"
   puts $CHECK_OUTPUT "total slots      : $data(total_slots)"
   puts $CHECK_OUTPUT "free slots       : $data(free_slots)"
   puts $CHECK_OUTPUT "jobs run time    : $data(job_run_time)"
   puts $CHECK_OUTPUT "test run time    : $data(test_run_time)"
   puts $CHECK_OUTPUT "last schedd time : $schedd($schedd(count),schedd_time)"
   puts $CHECK_OUTPUT ""

   # check data
   if { [ expr ( $data(jobs_done) + $data(jobs_running) + $data(jobs_pending) )  ] != $data(jobs_submitted) } {
      add_proc_error "show_current_system_status" -1 "unexpected job count error"
   }
   flush $CHECK_OUTPUT
}

proc clean_current_system_status { results_array array_name job_array_name schedd_array_name } {
   global ts_config

   global queue_list global_job_run_time nr_slots
   upvar $results_array results
   upvar $array_name data
   upvar $job_array_name jobs
   upvar $schedd_array_name schedd

   set data(jobs_done) 0
   set data(jobs_pending) 0
   set data(jobs_running) 0
   set data(jobs_submitted) 0
   set data(total_slots) [ expr ( [llength $queue_list] * $nr_slots ) ]
   set data(free_slots)  $data(total_slots)
   set data(job_run_time) $global_job_run_time
   set data(test_run_time) 0

   if { [ info exists jobs] } {
      unset jobs
   }
   if { [ info exists results] } {
      unset results
   }
   if { [ info exists schedd] } {
      unset schedd
   }
   set schedd(0,system_time) 0
   set schedd(0,schedd_time) 0
   set schedd(0,schedd_orders) 0
   
   set schedd(count) 0
   set results(count) 0
}
