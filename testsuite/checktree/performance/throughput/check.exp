#!/vol2/TCL_TK/glinux/bin/expect --
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2001 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__

# Define the global veriables to give them back
global check_name check_description check_needs check_functions check_errno check_errstr check_highest_level
global check_init_level_procedure check_category

set check_init_level_procedure "init_level"
set check_category            "PERFORMANCE"
set check_name                "throughput"
set check_description(0)      "Functional test"
set check_description(1)      "Functional test with sharetree (only sgeee)"
set check_description(100)    "test"
set check_description(101)    "with sharetree (only sgeee)"

set check_needs               "init_core_system"      ;# dependencies of this check (name of other check)

set check_functions           ""
lappend check_functions       "setup_queues"          ;# functions to call (in order)
lappend check_functions       "run_throughput_test"
lappend check_functions       "cleanup_queues"
#set check_functions          "compare_dump_data_file"

set check_highest_level       101

global nr_queues  nr_slots
global queue_list
global host_list
global enable_queues_job_count 
global end_job_count
global event_client_bin
global global_job_run_time
global stored_configuration FLUSH_SUBMIT_SEC FLUSH_FINISH_SEC run_throughput_test_SCHEDULE_INTERVAL
global throughput_subdir
global throughput_sharetree

set queue_list ""
set host_list ""
set event_client_bin ""
set throughput_subdir ""

proc init_level {} {
    global CHECK_ACT_LEVEL CHECK_PRODUCT_TYPE
    global end_job_count                      ;# number of jobs
    global enable_queues_job_count             ;# after with job, enable queues
    global nr_queues                            ;# nr of queues on each host
    global nr_slots                            ;# nr of slots on each queue
    global global_job_run_time                  ;# job sleep parameter
    global FLUSH_SUBMIT_SEC                    ;# -1 or 0,1,2,3 ...
    global FLUSH_FINISH_SEC                    ;# -1 or 0,1,2,3 ...
    global run_throughput_test_SCHEDULE_INTERVAL             ;# 00:00:30 ...
    global throughput_subdir             ;# subdirectory in protocols/throughput/
    global throughput_sharetree


    # paramters for all tests
    set run_throughput_test_SCHEDULE_INTERVAL        00:00:15
    set global_job_run_time      5            ;# job sleep parameter
    set nr_queues                10            ;# nr of queues on each host
    set nr_slots                 5           ;# nr of slots on each queue
    set enable_queues_job_count  0         ;# after witch job, enable queues

    # TODO setup levels 
  switch -- $CHECK_ACT_LEVEL {
     "0"  { 
        set end_job_count            100         ;# number of jobs
        set FLUSH_SUBMIT_SEC         0             ;# -1 or 0,1,2,3 ...
        set FLUSH_FINISH_SEC         0             ;# -1 or 0,1,2,3 ...
        set throughput_sharetree     0
        set throughput_subdir        "functional"
        return 0
     }
     "1"  { 
        set end_job_count            100         ;# number of jobs
        set FLUSH_SUBMIT_SEC         0           ;# -1 or 0,1,2,3 ...
        set FLUSH_FINISH_SEC         0           ;# -1 or 0,1,2,3 ...
        set throughput_sharetree     1
        set throughput_subdir        "functional_sharetree"
        if { $CHECK_PRODUCT_TYPE == "sge" } {
           return -1
        } 
        return 0  
     }
     "100"  { 
        set end_job_count            3000         ;# number of jobs
        set FLUSH_SUBMIT_SEC         0             ;# -1 or 0,1,2,3 ...
        set FLUSH_FINISH_SEC         0             ;# -1 or 0,1,2,3 ...
        set enable_queues_job_count  1500         ;# after witch job, enable queues
        set throughput_sharetree     0
        set throughput_subdir        "functional"
        return 0  
     }
     "101"  { 
        set end_job_count            3000         ;# number of jobs
        set FLUSH_SUBMIT_SEC         0           ;# -1 or 0,1,2,3 ...
        set FLUSH_FINISH_SEC         0           ;# -1 or 0,1,2,3 ...
        set enable_queues_job_count  1500         ;# after witch job, enable queues

        set throughput_sharetree     1
        set throughput_subdir        "functional_sharetree"
        if { $CHECK_PRODUCT_TYPE == "sge" } {
           return -1
        } 
        return 0  
     }
  }
  return -1
}

proc throughput_set_share_tree {} {

   global CHECK_HOST CHECK_OUTPUT

   set s_tree ""  
   lappend s_tree "id=0"
   lappend s_tree "name=Root"
   lappend s_tree "type=0"
   lappend s_tree "shares=1"
   lappend s_tree "childnodes=1,4"
   lappend s_tree "id=1"
   lappend s_tree "name=node1"
   lappend s_tree "type=0"
   lappend s_tree "shares=8000"
   lappend s_tree "childnodes=2,3"
   lappend s_tree "id=2"
   lappend s_tree "name=project1"
   lappend s_tree "type=0"
   lappend s_tree "shares=4000"
   lappend s_tree "childnodes=NONE"
   lappend s_tree "id=3"
   lappend s_tree "name=project2"
   lappend s_tree "type=0"
   lappend s_tree "shares=6000"
   lappend s_tree "childnodes=NONE"
   lappend s_tree "id=4"
   lappend s_tree "name=node2"
   lappend s_tree "type=0"
   lappend s_tree "shares=2000"
   lappend s_tree "childnodes=5"
   lappend s_tree "id=5"
   lappend s_tree "name=project3"
   lappend s_tree "type=0"
   lappend s_tree "shares=10000"
   lappend s_tree "childnodes=NONE"
   return $s_tree
}

proc throughput_setup_sharetree {} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH
   global CHECK_HOST

   puts $CHECK_OUTPUT "setup sharetree ..."

   


   puts $CHECK_OUTPUT "   adding projects ..."
   set prj_setup(name) "project1"
   add_prj prj_setup

   set prj_setup(name) "project2"
   add_prj prj_setup

   set prj_setup(name) "project3"
   add_prj prj_setup

   # setup sharetree
   
   set vi_commands "i" 
   set s_tree [throughput_set_share_tree]
   foreach elem $s_tree {
      lappend vi_commands "${elem}\n"
   } 
   lappend vi_commands [format "%c" 27]
   lappend  vi_commands "dddddddddddd"
   

   set catch_return [ catch {  
      eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf -dstree" 
   } result ] 
 
   set CHANGED_SHARETREE [translate $CHECK_HOST 1 0 0 [sge_macro MSG_TREE_CHANGEDSHARETREE]]
   set CAN_T_READ [translate $CHECK_HOST 1 0 0 [sge_macro MSG_QCONF_CANTREADSHARETREEX_S] "*"]

   set result [ handle_vi_edit "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf" "-astree" $vi_commands $CHANGED_SHARETREE $CAN_T_READ ]  
   if { $result != 0 } {
      add_proc_error "throughput_setup_sharetree" -1 "could not add sharetree (error: $result)"
   }

   get_schedd_config my_config 
   set my_config(weight_tickets_share) "10000"
   set my_config(usage_weight_list)    "cpu=1,mem=0,io=0"
   set my_config(job_load_adjustments) "np_load_avg=0.0"
   set_schedd_config my_config

}
proc throughput_cleanup_sharetree {} {
   global CHECK_OUTPUT CHECK_PRODUCT_ROOT CHECK_ARCH

   puts $CHECK_OUTPUT "cleanup sharetree ..."
   reset_schedd_config

   set catch_return [ catch {  
      eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf -dstree" 
   } result ]

   puts "qconf -dstree result: $result"
   puts "qconf -dstree exit value: $catch_return "


   puts $CHECK_OUTPUT "   removing projects ..."
   del_prj "project1"
   del_prj "project2"
   del_prj "project3"


}

proc setup_queues {} {

   global CHECK_CORE_EXECD CHECK_CORE_MASTER CHECK_OUTPUT
   global CHECK_HOST event_client_bin CHECK_SOURCE_DIR
   global nr_queues queue_list host_list  nr_slots
   global stored_configuration FLUSH_SUBMIT_SEC FLUSH_FINISH_SEC run_throughput_test_SCHEDULE_INTERVAL
   global throughput_sharetree


   if { [llength $CHECK_CORE_EXECD] <= 1 } {
      set_error -3 "need more than one host for this test"
      return -3
   }

   if { [resolve_version] < 2 } {
       set_error -3 "test not supported for version [get_version_info]"
       return -3
   }

   # start event client (if compiled)
   set up_arch [resolve_upper_arch $CHECK_HOST]
   set event_client_bin $CHECK_SOURCE_DIR/$up_arch/qevent
   if { [file isfile $event_client_bin] != 1 } {
      set_error -3 "could not open event client binary: $event_client_bin"
      return -3
   }
   puts $CHECK_OUTPUT "using event client: $event_client_bin"

   

   # setup scheduler configuration
   if { [info exists stored_configuration] } {
      unset stored_configuration
   }
   get_config stored_configuration
      set myconfig(loglevel)         "log_warning"

   set my_schedd_params "PROFILE=1"

   if { [resolve_version] <= 2 } {
      if { [string compare "none" $stored_configuration(schedd_params)] != 0 } {
         append my_schedd_params ",$stored_configuration(schedd_params)"
      }
      if { $FLUSH_SUBMIT_SEC == -1 && $FLUSH_FINISH_SEC == -1 } {
         set myconfig(schedd_params)    "$my_schedd_params"
      } else {
         set myconfig(schedd_params)    "$my_schedd_params,FLUSH_SUBMIT_SEC=${FLUSH_SUBMIT_SEC},FLUSH_FINISH_SEC=${FLUSH_FINISH_SEC}"
      }
   } 
   else{
      get_schedd_config stored_schedd_config
      if { [string compare "none" $stored_schedd_config(params)] != 0 } {
         append my_schedd_params ",$stored_schedd_config(params)"
      }
      set my_schedd_config(params)      "$my_schedd_params"
      if { $FLUSH_SUBMIT_SEC > 0} {
         set my_schedd_config(flush_submit_sec) "$FLUSH_SUBMIT_SEC"
      }
      if { $FLUSH_FINISH_SEC > 0} {
         set my_schedd_config(flush_finish_sec) "$FLUSH_FINISH_SEC"
      }

   } 
   
   set my_execd_params "SHARETREE_RESERVED_USAGE=true"
   if { [string compare "none" $stored_configuration(execd_params)] != 0 } {
      append my_execd_params ",$stored_configuration(execd_params)"
   }
   set myconfig(execd_params) "$my_execd_params"

   set_config myconfig
 
   # disable all default queues and create host_list:
   set host_list ""
   foreach elem $CHECK_CORE_EXECD {
      disable_queue $elem.q
      if { [string compare $elem $CHECK_CORE_MASTER] == 0 } { 
         continue;
      }
      lappend host_list $elem
   }

   set max_u_jobs_parameter [expr ( [llength $host_list] * $nr_queues  * $nr_slots )]

   set my_schedd_config(schedule_interval)    "$run_throughput_test_SCHEDULE_INTERVAL"
   set my_schedd_config(job_load_adjustments) "none"
   set my_schedd_config(schedd_job_info)      "false"
   set my_schedd_config(maxujobs)             $max_u_jobs_parameter 
   set_schedd_config my_schedd_config


   # now setup submit queues for hosts in host_list:
   # set queue_list:
   set queue_list ""
   puts $CHECK_OUTPUT "using following host for throughput test:"
   foreach host $host_list {
      puts $CHECK_OUTPUT "setup queues for host $host"
      for {set i 0} { $i < $nr_queues } { incr i 1 } {
         set change_array(qname) "${host}_m${i}"
         set change_array(hostname) "$host"
         set change_array(slots) $nr_slots
         set change_array(load_thresholds) "np_load_avg=11.75"
         add_queue change_array 1
         lappend queue_list "${host}_m${i}"
      }
   }
   # show queue list:

   puts $CHECK_OUTPUT "using [llength $queue_list] queues to submit jobs"

   if { $throughput_sharetree == 1 } {
      throughput_setup_sharetree
   }

   set_error 0 "ok"
}

proc cleanup_queues {} {
   global CHECK_CORE_EXECD  CHECK_OUTPUT
   global queue_list event_client_bin CHECK_ARCH  CHECK_PRODUCT_ROOT
   global stored_configuration throughput_sharetree

   if { [llength $CHECK_CORE_EXECD] <= 1 } {
      set_error -3 "need more than one host for this test"
      return -3
   }

   if { [resolve_version] < 2 } {
       set_error -3 "test not supported for version [get_version_info]"
       return -3
   }
  
   if { [file isfile $event_client_bin] != 1 } {
      set_error -3 "could not open event client binary: $event_client_bin"
      return -3
   }

   catch {  eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qdel" "-uall" } catch_result


   # after this we can cleanup the system (no jobs registered at qmaster)
   wait_for_end_of_all_jobs 120


   if { $throughput_sharetree == 1 } {
      throughput_cleanup_sharetree
   }


   # reset scheduler configurations
   reset_schedd_config
   set_config stored_configuration

   puts $CHECK_OUTPUT "deleting queues"
   foreach queue $queue_list {
      puts $CHECK_OUTPUT $queue 
      del_queue $queue
   }

   puts $CHECK_OUTPUT "enabling default queues"
   foreach elem $CHECK_CORE_EXECD {
      puts $CHECK_OUTPUT $elem
      enable_queue $elem.q     
   }
   
   set_error 0 "ok"
}
proc get_event_client_time { string  } {
   set ecl_time_start [string first "(" $string]
   incr ecl_time_start 1
   set ecl_time_end [string first ")" $string]
   incr ecl_time_end -1
   set data [string range $string $ecl_time_start $ecl_time_end]
   set data [split $data ":"]
   foreach elem $data {
      set ecl_time_start [string first "ECL_TIME=" $elem]
      if { $ecl_time_start >= 0 } {
         incr ecl_time_start 9
         return [ string range $elem $ecl_time_start end]
      }
   }
   return -1
}

proc run_throughput_test {} {

   global CHECK_OUTPUT CHECK_USER CHECK_PRODUCT_ROOT CHECK_HOST CHECK_ARCH
   global queue_list CHECK_TESTSUITE_ROOT CHECK_SCRIPT_FILE_DIR
   global enable_queues_job_count CHECK_SOURCE_DIR CHECK_CORE_EXECD
   global end_job_count host_list event_client_bin CHECK_FIRST_FOREIGN_SYSTEM_USER
   global throughput_sharetree

   if { [llength $CHECK_CORE_EXECD] <= 1 } {
      set_error -3 "need more than one host for this test"
      return -3
   }

   if { [resolve_version] < 2 } {
       set_error -3 "test not supported for version [get_version_info]"
       return -3
   }


   if { [file isfile $event_client_bin] != 1 } {
      set_error -3 "could not open event client binary: $event_client_bin"
      return -3
   }



   # translate jobs submit output string
   set JOB_SUBMITTED       [translate $CHECK_HOST 1 0 0 [sge_macro MSG_JOB_SUBMITJOB_USS] "*" "*" "*"]
   set JOB_SUBMITTED_DUMMY [translate $CHECK_HOST 1 0 0 [sge_macro MSG_JOB_SUBMITJOB_USS] "__JOB_ID__" "__JOB_NAME__" "__JOB_ARG__"]
   set COULD_NOT_SUBMIT [translate $CHECK_HOST 1 0 0 [sge_macro MSG_QSUB_YOURQSUBREQUESTCOULDNOTBESCHEDULEDDTRYLATER]]


   # start event client (if compiled) 
   set event_client_sid [ open_remote_spawn_process $CHECK_HOST "ts_def_con2" $event_client_bin ""]
   set event_client_id [lindex $event_client_sid 1]

   set timeout 30
   set is_old_version 0

   while { 1 } {
      expect {
         -i $event_client_id full_buffer {
            add_proc_error "run_throughput_test" -1 "expect full_buffer error (3)"
            return -1
         }
         -i $event_client_id timeout {
            puts $CHECK_OUTPUT "timeout starting event client"
            break;
         }
         -i $event_client_id eof {
            puts $CHECK_OUTPUT "eof from event client"
            break;
         }
         -i $event_client_id "ECL_STATE" {
            puts $CHECK_OUTPUT "old qevent version"
            set is_old_version 1
            break;
         }
         -i $event_client_id -- "ts|*testsuite" {
            puts $CHECK_OUTPUT "new qevent version"
            set is_old_version 0
            break;
         }
       }
   }

   if { $is_old_version == 0 } {
      close_spawn_process $event_client_sid
      puts $CHECK_OUTPUT "starting event client with -ts option ..."
      # start event client with -ts option
      set event_client_sid [ open_remote_spawn_process $CHECK_HOST "ts_def_con2" $event_client_bin "-ts"]
      set event_client_id [lindex $event_client_sid 1]
   }

   # open scheduler messages file
   set schedd_messages_file [check_schedd_messages 2]
   set schedd_messages_sid [ open_remote_spawn_process $CHECK_HOST "ts_def_con" "tail" "-f $schedd_messages_file"]
   set schedd_messages_id [lindex $schedd_messages_sid 1]

   # disable queues if enable_queues_job_count is set
   set are_enabled 1
   if { $enable_queues_job_count > 0 } {
      foreach queue $queue_list {
         disable_queue $queue
         set are_enabled 0
      }
   }
   
   # prepare results array
   clean_current_system_status results_list result job_data schedd_data

   # prepare job arguments 
   set my_job "\$SGE_ROOT/examples/jobs/sleeper.sh"

   # open shell on each execd host, used for submitting jobs
   set spawn_list ""
   set remote_spawn_list ""
   

   set tries 0
   set con_error 1
   while { $tries < 3 && $con_error > 0} {
      set con_error 0
      foreach host $host_list {
         puts $CHECK_OUTPUT "start remote call on host $host"
         set output [start_remote_prog $host $CHECK_USER "id" ""]
         puts $CHECK_OUTPUT $output
         if { $prg_exit_state != 0 } {
            incr con_error 1
         }
      }
      incr tries 1
   }

   if { $con_error != 0 } {
      set_error -1 "could not enable connection to host $host"
      return -1
   }

   # connections are buffered, so the connection are already open !!!
   foreach host $host_list {
      puts $CHECK_OUTPUT "open connection to host $host"
      set id [ open_remote_spawn_process $host $CHECK_USER "/bin/sh" "" ]
      lappend spawn_list [ lindex $id 1 ]
      lappend remote_spawn_list $id
   }
   
   # wait for _start_mark_ response from each execd host, used for submitting jobs
   set timeout 60
   set ok 0
   set next_submit_list ""
   set sent_jobs 0
   set sent_job_ids ""
   set schedd_nr 0
   set ids_received 0
   set ids_spawn_list ""
   set active_spawn_ids ""

   set my_timeout [ expr ( [timestamp] + 300 ) ]
   while { $ok != [llength $host_list] || $ids_received != [llength $host_list] } {
      
      foreach elem $active_spawn_ids {
         puts $CHECK_OUTPUT "sending id request to spawn id $elem"
         send -i $elem "id\n"
      }

      expect {
         -i $spawn_list full_buffer {
            add_proc_error "run_throughput_test" -1 "expect full_buffer error (1)"
         }
         -i $spawn_list timeout {
            set_error -1 "timeout while waiting for remote shell"
            return -1
         }
         -i $spawn_list eof {
            set spawn_id $expect_out(spawn_id)
            set host_nr [lsearch $spawn_list $spawn_id]
            set host_name [lindex $host_list $host_nr]
            add_proc_error "run_throughput_test" -1 "got eof from host $host_name\n$expect_out(0,string)"
         }
         -i $spawn_list "_start_mark_:(0)" {
            set spawn_id $expect_out(spawn_id)
            set host_nr [lsearch $spawn_list $spawn_id]
            set host_name [lindex $host_list $host_nr]
            incr ok 1
            lappend active_spawn_ids $spawn_id
            puts $CHECK_OUTPUT "testing spawn id $spawn_id"
            # here the host is added to the next submit list
            lappend next_submit_list $host_name
         }
         -i $spawn_list "uid=*$CHECK_USER" {
            set spawn_id $expect_out(spawn_id)
            puts $CHECK_OUTPUT "got id from spawn id: $spawn_id"
            if { [lsearch $ids_spawn_list $spawn_id] < 0 } {
               lappend  ids_spawn_list $spawn_id
            }
            set help [lsearch $active_spawn_ids $spawn_id]
            if { $help >= 0 } {
               puts $CHECK_OUTPUT "found spawn id on pos $help"
               set active_spawn_ids [lreplace $active_spawn_ids $help $help]
            }
         }
       }
       if {  [timestamp] > $my_timeout  } {
          foreach elem $remote_spawn_list {
             close_spawn_process $elem
          }
          set_error -1 "timeout - could not enable all host connections"
          return -1
       }
       set ids_received [llength $ids_spawn_list]
       sleep 1
   }

   sleep 5
   # variables set not in main loop for speed reasons
   set event_and_msg_id_list $event_client_id
   lappend event_and_msg_id_list $schedd_messages_id
   set timeout 120


   # job list where job start event was faster than submit
   set job_buffer_data_index 0
   set job_buffer_data ""
   set max_errors 10
   set resend_buffer ""
   set last_job_id 0

   set max_submit_output_lines 40
   set current_output_line 0
   # here the throughput test starts
   while { $result(jobs_done) < $end_job_count } {
       # submit jobs (via expect chanels)
       if { $sent_jobs < $end_job_count } {
           if { [llength $resend_buffer] == 0 } {
              # get first host in next_submit_list hand submit job on that host
              set sub_host   [lindex $next_submit_list 0 ]       
              set host_index [lsearch $host_list $sub_host]
              if { $host_index >= 0 } {
                 set spawn_id [lindex $spawn_list $host_index]
                 set next_submit_list [lrange $next_submit_list 1 end]

                 if { $throughput_sharetree == 1 } {
                    set numb [ expr ( ( $sent_jobs  % 3 ) + 1 )]
                    set my_job_command "qsub -o /dev/null -e /dev/null -P project${numb} $my_job $result(job_run_time)"
                    #set job_data($sent_jobs,project) $numb
                 } else { 
                    set my_job_command "qsub -o /dev/null -e /dev/null $my_job $result(job_run_time)"
                 }
                 send -i $spawn_id "$my_job_command ; echo \"_:>${my_job_command}<:_>>\"\$?\"<<\"\n"
                 set job_data($sent_jobs,state) "submit"
   #              puts $CHECK_OUTPUT "setting job_data($sent_jobs,state) to submit"
                 set job_data($sent_jobs,job_id) "-"
                 set job_data($sent_jobs,submit_start_time) [timestamp]
                 set job_data($sent_jobs,submit_end_time) 0
                 set job_data($sent_jobs,run_start_time) 0
                 set job_data($sent_jobs,run_end_time) 0
                 incr sent_jobs 1
#                 puts $CHECK_OUTPUT "submitted job from host $sub_host, expect id: $spawn_id"
              }
           } else {
              # resend job
              set resend_spawn_id [lindex $resend_buffer 0]
              set resend_command [lindex $resend_buffer 1 ]

              puts $CHECK_OUTPUT "resending of command to spawn id $resend_spawn_id ..."
              puts $CHECK_OUTPUT $resend_command
             
              send -i $resend_spawn_id "$resend_command ; echo \"_:>${resend_command}<:_>>\"\$?\"<<\"\n"
              set resend_buffer [lreplace $resend_buffer 0 1]
           }
       } else {
           # maybe we lost a job ??? through expect ??? or due to an error ???
           if { $result(jobs_done) !=  $end_job_count } {

           }
       }
       # enable queues when $enable_queues_job_count is reached
       if { $are_enabled != 1 } {
          if { $result(jobs_submitted) >= $enable_queues_job_count } {
             set are_enabled 1
             foreach queue $queue_list {
                enable_queue $queue
             }
          }
       }

       # wait for job submit success for all execd hosts and event client reports
       expect {
         -i $spawn_list full_buffer {
            add_proc_error "run_throughput_test" -1 "expect full_buffer error (2)"
            return -1
         }
         -i $spawn_list timeout {
            puts $CHECK_OUTPUT "---->>>>>>>>> got timeout while waiting for submitted jobs"
            add_proc_error "run_throughput_test" -1 "got timeout while waiting for submitted jobs"
            # not all jobs are submitted ????
            return -1
         }
         -i $spawn_list eof {
            set spawn_id $expect_out(spawn_id)
            set host_nr [lsearch $spawn_list $spawn_id]
            set host_name [lindex $host_list $host_nr]
            add_proc_error "run_throughput_test" -1 "$host_name EOF : $expect_out(buffer)"
         }
         #  -i $spawn_list -- "$JOB_SUBMITTED\r\n"
         -i $spawn_list -- "*\r\n" {
            set output $expect_out(0,string) 
            set output [ split $output "\n" ]
            foreach help $output {
               set line [string trim $help]
               set output_lines($current_output_line) "$line"
               if { $current_output_line < $max_submit_output_lines } {
                  incr current_output_line 1
               } else {
                  for {set ln 0 } { $ln < $max_submit_output_lines } { incr ln 1 } {
                     set output_lines($ln) $output_lines([expr ( $ln + 1 )])
                  }
                  set  output_lines($max_submit_output_lines) ""
               }
               # removing additional characters before string
               set match_start [lindex $JOB_SUBMITTED 0]
               set match_pos [string first $match_start $line]
               if { $match_pos >= 1 } {
                  set line [ string range $line $match_pos end ] 
               }
               if { [ string match $JOB_SUBMITTED $line ] } {
#                  puts $CHECK_OUTPUT "line : >$line<"
#                  puts $CHECK_OUTPUT "match: >$JOB_SUBMITTED<"
                  set job_id_pos [ string first "__JOB_ID__" $JOB_SUBMITTED_DUMMY ]
                  if { $result(jobs_submitted) < 50 } {
                     # test evtl. L10N errors only the first 50 jobs
                     set job_name_pos [ string first "__JOB_NAME__" $JOB_SUBMITTED_DUMMY ]
                     set job_arg_pos [ string first "__JOB_ARG__" $JOB_SUBMITTED_DUMMY ]
                     if { $job_id_pos > $job_name_pos || $job_id_pos > $job_arg_pos } {
                         add_proc_error "run_throughput_test" "-1" "locale switches parameter for qsub string! This is not supported yet"
                     }
                  }
                  incr job_id_pos -1
                  set job_id_prefix [ string range $JOB_SUBMITTED_DUMMY 0 $job_id_pos ]
                  set job_id_prefix_length [ string length $job_id_prefix]
                  set outtext $line 
                  set id_pos [ string first $job_id_prefix $outtext]
                  incr id_pos $job_id_prefix_length
                  set submitjob_jobid [string range $outtext $id_pos end]
                  set space_pos [ string first " " $submitjob_jobid ]
                  set submitjob_jobid [string range $submitjob_jobid 0 $space_pos ]
                  set submitjob_jobid [string trim $submitjob_jobid]
                  
                  set last_job_id $submitjob_jobid

                  set job_data($result(jobs_submitted),job_id) $submitjob_jobid
#                  puts $CHECK_OUTPUT "job $submitjob_jobid submitted"    
                  set job_data($submitjob_jobid) $result(jobs_submitted)   ;# pointer from job id to submit id
                  set job_data($result(jobs_submitted),state) "pending" 
                  set job_data($result(jobs_submitted),submit_end_time) [timestamp] 


                  # do the rest
                  set spawn_id $expect_out(spawn_id)
                  set host_nr 0
                  set host_nr [lsearch $spawn_list $spawn_id]
                  set host_name [lindex $host_list $host_nr]
                  incr result(jobs_submitted) 1
                  # here a job is definitely submitted
                  lappend next_submit_list $host_name
                  lappend sent_job_ids $submitjob_jobid

                  # show for buffered job starts
                  while { $job_buffer_data_index > 0 } {
                     set buf_time  [lindex $job_buffer_data 0]
                     set buf_state [lindex $job_buffer_data 1]
                     set buf_jobid [lindex $job_buffer_data 2]

                     set sub_id [get_submit_id_from_job_id job_data $buf_jobid]
                     if { $sub_id >= 0 } {
                         set job_data($sub_id,run_start_time) $buf_time
                         set job_data($sub_id,state) $buf_state
                         set tmp_list [lrange $job_buffer_data 3 end]
                         set job_buffer_data $tmp_list
                         incr result(jobs_running) 1
                         incr job_buffer_data_index -1
#                         puts $CHECK_OUTPUT "removed job $buf_jobid from buffer"
                     } else {
                         # job submit message not available till now
                         break
                     }
                  }

               } else {
                  if { [string length $line] > 0 } {
                      
                     if { [ string match "*>>*<<*" $line] } {
                         # exit state of last submit
                         set exit_state_start [string first ">>" $line]
                         incr exit_state_start 2
                         set exit_state_end [string first "<<" $line]
                         incr exit_state_end -1
                         set exit_state [string range $line $exit_state_start $exit_state_end]
                         if { [string first "?" $exit_state] < 0 } {
                            if { $exit_state != 0 } {
                               puts $CHECK_OUTPUT "exit_state: >$exit_state< line: $line"
                               set command_start [string first "_:>" $line]
                               incr command_start 3
                               set command_end [string first "<:_" $line]
                               incr command_end -1
                               set command_string [string range $line $command_start $command_end]
                               lappend resend_buffer "$expect_out(spawn_id)"
                               lappend resend_buffer "$command_string"
   
                               set proc_error_help_buffer ""
                               for {set ln 0 } { $ln <= $max_submit_output_lines } { incr ln 1 } {
                                  if { [info exists output_lines($ln) ] } {
                                     append proc_error_help_buffer "$output_lines($ln)\n"
                                  }
                               }


                               add_proc_error "run_throughput_test" -3 "submit exit state is $exit_state, expect id: $expect_out(spawn_id), sent jobs: $sent_jobs\n$proc_error_help_buffer"

                               
                               incr max_errors -1
                               if { $max_errors < 0 } {
                                  add_proc_error "run_throughput_test" -1 "to much submit errors - break"
                                  foreach elem $remote_spawn_list {
                                     close_spawn_process $elem
                                  }
                                  close_spawn_process $event_client_sid
                                  close_spawn_process $schedd_messages_sid
                                  set_error -1 "error"
                                  return -1
                               }
                            }
                         }
                     }
                  }
               }
            }
         }

         # here we expect event client
         -i $event_and_msg_id_list -- full_buffer {
            add_proc_error "run_throughput_test" -1 "expect full_buffer error (3)"
            return -1
         }
         -i $event_and_msg_id_list eof {
            add_proc_error "run_throughput_test" "-1" "unexpected EOF"
         }
         -i $event_and_msg_id_list -- "_exit_status_" {
            add_proc_error "run_throughput_test" "-1" "unexpected _exit_status_"
         }
         -i $event_and_msg_id_list -- "*\n" {
             set output $expect_out(0,string) 
             set output [ split $output "\n" ]
             foreach line $output {
                set help [string trim $line]


                if { [string match "JOB_ADD (*)" $help] } {
                   # job is done remove job from sent_job_ids list
                   set job_s_pos [string first "(" $help]
                   incr job_s_pos 1
                   set job_e_pos [string first ")" $help]
                   incr job_e_pos -1

                   set event_data [string range $help $job_s_pos $job_e_pos]
                   set event_data [split $event_data ":"]
                   set job_id [lindex $event_data 0] 
                   set project_name [lindex $event_data 2]

                   set help_pos [string first "." $job_id]
                   incr help_pos -1
                   set job_id [string range $job_id 0 $help_pos]

                   set help_pos [string first "=" $project_name]
                   incr help_pos 1
                   set project_name [string range $project_name $help_pos end]
                   set job_id_project_list($job_id) [ string index $project_name 7]
                }


                if { [string match "JOB_FINISH (*)" $help] } {
                   # job is done remove job from sent_job_ids list
                   set job_s_pos [string first "(" $help]
                   incr job_s_pos 1
                   set job_e_pos [string first "." $help]
                   incr job_e_pos -1
                   set job_id [string range $help $job_s_pos $job_e_pos]
#                   puts $CHECK_OUTPUT "Job $job_id finished"
                   set pos [lsearch $sent_job_ids $job_id]
                   if { $pos >= 0 } {
                      incr result(jobs_done) 1
                      set sent_job_ids [lreplace $sent_job_ids $pos $pos]
                      incr result(jobs_running) -1

                      set id_position [lsearch $result(job_ids_running) $job_id]
                      set new_running_job_ids_list [lreplace $result(job_ids_running) $id_position $id_position ]
                      set result(job_ids_running) $new_running_job_ids_list
                   
                      set sub_id [get_submit_id_from_job_id job_data $job_id]
                      if { $sub_id >= 0 } {
                         set job_data($sub_id,run_end_time) [get_event_client_time $help] ;#[timestamp]
                         set job_data($sub_id,state) "done"
                         set job_data($sub_id,project) $job_id_project_list($job_id)
                      }
                   }
                }
                if { [string match "JOB_START (*)" $help] } {
                   # job is done remove job from sent_job_ids list
                   set job_s_pos [string first "(" $help]
                   incr job_s_pos 1
                   set job_e_pos [string first "." $help]
                   incr job_e_pos -1
                   set job_id [string range $help $job_s_pos $job_e_pos]
#                   puts $CHECK_OUTPUT "Job $job_id started"
                   incr result(jobs_running) 1
                   lappend result(job_ids_running) $job_id

                   set sub_id [get_submit_id_from_job_id job_data $job_id]
                   if { $sub_id >= 0 } {
                      set job_data($sub_id,run_start_time) [get_event_client_time $help] ;#[timestamp]
                      set job_data($sub_id,state) "running"
                   } else {
                      # puts $CHECK_OUTPUT "assuming job submit before start!"
                      # add the job start to job_buffer_data (when submit command
                      # returns, the job data is actualized)
                      lappend job_buffer_data [get_event_client_time $help] ;# [timestamp]
                      lappend job_buffer_data "running"
                      lappend job_buffer_data $job_id
                      incr job_buffer_data_index 1
                      incr result(jobs_running) -1
                   }
                }
                if { [string match "*scheduled in*" $help] } {
#  Mon Dec 16 15:01:05 2002|schedd|es-ergb01-01|I|scheduled in 0.000 s: 0 fast, 0 complex, 0 orders, 4 H, 4 Q, 13 QA, 0 J, 2 C, 1 ACL, 1 PE, 1 CONF, 0 U, 1 D, 1 PRJ, 0 ST, 1 CKPT, 0 RU


#new                                                  0      1   2    3   4   5 6 7     8  9
#  Wed Feb 12 10:53:06 2003|schedd|es-ergb01-01|I|scheduled in 0.010 (u 0.010 + s 0.000 = 0.010): 0 fast, 0 complex, 0 orders, 5 H, 30 Q, 34 QA, 0 J(qw), 0 J(r), 0 J(x), 2 C, 1 ACL, 1 PE, 1 CONF, 0 U, 1 D, 1 PRJ, 0 ST, 1 CKPT, 0 RU

# newest
#  Mon Jul 21 15:29:35 2003|schedd|es-ergb01-01|I|PROF: scheduled in 0.000 (u 0.000 + s 0.000 = 0.000): 0 fast, 0 complex, 0 orders, 4 H, 0 Q, 3 QA, 0 J(qw), 0 J(r), 0 J(s), 0 J(h), 0 J(e), 0 J(x), 0 J(all), 3 C, 1 ACL, 1 PE, 1 CONF, 0 U, 0 D, 0 PRJ, 0 ST, 1 CKPT, 0 RU


                   set st_pos [string first "|I|" $help ]
                   incr st_pos 3
                   set schedd_string [ string range $help $st_pos end ]
#                   puts $CHECK_OUTPUT $schedd_string
                   if { [ string compare "PROF:" [lindex $schedd_string 0]] == 0 } {
                      set schedd_string [ string range $schedd_string 6 end ]
#                      puts $CHECK_OUTPUT "new schedd string: \n$schedd_string"
                   }

                   if { [ string compare "in" [lindex $schedd_string 1 ]] != 0 } {
                      foreach elem $remote_spawn_list {
                         close_spawn_process $elem
                      }
                      close_spawn_process $event_client_sid
                      close_spawn_process $schedd_messages_sid
                      set_error -1 "format error for orders (1)"
                      return -1
                   }
                   set schedd_time [ lindex $schedd_string 2 ]   ;# this is wall clock time
                   if { [string match "*orders*" [lindex $schedd_string 9]] == 0 } {
                      set schedd_time [ lindex $schedd_string 9 ]  ;# this is system + user time (plus "):" )
                      set schedd_time_length [string length $schedd_time]
                      incr schedd_time_length -3
                      set schedd_time [ string range $schedd_time 0 $schedd_time_length ]
                   }

                   
                   for { set s_index 0 } { $s_index < [llength $schedd_string] } { incr s_index 1 } {
                      if { [string compare [lindex $schedd_string $s_index] "orders," ] == 0  } {
                         break
                      }
                   }
                   
                   if { [ string compare "orders," [lindex $schedd_string $s_index ]] != 0 } {
                      foreach elem $remote_spawn_list {
                         close_spawn_process $elem
                      }
                      close_spawn_process $event_client_sid
                      close_spawn_process $schedd_messages_sid
                      set_error -1 "format error for orders (2)"
                      return -1
                   }
                   incr s_index -1
                   set orders_value [ lindex $schedd_string $s_index ]
#                   puts $CHECK_OUTPUT "schedd_time: $schedd_time"
#                   puts $CHECK_OUTPUT "orders: $orders_value"
                   set schedd_data($schedd_nr,system_time)   [timestamp] 
                   set schedd_data($schedd_nr,schedd_time)   $schedd_time
                   set schedd_data($schedd_nr,schedd_orders) $orders_value
                   set schedd_data($schedd_nr,data_line)     $schedd_string
                   set schedd_data(count) $schedd_nr
                   incr schedd_nr 1
                }
             }
         }
       }

       # update system status
       # we have one slot per queue !
       set jobs_running $result(jobs_running)
       set jobs_run_pend         [ expr ( $result(jobs_submitted) - $result(jobs_done)    ) ]
       set result(jobs_pending)  [ expr ( $jobs_run_pend          - $jobs_running ) ]
       set result(free_slots)    [ expr ( $result(total_slots)    - $jobs_running ) ]
       
       set time_now [timestamp]
       if { $result(test_run_time) != $time_now } {
           show_current_system_status result job_data schedd_data
           flush $CHECK_OUTPUT
       }
       set result(test_run_time) $time_now
       save_current_system_status results_list result
   } 

   create_reports results_list job_data schedd_data

   # close all open connections and event client
   foreach elem $remote_spawn_list {
      close_spawn_process $elem
   }
   close_spawn_process $event_client_sid
   close_spawn_process $schedd_messages_sid

   catch {  eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qdel" "-uall" } catch_result
   puts $CHECK_OUTPUT "qdel -uall\n$catch_result"
   wait_for_jobend $last_job_id leeper 60 0 1
   set_error 0 "ok"
}

proc get_submit_id_from_job_id { job_array_name job_id } {
   global CHECK_OUTPUT
   upvar $job_array_name jobs
   
   if { [info exists jobs($job_id)] == 0 } {
#      puts $CHECK_OUTPUT "job $job_id not existing"
      return -1
   }

   return $jobs($job_id)
}

proc save_current_system_status { results_array array_name } {
   global CHECK_OUTPUT

   upvar $array_name data
   upvar $results_array results

   set count $results(count)
   set names [array names data]
   foreach name $names {
      set results($count,$name) $data($name)
   }
   incr results(count) 1
}

proc compare_dump_directory { dir } {

   global CHECK_OUTPUT

   set files [get_file_names $dir "saved_run*"]
   set first_data 0
   set test_info "FLUSH_FINISH_SEC"
   lappend test_info "FLUSH_SUBMIT_SEC"
   lappend test_info "SCHEDULE_INTERVAL"
   lappend test_info "enable_queues_job_count"
   lappend test_info "end_job_count"
   lappend test_info "global_job_run_time"
   lappend test_info "hostlist"
   lappend test_info "nr_of_local_spool_directories"
   lappend test_info "nr_queues"
   lappend test_info "nr_slots_per_queue"

   set test_data "avg_run"
   lappend test_data "avg_schedd_time"
   lappend test_data "avg_submit"
   lappend test_data "utilization"
   lappend test_data "submits_per_second"
   lappend test_data "jobs_per_second"
   lappend test_data "total_submit_time"
   lappend test_data "total_run_time"

   foreach data $test_data {
      set nr [lsearch $test_data $data]
      set xy_rows($nr,drawmode) "linespoints"
      set xy_rows($nr,title) $data
      set xy_rows($nr,show) 0
      set sum($data) 0.0000
   }


   set count 0
   foreach file $files {
      if { [string first "old" $file ] > 0 } {
         continue
      }
      if { [string first "_vs_" $file ] > 0 } {
         continue
      }

      set test_info_file $dir/${file}_dir/test_results_array.dat
#      puts $CHECK_OUTPUT "file: $test_info_file\n"
      read_array_from_file $test_info_file "test settings" test_settings
      read_array_from_file $test_info_file "test results"  test_results

      if { $first_data == 0 } {
         foreach info  $test_info {
            set defaults($info) $test_settings($info)
         }
      }
      set ignore 0
      foreach info  $test_info {
         if { [ string compare $defaults($info) $test_settings($info) ] != 0 } {
            puts $CHECK_OUTPUT "ignoring file $file: $defaults($info) for $info setting not $defaults($info)"
            set ignore 1
         } 
      }

      if { $ignore == 0 } {
         # here we have the data
         foreach data $test_data {
#            puts $CHECK_OUTPUT "($count=$file) $data: $test_results($data)" 
            set nr [lsearch $test_data $data]

            # x value: (nr of file )
            set xy_rows($nr,$count,x) $count
            set xy_rows($nr,$count,y) $test_results($data)
            set sum($data) [ expr ( $sum($data) + $test_results($data)) ]
         }
         incr count 1
      }
      incr first_data 1
   }
   set plot_data(xlabel) "nr"
   set plot_data(ylabel) "values"
   
   foreach data $test_data {
      set nr [lsearch $test_data $data]
      set calc_avg [expr ( $sum($data) / $count )]
      puts $CHECK_OUTPUT "avg. $data: $calc_avg"
   }

   foreach data $test_data {
      set nr [lsearch $test_data $data]
      set plot_data(title) "historical - $data"
      set plot_data(output_file) "$dir/$data.gif"
      set xy_rows($nr,show) 1
      create_gnuplot_xy_gif plot_data xy_rows
      set xy_rows($nr,show) 0
   }
}

proc compare_dump_data_file { file1 file2 } {

   global CHECK_OUTPUT 

   if { [file isfile $file1] != 1 } {
      puts $CHECK_OUTPUT "no file $file1"
      return -1
   }
   if { [file isfile $file2] != 1 } {
      puts $CHECK_OUTPUT "no file $file2"
      return -1
   }


   # first analyse the files (if not existent)
   analyse_dump_data_file $file1 
   analyse_dump_data_file $file2
   
   # create output directory
   set sub_dir1 [file tail $file1]
   set sub_dir2 [file tail $file2]
   set sub_dir "${sub_dir1}_vs_${sub_dir2}"
   set dir_name [file dirname $file1]
   set output_dir $dir_name/${sub_dir}_dir
   puts $CHECK_OUTPUT "file: [file tail $file1]"
   puts $CHECK_OUTPUT "file: [file tail $file2]"
   puts $CHECK_OUTPUT "generating report in directory: $output_dir"
   file mkdir $output_dir
   puts $CHECK_OUTPUT "please wait ..."

   # read in test configuration files
   read_array_from_file $file1 "test configuration" test_config1
   read_array_from_file $file2 "test configuration" test_config2


   set content ""
   set error 0
   set job_count1 $test_config1(end_job_count)
   set job_count2 $test_config2(end_job_count)
   if { $job_count1 != $job_count2 } {
      incr error 1
      append content [create_html_text "The to projects have different job count"]
   }
 
   set enable_queue_job_count1 $test_config1(enable_queues_job_count)
   set enable_queue_job_count2 $test_config2(enable_queues_job_count)
   if { $enable_queue_job_count1 != $enable_queue_job_count2 } {
      incr error 1
      append content [create_html_text "The queue enable threshold values are different"]
   }

   set global_job_run_time1 $test_config1(global_job_run_time) 
   set global_job_run_time2 $test_config2(global_job_run_time)
   if { $global_job_run_time1 != $global_job_run_time2 } {
      incr error 1
      append content [create_html_text "The to test runs have different job run time"]
   }

   set nr_queues1 $test_config1(nr_queues)
   set nr_queues2 $test_config2(nr_queues)
   set nr_slots_per_queue1 $test_config1(nr_slots_per_queue)
   set nr_slots_per_queue2 $test_config2(nr_slots_per_queue)
   set hostslots1 [ expr ( $nr_queues1 * $nr_slots_per_queue1 ) ]
   set hostslots2 [ expr ( $nr_queues2 * $nr_slots_per_queue2 ) ]

   if { $hostslots1 != $hostslots2 } {
      incr error 1
      append content [create_html_text "The number of slots on each host is different"]
   }
   


   set FLUSH_SUBMIT_SEC1 $test_config1(FLUSH_SUBMIT_SEC)
   set FLUSH_SUBMIT_SEC2 $test_config2(FLUSH_SUBMIT_SEC)
   if { $FLUSH_SUBMIT_SEC1  != $FLUSH_SUBMIT_SEC2 } {
      incr error 1
      append content [create_html_text "The test runs have different FLUSH_SUBMIT_SEC times"]
   }

  
   set FLUSH_FINISH_SEC1 $test_config1(FLUSH_FINISH_SEC)
   set FLUSH_FINISH_SEC2 $test_config2(FLUSH_FINISH_SEC)
   if { $FLUSH_FINISH_SEC1 != $FLUSH_FINISH_SEC2 } {
      incr error 1
      append content [create_html_text "The test runs have different FLUSH_FINISH_SEC times"]
   }

  
   set SCHEDULE_INTERVAL1 $test_config1(SCHEDULE_INTERVAL)
   set SCHEDULE_INTERVAL2 $test_config2(SCHEDULE_INTERVAL)
   if { $SCHEDULE_INTERVAL1 != $SCHEDULE_INTERVAL2 } {
      incr error 1
      append content [create_html_text "The test runs have different SCHEDULE_INTERVAL values"]
   }
  
   read_array_from_file $file1 "execd list" host_list1
   read_array_from_file $file2 "execd list" host_list2
   set nr 0
   set execd_list1 ""
   set qmaster1 [lindex $host_list1(host_list) 0]
   foreach elem $host_list1(host_list) {
      if { $elem == $qmaster1 } {
         continue
      }
      if { $elem == "global" } {
         continue
      }
      lappend execd_list1 $elem
   }
   set nr 0
   set execd_list2 ""
   set qmaster2 [lindex $host_list2(host_list) 0]
   foreach elem $host_list2(host_list) {
      if { $elem == $qmaster2 } {
         continue
      }
      if { $elem == "global" } {
         continue
      }
      lappend execd_list2 $elem
   }

   # qmaster, execd_list, host_list
   if { [string compare $host_list1(host_list) $host_list2(host_list)] != 0 } {
      incr error 1
      append content [create_html_text "The test runs have different host list settings"]
   }

   read_array_from_file "${file1}_dir/test_results_array.dat" "test settings" test_settings1
   read_array_from_file "${file2}_dir/test_results_array.dat" "test settings" test_settings2
  
   puts $CHECK_OUTPUT "A spool directories: $test_settings1(nr_of_local_spool_directories)"
   puts $CHECK_OUTPUT "B spool directories: $test_settings2(nr_of_local_spool_directories)"
   if { $test_settings1(nr_of_local_spool_directories) != $test_settings2(nr_of_local_spool_directories) } {
      incr error 1
      append content [create_html_text "The execd have different count of local spool directories"]
   }

   
   if { $error != 0 } {
      append content [create_html_text "Can't compare the two test scenarios !!!"]
      generate_html_file $output_dir/index.html "$test_config1(gridengine_version) (A) from $test_config1(test_date)<br>vs<br>$test_config2(gridengine_version) (B) from $test_config2(test_date)" $content
      return -1
   }

   # ok, we can compare the two scenarios !!!
   set text ""
   append text "The Grid Engine throughput test runs submits sleeper jobs to each execd host in the "
   append text "cluster. No job is submitted from master host. This test report compares two testsuite "
   append text "runs and shows only the divergent test values. Both testsuite Grid Engine clusters had "
   append text "following settings:"
   append content [ create_html_text $text ]

   set test "Grid Engine version A"
   set table($test) "$test_config1(gridengine_version)"
   set test "Grid Engine version B"
   set table($test) "$test_config2(gridengine_version)"

   set test "Nr. of Execution daemons"
   set table($test) [create_html_link [llength $execd_list1] "#Execd list"]

   set test "Master/Scheduler host"
   set table($test) "$qmaster1"

   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   if { $test_config1(enable_queues_job_count) == 0 } {
      set text ""
      append text "There was no threshold value for enabling queues in the tests. So all queues was "
      append text "enabled when testsuite started to submit jobs." 
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "There was a threshold value for enabling queues in the tests. So all queues was "
      append text "disabled when testsuite started to submit jobs. As the pending job count reached " 
      append text "a count of $test_config1(enable_queues_job_count) the testsuite enabled all cluster "
      append text "queues."
      append content [ create_html_text $text ]
   }
   append content [ create_html_text "" ]

   set text ""
   append text "The Grid Engine system A had $test_config1(nr_queues) queues with $test_config1(nr_slots_per_queue) "
   append text "slots on each host (=[ expr ( $test_config1(nr_queues) * $test_config1(nr_slots_per_queue) * [llength $execd_list1]  )] "
   append text "slots)." 
   append content [ create_html_text $text ]
   set text ""
   append content [ create_html_text "" ]
   append text "The Grid Engine system B had $test_config2(nr_queues) queues with $test_config2(nr_slots_per_queue) "
   append text "slots on each host (=[ expr ( $test_config2(nr_queues) * $test_config2(nr_slots_per_queue) * [llength $execd_list2]  )] "
   append text "slots)." 
   append content [ create_html_text $text ]
   set text ""
   append content [ create_html_text "" ]
   append text "The testsuite subitted $test_config1(end_job_count) sleeper jobs to the systems. Each job had " 
   append text "a sleep time of $test_config1(global_job_run_time) seconds."
   append content [ create_html_text $text ]
   append content [ create_html_text "" ]


   if { $test_config1(FLUSH_SUBMIT_SEC) == -1 } {
      set text ""
      append text "The FLUSH_SUBMIT_SEC parameters were turned off."
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "The FLUSH_SUBMIT_SEC parameters were set to $test_config1(FLUSH_SUBMIT_SEC) seconds."
      append content [ create_html_text $text ]
   }
 
   append content [ create_html_text "" ]
   if { $test_config1(FLUSH_FINISH_SEC) == -1 } {
      set text ""
      append text "The FLUSH_FINISH_SEC parameters were turned off."
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "The FLUSH_FINISH_SEC parameter were set to $test_config1(FLUSH_FINISH_SEC) seconds."
      append content [ create_html_text $text ]
   }

   append content [ create_html_text "" ]
   set text ""
   append text "The schedule interval parameters were set to $test_config1(SCHEDULE_INTERVAL)"
   append content [ create_html_text $text ]
   
   read_file $file1 file_data1
   read_file $file2 file_data2

   puts $CHECK_OUTPUT "reading online data of test A"
   read_array_from_file_data file_data1 "online data"    results1
   puts $CHECK_OUTPUT "reading job data of test A"
   read_array_from_file_data file_data1 "job data"       jobs1
   puts $CHECK_OUTPUT "reading scheduler data of test A"
   read_array_from_file_data file_data1 "scheduler data" schedd1
   puts $CHECK_OUTPUT "reading online data of test B"
   read_array_from_file_data file_data2 "online data"    results2
   puts $CHECK_OUTPUT "reading job data of test B"
   read_array_from_file_data file_data2 "job data"       jobs2
   puts $CHECK_OUTPUT "reading scheduler data of test B"
   read_array_from_file_data file_data2 "scheduler data" schedd2
   

# --  1  set test "Total run time"
# --   set test_data(total_run_time) $cluster_results(total_run_time)
# --  2  set test "Total submit time"
# --   set test_data(total_submit_time) $cluster_results(total_submit_time)
# --  3  set test "Submits per second"
# --   set test_data(submits_per_second)  $cluster_results(submits_per_second)
# --  4  set test "Jobs per second"
# --   set test_data(jobs_per_second) $cluster_results(jobs_per_second)
# --  5  set test "Utilization (Slot allocation)"
# --   set test_data(utilization)  $cluster_results(utilization)
# --  6  set test "Average Submit time"
# --   set test_data(avg_submit) $avg_values(avg_submit)
# --  7  set test "Average run/transfer time"
# --   set test_data(avg_run) $avg_values(avg_run)
# --  8  set test "Average scheduler calculation time"
# --   set test_data(avg_schedd_time) $avg_schedd_values(avg_schedd_time)


   read_array_from_file "${file1}_dir/test_results_array.dat" "test results" test_data1
   read_array_from_file "${file2}_dir/test_results_array.dat" "test results" test_data2
   

   #   A absolut  |  B absolut | B compared to A (in %) 
   set table(COLS) 4
   set table(ROWS) 9
   set table(1,BGCOLOR) "#FFFFFF"
   set table(1,FNCOLOR) "#000000"
   set table(1,1) ""
   set table(1,2) "A<br>($test_config1(gridengine_version))"
   set table(1,3) "B<br>($test_config2(gridengine_version))"
   set table(1,4) "B compared to A (in %)"

   set row_names "dummy dummy"
   lappend row_names "Total run time"
   lappend row_names "Total submit time"
   lappend row_names "Submits per second"
   lappend row_names "Jobs per second"
   lappend row_names "Utilization (Slot allocation)"  
   lappend row_names "Average Submit time"
   lappend row_names "Average run/transfer time"
   lappend row_names "Average scheduler calculation time"

   set A "dummy dummy"
   lappend A $test_data1(total_run_time)
   lappend A $test_data1(total_submit_time)
   lappend A $test_data1(submits_per_second)
   lappend A $test_data1(jobs_per_second)
   lappend A $test_data1(utilization)
   lappend A $test_data1(avg_submit)
   lappend A $test_data1(avg_run)
   lappend A $test_data1(avg_schedd_time)
   set B "dummy dummy"
   lappend B $test_data2(total_run_time)
   lappend B $test_data2(total_submit_time)
   lappend B $test_data2(submits_per_second)
   lappend B $test_data2(jobs_per_second)
   lappend B $test_data2(utilization)
   lappend B $test_data2(avg_submit)
   lappend B $test_data2(avg_run)
   lappend B $test_data2(avg_schedd_time)


   for { set row 2} { $row <= 9 } { incr row 1} {
      set table($row,BGCOLOR) "#FFFFFF"
      set table($row,FNCOLOR) "#000000"
      set table($row,1) [lindex $row_names $row]
      set a [lindex $A $row]
      set b [lindex $B $row]
      set table($row,2) [format "%.3f" $a]
      set table($row,3) [format "%.3f" $b]

      # a is 100%
      set one_percent [ expr ( $a / 100.000  ) ]
      set b_in_percent [ expr ( $b / $one_percent ) ]      
      set diff [ expr ( abs ( 100.000 - $b_in_percent ) ) ]

      set good  "#00FF00"  ;# green
      set bad   "#FF0000"  ;# red
      set good_s "B beats A"
      set bad_s  "B underlies A"

      if { $row == 4 || $row == 5 || $row == 6 } {
         set help $good
         set good $bad
         set bad $help
         set help $good_s
         set good_s $bad_s
         set bad_s $help
         
      }
     

      if { $b_in_percent > 100 } {
         set table($row,4,FNCOLOR) $bad    ;# red
         set arrow $bad_s
      } else {
         set table($row,4,FNCOLOR) $good    ;# green
         set arrow $good_s
      }
      if { $b_in_percent == 100.00 } {
         set table($row,4,FNCOLOR) "#000000"
         set arrow "B equals A"
      }
      
      set table($row,4) "[format "%.3f" $b_in_percent]%<br>(difference: [format "%.3f" $diff]%)<br>($arrow)"

   }
   append content [ create_html_table table 1 CENTER]


   # links to other documents
   append content [ create_html_text "" ]
   append content [create_html_link "   (1) Running job analysis" "running_jobs.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (2) Job time analysis" "job_times.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (3) Job distribution analysis" "job_distribution.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (4) Pending job analysis" "pending_jobs.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (5) Scheduler calculation time analysis" "schedd_calc_time.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (6) Scheduler job order analysis" "schedd_orders.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (7) All charts in one html document" "all_charts.html"]



  
   # apendix
   append content [ create_html_text "" ]
   append content "<hr WIDTH=\"100%\">"
   append content [ create_html_text "Appendix" 1]
   append content "<hr WIDTH=\"100%\">"
   
   # host architecture list
   append content [create_html_target "Execd list"]
   append content [create_html_text "The test runs used the following execution hosts:"]
   unset table
   set table(Hostname) "Architecture"
   foreach host $execd_list1 {
      set table($host) [resolve_arch $host]
   }
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]


   
   generate_html_file $output_dir/index.html "$test_config1(gridengine_version) (A) from $test_config1(test_date)<br>file: $file1<br>vs<br>$test_config2(gridengine_version) (B) from $test_config2(test_date)<br>file: $file2" $content

   # generate chart files ------------------------------------------------
   set content ""
   append content ""
   append content [create_html_image "Running jobs" "running_jobs.gif"]
   set title "$test_config1(gridengine_version) (A) from $test_config1(test_date)<br>vs<br>$test_config2(gridengine_version) (B) from $test_config2(test_date)"
   generate_html_file $output_dir/running_jobs.html $title $content
   
   set content ""
   append content ""
   append content [create_html_image "Job times" "job_times.gif"]
   generate_html_file $output_dir/job_times.html $title $content

   set content ""
   append content ""
   append content [create_html_image "Job distribution" "job_distribution.gif"]
   generate_html_file $output_dir/job_distribution.html $title $content


   set content ""
   append content ""
   append content [create_html_image "Pending jobs" "pending_jobs.gif"]
   generate_html_file $output_dir/pending_jobs.html $title $content

   set content ""
   append content ""
   append content [create_html_image "Scheduler times" "schedd_calc_time.gif"]
   generate_html_file $output_dir/schedd_calc_time.html $title $content

   set content ""
   append content ""
   append content [create_html_image "Scheduler orders" "schedd_orders.gif"]
   generate_html_file $output_dir/schedd_orders.html $title $content

   set content ""
   append content ""
   append content [create_html_image "Running jobs" "running_jobs.gif"]
   append content [create_html_image "Job times" "job_times.gif"]
   append content [create_html_image "Job distribution" "job_distribution.gif"]
   append content [create_html_image "Pending jobs" "pending_jobs.gif"]
   append content [create_html_image "Scheduler times" "schedd_calc_time.gif"]
   append content [create_html_image "Scheduler orders" "schedd_orders.gif"]
   generate_html_file $output_dir/all_charts.html $title $content


   # plot diagrams
   # get functions for test run  and schedd data
       #  1) test run
       calculate_test_run_xy_rows results1 xy_rows 0
       #  2) schedd run
       set test_start $results1(0,test_run_time)
       calculate_schedd_run_xy_rows schedd1 xy_rows $test_start 0
       #  3) job submit times and job run times
       calculate_submit_run_xy_rows jobs1 xy_rows $test_start 0

       #  1) test run
       calculate_test_run_xy_rows results2 xy_rows 11
       #  2) schedd run
       set test_start $results2(0,test_run_time)
       calculate_schedd_run_xy_rows schedd2 xy_rows $test_start 11
       #  3) job submit times and job run times
       calculate_submit_run_xy_rows jobs2 xy_rows $test_start 11




       set plot_data(xlabel) "time\[s\]"
       set plot_data(ylabel) "values"

       set plot_data(title) "Throughput test results - running jobs"
       set plot_data(output_file) "$output_dir/running_jobs.gif"
       set xy_rows(0,show) 1     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 1     ;# total system slots
       set xy_rows(5,show) 1     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution

       set start 11
       set xy_rows($start,show) 1     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 1     ;# total system slots
       incr start 1
       set xy_rows($start,show) 1     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows



       set plot_data(title) "Throughput test results - pending jobs"
       set plot_data(output_file) "$output_dir/pending_jobs.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 1     ;# pending jobs
       set xy_rows(2,show) 1     ;# jobs done
       set xy_rows(3,show) 1     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution


       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 1     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 1     ;# jobs done
       incr start 1
       set xy_rows($start,show) 1     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - schedd calculation time"
       set plot_data(output_file) "$output_dir/schedd_calc_time.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 1     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution

       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 1     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows


       set plot_data(title) "Throughput test results - schedd orders"
       set plot_data(output_file) "$output_dir/schedd_orders.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 1     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution

       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 1     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - job times"
       set plot_data(output_file) "$output_dir/job_times.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 1     ;# job submit time
       set xy_rows(9,show) 1     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution

       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 1     ;# job submit time
       incr start 1
       set xy_rows($start,show) 1     ;# job run time
       incr start 1
       set xy_rows($start,show) 0     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows
   
       set plot_data(title) "Throughput test results - job distribution"
       set plot_data(output_file) "$output_dir/job_distribution.gif"
       set plot_data(xlabel) "job time\[s\]"
       set plot_data(ylabel) "number of jobs"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 1     ;# job distribution

       set start 11
       set xy_rows($start,show) 0     ;# running jobs
       incr start 1
       set xy_rows($start,show) 0     ;# pending jobs
       incr start 1
       set xy_rows($start,show) 0     ;# jobs done
       incr start 1
       set xy_rows($start,show) 0     ;# jobs subitted
       incr start 1
       set xy_rows($start,show) 0     ;# total system slots
       incr start 1
       set xy_rows($start,show) 0     ;# free system slots
       incr start 1
       set xy_rows($start,show) 0     ;# schedduler calculation time
       incr start 1
       set xy_rows($start,show) 0     ;# schedd orders
       incr start 1
       set xy_rows($start,show) 0     ;# job submit time
       incr start 1
       set xy_rows($start,show) 0     ;# job run time
       incr start 1
       set xy_rows($start,show) 1     ;#  job distribution
       create_gnuplot_xy_gif plot_data xy_rows


   return 0

}

proc analyse_dump_data_file { file { force 0 } } {

   global CHECK_OUTPUT
   global throughput_sharetree
   
   set sub_dir [file tail $file]
   set dir_name [file dirname $file] 
   set output_dir $dir_name/${sub_dir}_dir
   puts $CHECK_OUTPUT "file: [file tail $file]"
   puts $CHECK_OUTPUT "generating report in directory: $output_dir"
   if { [file isdirectory $output_dir] && $force == 0 } {
      puts $CHECK_OUTPUT "existing analyse directory found. Use force option to re-analyse data file."
      return
   }
   if { [file isdirectory $output_dir] && $force != 0 } {
      puts $CHECK_OUTPUT "forcing re-analyse ..."
   }
   
   file mkdir $output_dir
  
   puts $CHECK_OUTPUT "please wait ..."
   read_array_from_file $file "online data"    results
   read_array_from_file $file "job data"       jobs
   read_array_from_file $file "scheduler data" schedd
   read_array_from_file $file "test configuration" test_config
   read_array_from_file $file "execd list" host_list
   puts $CHECK_OUTPUT "Test date:          $test_config(test_date)"
   puts $CHECK_OUTPUT "gridengine version: $test_config(gridengine_version)"

   read_array_from_file $file "schedd config" schedd_config
   

   
   # job results
   calculate_average_cluster_times results cluster_results $output_dir/cluster_times.txt
   calculate_average_job_times jobs avg_values $output_dir/job_times.txt
   calculate_average_schedd_times schedd avg_schedd_values $output_dir/schedd_times.txt

   

   set nr 0
   set execd_list ""
   set qmaster [lindex $host_list(host_list) 0]
   foreach elem $host_list(host_list) {
      if { $elem == $qmaster } {
         continue
      }
      if { $elem == "global" } {
         continue
      }
      lappend execd_list $elem
   }

   set content ""
   set text ""
   append text "The Grid Engine throughput test runs submits sleeper jobs to each execd host in the "
   append text "cluster. No job is submitted from master host. The testsuite Grid Engine cluster had "
   append text "following settings:"
   append content [ create_html_text $text ]

   set test "Grid Engine version"
   set table($test) "$test_config(gridengine_version)"
   set test "Nr. of Execution daemons"
   set table($test) [create_html_link [llength $execd_list] "#Execd list"]
   set test "Master/Scheduler host"
   set table($test) "$qmaster"
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   # 
   if { $test_config(enable_queues_job_count) == 0 } {
      set text ""
      append text "There was no threshold value for enabling queues in the test. So all queues was "
      append text "enabled when testsuite started to submit jobs." 
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "There was a threshold value for enabling queues in the test. So all queues was "
      append text "disabled when testsuite started to submit jobs. As the pending job count reached " 
      append text "a count of $test_config(enable_queues_job_count) the testsuite enabled all cluster "
      append text "queues."
      append content [ create_html_text $text ]
   }
   append content [ create_html_text "" ]
   set text ""
   append text "The Grid Engine system had $test_config(nr_queues) queues with $test_config(nr_slots_per_queue) "
   append text "slots on each host (=[ expr ( $test_config(nr_queues) * $test_config(nr_slots_per_queue) * [llength $execd_list]  )] "
   append text "slots). The testsuite subitted $test_config(end_job_count) sleeper jobs to the system. Each job had " 
   append text "a sleep time of $test_config(global_job_run_time) seconds."
   append content [ create_html_text $text ]
   
   append content [ create_html_text "" ]
   if { $test_config(FLUSH_SUBMIT_SEC) == -1 } {
      set text ""
      append text "The FLUSH_SUBMIT_SEC parameter was turned off."
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "The FLUSH_SUBMIT_SEC parameter was set to $test_config(FLUSH_SUBMIT_SEC) seconds."
      append content [ create_html_text $text ]
   }
 
   append content [ create_html_text "" ]
   if { $test_config(FLUSH_FINISH_SEC) == -1 } {
      set text ""
      append text "The FLUSH_FINISH_SEC parameter was turned off."
      append content [ create_html_text $text ]
   } else {
      set text ""
      append text "The FLUSH_FINISH_SEC parameter was set to $test_config(FLUSH_FINISH_SEC) seconds."
      append content [ create_html_text $text ]
   }

   append content [ create_html_text "" ]
   set text ""
   append text "The schedule interval parameter was set to $cluster_results(schedule_interval)"
   append content [ create_html_text $text ]
   



   puts $CHECK_OUTPUT "total run time     : $cluster_results(total_run_time)"
   puts $CHECK_OUTPUT "total jobs done    : $cluster_results(total_jobs_done)"
   puts $CHECK_OUTPUT "total submit time  : $cluster_results(total_submit_time)"
   puts $CHECK_OUTPUT "submits per second : $cluster_results(submits_per_second)"
   puts $CHECK_OUTPUT "jobs per second    : $cluster_results(jobs_per_second)"
   puts $CHECK_OUTPUT "avg. slots free    : $cluster_results(avg_slots_free)"
   puts $CHECK_OUTPUT "total slots        : $cluster_results(total_slots)"
   puts $CHECK_OUTPUT "utilization        : $cluster_results(utilization)"
   puts $CHECK_OUTPUT "job sleep time     : $cluster_results(jobs_sleep_time)"
   puts $CHECK_OUTPUT "queue enable value : $cluster_results(queue_enable_value)"
   puts $CHECK_OUTPUT "flush submit sec   : $cluster_results(flush_submit_sec)"
   puts $CHECK_OUTPUT "flush finish sec   : $cluster_results(flush_finish_sec)"
   puts $CHECK_OUTPUT "schedule interval  : $cluster_results(schedule_interval)"
   puts $CHECK_OUTPUT ""
   puts $CHECK_OUTPUT "avg. submit       (count=$avg_values(jobs_submit))   : $avg_values(avg_submit) "
   puts $CHECK_OUTPUT "avg. run/transfer (count=$avg_values(jobs_run))   : $avg_values(avg_run)    "
   puts $CHECK_OUTPUT ""
   puts $CHECK_OUTPUT "avg. schedd time (count=$avg_schedd_values(nr_of_schedd_runs))   : $avg_schedd_values(avg_schedd_time)"

   

   append content [ create_html_text "" ]
  
   unset table
   set test "Total run time"
   set table($test) $cluster_results(total_run_time)
   set test_data(total_run_time) $cluster_results(total_run_time)


   set test "Total submit time"
   set table($test) $cluster_results(total_submit_time)
   set test_data(total_submit_time) $cluster_results(total_submit_time)

   set test "Submits per second"
   set table($test) $cluster_results(submits_per_second)
   set test_data(submits_per_second)  $cluster_results(submits_per_second)

   set test "Jobs per second"
   set table($test) $cluster_results(jobs_per_second)
   set test_data(jobs_per_second) $cluster_results(jobs_per_second)

   set test "Utilization (Slot allocation)"
   set table($test) $cluster_results(utilization)
   set test_data(utilization)  $cluster_results(utilization)


   set test "Average Submit time"
   set table($test) $avg_values(avg_submit)
   set test_data(avg_submit) $avg_values(avg_submit)
  
   set test "Average run/transfer time"
   set table($test) $avg_values(avg_run)
   set test_data(avg_run) $avg_values(avg_run)

   set test "Average scheduler calculation time"
   set table($test) $avg_schedd_values(avg_schedd_time)
   set test_data(avg_schedd_time) $avg_schedd_values(avg_schedd_time)

   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   spool_array_to_file $output_dir/test_results_array.dat "test results" test_data



   # links to other documents
   append content [ create_html_text "" ]
   append content [create_html_link "   (1) Running job analysis" "running_jobs.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (2) Job time analysis" "job_times.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (3) Job time analysis" "job_distribution.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (4) Pending job analysis" "pending_jobs.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (5) Scheduler calculation time analysis" "schedd_calc_time.html"]
   append content [ create_html_text "" ]
   append content [create_html_link "   (6) Scheduler job order analysis" "schedd_orders.html"]
   append content [ create_html_text "" ]
   if { $throughput_sharetree == 1 }  {
      append content [create_html_link "   (7) Running project job analysis" "project_jobs.html"]
      append content [ create_html_text "" ]
      append content [create_html_link "   (8) All charts in one html document" "all_charts.html"]
   } else {
      append content [create_html_link "   (7) All charts in one html document" "all_charts.html"]
   }

   # links to data
   append content [ create_html_text "" ]
   append content [ create_html_text "" ]
   append content [ create_html_text "Links to test data:" ]
   
   append content [ create_html_text "" ]
   append content [create_html_link "   Cluster Time data" "cluster_times.txt"]
   append content [ create_html_text "" ]
   append content [create_html_link "   Job Time data" "job_times.txt"]
   append content [ create_html_text "" ]
   append content [create_html_link "   Scheduler Time data" "schedd_times.txt"]

   
   # links to object dumps
   append content [ create_html_text "" ]
   append content [ create_html_text "" ]
   append content [ create_html_text "Links to configuration data:" ]

   append content [ create_html_text "" ]
   append content [create_html_link "   Testsuite configuration" "#test_config"]

   append content [ create_html_text "" ]
   append content [create_html_link "   Testsuite scheduler configuration" "#schedd_config"]

   foreach execd $host_list(host_list) { 
      append content [ create_html_text "" ]
      append content [create_html_link "   Execution host $execd" "#execd $execd"]

      append content [ create_html_text "" ]
      append content [create_html_link "   Configuration for host $execd" "#config execd $execd"]
   }


   # apendix
   append content [ create_html_text "" ]
   append content "<hr WIDTH=\"100%\">"
   append content [ create_html_text "Appendix" 1]
   append content "<hr WIDTH=\"100%\">"

   # host architecture list
   append content [create_html_target "Execd list"]
   append content [create_html_text "The test run used the following execution hosts:"]
   unset table
   set table(Hostname) "Architecture"
   foreach host $execd_list {
      set table($host) [resolve_arch $host]
   }
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file "table" table
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]


   # test_config
   append content [create_html_target "test_config"]
   append content [create_html_text "Testsuite configration data:"]
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file test_config test_config
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   # schedd_config
   append content [create_html_target "schedd_config"]
   append content [create_html_text "Cluster scheduler configuration file:"]
   set tmp_file [get_tmp_file_name]
   spool_array_to_file $tmp_file schedd_config schedd_config  
   append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]

   # configurations
   set nr_of_local_spool_directories 0

   foreach execd $host_list(host_list) { 
      read_array_from_file $file "execd $execd" execd_array
      append content [create_html_target "execd $execd"]
      append content [create_html_text "Execd $execd:"]
      set tmp_file [get_tmp_file_name]
      spool_array_to_file $tmp_file execd_array execd_array
      append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]
      unset execd_array

      read_array_from_file $file "config execd $execd" config_array

      if { $execd != "global" } {
         if { [info exists config_array(execd_spool_dir)] } {
            incr nr_of_local_spool_directories 1
         }
      }


      append content [create_html_target "config execd $execd"]
      append content [create_html_text "Execd configuration for $execd:"]
      set tmp_file [get_tmp_file_name]
      spool_array_to_file $tmp_file config_array config_array
      append content [convert_spool_file_to_html $tmp_file $output_dir/index.html 1]
      unset config_array
   }
   



   generate_html_file $output_dir/index.html "Testsuite Throughput Test Status Report from $test_config(test_date)" $content

   # spool addition test information into test_results_array.dat
   set info_data(end_job_count) $test_config(end_job_count)
   set info_data(enable_queues_job_count)  $test_config(enable_queues_job_count)
   set info_data(global_job_run_time) $test_config(global_job_run_time)
   set info_data(nr_queues) $test_config(nr_queues)
   set info_data(nr_slots_per_queue) $test_config(nr_slots_per_queue)
   set info_data(FLUSH_SUBMIT_SEC) $test_config(FLUSH_SUBMIT_SEC)
   set info_data(FLUSH_FINISH_SEC) $test_config(FLUSH_FINISH_SEC)
   set info_data(SCHEDULE_INTERVAL) $test_config(SCHEDULE_INTERVAL)
   set info_data(hostlist) $host_list(host_list)
   set info_data(nr_of_local_spool_directories) $nr_of_local_spool_directories   
   spool_array_to_file $output_dir/test_results_array.dat "test settings" info_data


   

   # generate chart files
   set content ""
   append content ""
   append content [create_html_image "Running jobs" "running_jobs.gif"]
   generate_html_file $output_dir/running_jobs.html "$test_config(gridengine_version) from $test_config(test_date)" $content

   if { $throughput_sharetree == 1 }  {
      set content ""
      append content ""
      append content [create_html_image "Running project jobs" "project_jobs.gif"]
      generate_html_file $output_dir/project_jobs.html "$test_config(gridengine_version) from $test_config(test_date)" $content
   }
   
   set content ""
   append content ""
   append content [create_html_image "Job times" "job_times.gif"]
   generate_html_file $output_dir/job_times.html "$test_config(gridengine_version) from $test_config(test_date)" $content
 
    set content ""
   append content ""
   append content [create_html_image "Job distribution" "job_distribution.gif"]
   generate_html_file $output_dir/job_distribution.html "$test_config(gridengine_version) from $test_config(test_date)" $content


   set content ""
   append content ""
   append content [create_html_image "Pending jobs" "pending_jobs.gif"]
   generate_html_file $output_dir/pending_jobs.html "$test_config(gridengine_version) from $test_config(test_date)" $content

   set content ""
   append content ""
   append content [create_html_image "Scheduler times" "schedd_calc_time.gif"]
   generate_html_file $output_dir/schedd_calc_time.html "$test_config(gridengine_version) from $test_config(test_date)" $content

   set content ""
   append content ""
   append content [create_html_image "Scheduler orders" "schedd_orders.gif"]
   generate_html_file $output_dir/schedd_orders.html "$test_config(gridengine_version) from $test_config(test_date)" $content

   set content ""
   append content ""
   append content [create_html_image "Running jobs" "running_jobs.gif"]
   append content [create_html_image "Job times" "job_times.gif"]
   append content [create_html_image "Job distribution" "job_distribution.gif"]
   append content [create_html_image "Pending jobs" "pending_jobs.gif"]
   append content [create_html_image "Scheduler times" "schedd_calc_time.gif"]
   append content [create_html_image "Scheduler orders" "schedd_orders.gif"]
   if { $throughput_sharetree == 1 }  {
      append content [create_html_image "Running project jobs" "project_jobs.gif"]
   }
   generate_html_file $output_dir/all_charts.html "$test_config(gridengine_version) from $test_config(test_date)" $content


   # plot diagrams
   # get functions for test run  and schedd data
       # 1) test run
       calculate_test_run_xy_rows results xy_rows 0
       # 2) schedd run
       set test_start $results(0,test_run_time)
       calculate_schedd_run_xy_rows schedd xy_rows $test_start 0
       # 3) job submit times and job run times
       calculate_submit_run_xy_rows jobs xy_rows $test_start 0

       # 4) optional: calculate project times 
       if { $throughput_sharetree == 1 }  {
          calculate_project_run_xy_rows results jobs xy_rows 0
       }

       set plot_data(xlabel) "time\[s\]"
       set plot_data(ylabel) "values"

       set plot_data(title) "Throughput test results - running jobs"
       set plot_data(output_file) "$output_dir/running_jobs.gif"
       set xy_rows(0,show)  1     ;# running jobs
       set xy_rows(1,show)  0     ;# pending jobs
       set xy_rows(2,show)  0     ;# jobs done
       set xy_rows(3,show)  0     ;# jobs subitted
       set xy_rows(4,show)  1     ;# total system slots
       set xy_rows(5,show)  1     ;# free system slots
       set xy_rows(6,show)  0     ;# schedduler calculation time
       set xy_rows(7,show)  0     ;# schedd orders
       set xy_rows(8,show)  0     ;# job submit time
       set xy_rows(9,show)  0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution
       set xy_rows(11,show) 0     ;# running jobs project 1
       set xy_rows(12,show) 0     ;# running jobs project 2
       set xy_rows(13,show) 0     ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows
        


       set plot_data(title) "Throughput test results - pending jobs"
       set plot_data(output_file) "$output_dir/pending_jobs.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 1     ;# pending jobs
       set xy_rows(2,show) 1     ;# jobs done
       set xy_rows(3,show) 1     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0    ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - schedd calculation time"
       set plot_data(output_file) "$output_dir/schedd_calc_time.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 1     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - schedd orders"
       set plot_data(output_file) "$output_dir/schedd_orders.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 1     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - job times"
       set plot_data(output_file) "$output_dir/job_times.gif"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 1     ;# job submit time
       set xy_rows(9,show) 1     ;# job run time
       set xy_rows(10,show) 0     ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows

       set plot_data(title) "Throughput test results - job distribution"
       set plot_data(output_file) "$output_dir/job_distribution.gif"
       set plot_data(xlabel) "job time\[s\]"
       set plot_data(ylabel) "number of jobs"
       set xy_rows(0,show) 0     ;# running jobs
       set xy_rows(1,show) 0     ;# pending jobs
       set xy_rows(2,show) 0     ;# jobs done
       set xy_rows(3,show) 0     ;# jobs subitted
       set xy_rows(4,show) 0     ;# total system slots
       set xy_rows(5,show) 0     ;# free system slots
       set xy_rows(6,show) 0     ;# schedduler calculation time
       set xy_rows(7,show) 0     ;# schedd orders
       set xy_rows(8,show) 0     ;# job submit time
       set xy_rows(9,show) 0     ;# job run time
       set xy_rows(10,show) 1    ;# job distribution
       set xy_rows(11,show) 0    ;# running jobs project 1
       set xy_rows(12,show) 0    ;# running jobs project 2
       set xy_rows(13,show) 0    ;# running jobs project 3
       create_gnuplot_xy_gif plot_data xy_rows


       if { $throughput_sharetree == 1 }  {
         set plot_data(xlabel) "time\[s\]"
         set plot_data(ylabel) "jobs done\[%\]"
         set plot_data(title) "Throughput test results - project jobs"
         set plot_data(output_file) "$output_dir/project_jobs.gif"
         set xy_rows(0,show)  0     ;# running jobs
         set xy_rows(1,show)  0     ;# pending jobs
         set xy_rows(2,show)  0     ;# jobs done
         set xy_rows(3,show)  0     ;# jobs subitted
         set xy_rows(4,show)  0     ;# total system slots
         set xy_rows(5,show)  0     ;# free system slots
         set xy_rows(6,show)  0     ;# schedduler calculation time
         set xy_rows(7,show)  0     ;# schedd orders
         set xy_rows(8,show)  0     ;# job submit time
         set xy_rows(9,show)  0     ;# job run time
         set xy_rows(10,show) 0     ;# job distribution
         set xy_rows(11,show) 1     ;# running jobs project 1
         set xy_rows(12,show) 1     ;# running jobs project 2
         set xy_rows(13,show) 1     ;# running jobs project 3
         create_gnuplot_xy_gif plot_data xy_rows
       }
}


proc calculate_schedd_run_xy_rows { results_array_name row_array_name test_start start_numb } {
   upvar $results_array_name schedd
   upvar $row_array_name xy_rows


   set add_info " A"
   if { $start_numb != 0 } {
      set add_info " B"
   }

       set pos1 [ expr ( $start_numb + 6 ) ]
       set pos2 [ expr ( $start_numb + 7 ) ]

        #  2) schedd run
       if { $schedd(count) > 0 } {
          set xy_rows($pos1,drawmode) "lines"
          set xy_rows($pos1,title) "schedduler calculation time $add_info"

          set xy_rows($pos2,drawmode) "lines"
          set xy_rows($pos2,title) "schedd orders $add_info"

          set last $schedd(count)
          # core data: job_run_time
          for { set i 0 } { $i <= $last } { incr i 1 } {
             set x_time        [ expr ( $schedd($i,system_time) - $test_start) ]  ;# test run time in seconds
             
             #   x->time y->schedd_time
             set xy_rows($pos1,$i,x) $x_time
             set xy_rows($pos1,$i,y) $schedd($i,schedd_time)

             #   x->time y->schedd_orders
             set xy_rows($pos2,$i,x) $x_time
             set xy_rows($pos2,$i,y) $schedd($i,schedd_orders)

          }
       }
   
   
}
proc calculate_submit_run_xy_rows { results_array_name row_array_name test_start start_numb} {
   upvar $results_array_name jobs
   upvar $row_array_name xy_rows

   set pos1 [ expr ( $start_numb + 8 ) ]
   set pos2 [ expr ( $start_numb + 9 ) ]
   set pos3 [ expr ( $start_numb + 10) ]

   set add_info " A"
   if { $start_numb != 0 } {
      set add_info " B"
   }


       #  3) job submit times and job run times
       set xy_rows($pos1,drawmode) "points"
       set xy_rows($pos1,title) "job submit time $add_info"

       set xy_rows($pos2,drawmode) "points"
       set xy_rows($pos2,title) "job run time $add_info"
 
       set xy_rows($pos3,drawmode) "linespoints" ;#"points"
       set xy_rows($pos3,title) "job run time distribution $add_info"


       set job 0

       set min_run_time 100000
       set max_run_time 0
       if { [info exists run_time_values ] } {
          unset run_time_values
       }       
       while { [info exists jobs($job,job_id) ] } {

          set normalized_submit_end_time [ expr ( $jobs($job,submit_end_time) - $test_start ) ]
          set normalized_run_end_time    [ expr ( $jobs($job,run_end_time)    - $test_start ) ]

          set submit_time [ expr ( $jobs($job,submit_end_time) - $jobs($job,submit_start_time) ) ]
          set run_time    [ expr ( $jobs($job,run_end_time)    - $jobs($job,run_start_time)    ) ]                    

          #   x->time y->submit_time
          set xy_rows($pos1,$job,x) $normalized_submit_end_time
          set xy_rows($pos1,$job,y) $submit_time

          #   x->time y->run_time
          set xy_rows($pos2,$job,x) $normalized_run_end_time
          set xy_rows($pos2,$job,y) $run_time
          if { $min_run_time > $run_time } {
             set min_run_time $run_time
          }
          if { $max_run_time < $run_time } {
             set max_run_time $run_time
          }
          if { [info exists run_time_values($run_time)] } {
             incr run_time_values($run_time) 1
          } else {
             set run_time_values($run_time) 1
          }
          incr job 1
       }
   
       set counter 0
       for { set i $min_run_time } { $i <= $max_run_time } { incr i 1 } {
          if { [ info exists run_time_values($i)] } {
             #   x->job time y->number of jobs with that runtime
             set xy_rows($pos3,$counter,x) $i
             set xy_rows($pos3,$counter,y) $run_time_values($i)
             incr counter 1
          }
       }
}


proc calculate_project_run_xy_rows { results_array_name job_array_name row_array_name start_numb } {
   global CHECK_OUTPUT
   upvar $results_array_name results
   upvar $job_array_name jobs
   upvar $row_array_name xy_rows

   set pos1 [ expr ( $start_numb + 11 ) ]
   set pos2 [ expr ( $start_numb + 12 ) ]
   set pos3 [ expr ( $start_numb + 13 ) ]

   set add_info " A"
   if { $start_numb != 0 } {
      set add_info " B"
   }


       if { $results(count) > 0 } {
          set xy_rows($pos1,drawmode) "lines"
          set xy_rows($pos1,title) "running jobs project1 (32 %) $add_info"

          set xy_rows($pos2,drawmode) "lines"
          set xy_rows($pos2,title) "running jobs project2 (48 %) $add_info"

          set xy_rows($pos3,drawmode) "lines"
          set xy_rows($pos3,title) "running jobs project3 (20 %) $add_info"

          set last $results(count)
          incr last -1

          set test_start $results(0,test_run_time)

          set job 0
          set jobs_p1 0
          set jobs_p2 0
          set jobs_p3 0
          set help_list ""
          while { [info exists jobs($job,job_id) ] } {

             set normalized_run_end_time    [ expr ( $jobs($job,run_end_time) - $test_start ) ]
             set job_project $jobs($job,project)

             if { [info exists help($normalized_run_end_time,p1)] == 0 } {
                set help($normalized_run_end_time,p1) 0
             }
             if { [info exists help($normalized_run_end_time,p2)] == 0 } {
                set help($normalized_run_end_time,p2) 0
             }
             if { [info exists help($normalized_run_end_time,p3)] == 0 } {
                set help($normalized_run_end_time,p3) 0
             }

             if { $job_project == 1 } {
                
                incr help($normalized_run_end_time,p1) 1
             }
             if { $job_project == 2 } {
                incr help($normalized_run_end_time,p2) 1

             }
             if { $job_project == 3 } {
                incr help($normalized_run_end_time,p3) 1
             }
             if { [lsearch $help_list $normalized_run_end_time] < 0  } {
                lappend help_list $normalized_run_end_time
             }
             incr job 1
          }
          set all_jobs $job

          set job 0
          set help_sort [lsort -integer $help_list]
          set jobs_p1 0
          set jobs_p2 0
          set jobs_p3 0

          foreach elem $help_sort {
             incr jobs_p1 $help($elem,p1)
             incr jobs_p2 $help($elem,p2)
             incr jobs_p3 $help($elem,p3)
             set current_job_count [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3 ) ]

             set one_percent [ expr ( $current_job_count / 100.00 ) ]
             set p1_p [ expr ( $jobs_p1 / $one_percent ) ]
             set p2_p [ expr ( $jobs_p2 / $one_percent ) ]
             set p3_p [ expr ( $jobs_p3 / $one_percent ) ]

             puts $CHECK_OUTPUT $elem
             # project 1
             set xy_rows($pos1,$job,x) $elem
             set xy_rows($pos1,$job,y) $p1_p
             # project 2
             set xy_rows($pos2,$job,x) $elem 
             set xy_rows($pos2,$job,y) $p2_p
             # project 3
             set xy_rows($pos3,$job,x) $elem 
             set xy_rows($pos3,$job,y) $p3_p
             incr job 1
          }
          puts $CHECK_OUTPUT "all_jobs=$all_jobs, [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3 ) ]"
          if { [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3 ) ] != $all_jobs } {
             add_proc_error "calculate_project_run_xy_rows" -1 "error job count all_jobs=$all_jobs, not [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3 ) ]"
          }

# ---          for { set i 0 } { $i <= $last } { incr i 1 } {
# ---             set x_time        [ expr ( $results($i,test_run_time) - $test_start) ]  ;# test run time in seconds
# ---            
# ---             set running_job_ids $results($i,job_ids_running)
# ---             set jobs_p1 0
# ---             set jobs_p2 0
# ---             set jobs_p3 0
# ---             foreach jb $running_job_ids {
# ---                set sub_id [get_submit_id_from_job_id jobs $jb]
# ---                set job_project $jobs($sub_id,project)
# ---                if { $job_project == 1 } {
# ---                   incr jobs_p1 1
# ---                }
# ---                if { $job_project == 2 } {
# ---                   incr jobs_p2 1
# ---                }
# ---                if { $job_project == 3 } {
# ---                   incr jobs_p3 1
# ---                }
# ---             }
# ---
# ---             if { [ expr ( $jobs_p1 + $jobs_p2 + $jobs_p3  ) ] != $results($i,jobs_running)  } {
# ---                add_proc_error "calculate_project_run_xy_rows" -1 "error: number of running jobs sum error"
# ---             }
# ---             set one_percent [ expr ( (0.000 + $results($i,jobs_running)) / 100 ) ]
# ---             set p1_p [ expr ( $jobs_p1 *  $one_percent  ) ]
# ---             set p2_p [ expr ( $jobs_p2 *  $one_percent  ) ]
# ---             set p3_p [ expr ( $jobs_p3 *  $one_percent  ) ]
# ---
# ---
# ---             # project 1
# ---             set xy_rows($pos1,$pro_pos_1,x) $x_time
# ---             set xy_rows($pos1,$pro_pos_1,y) $p1_p ;# $results($i,jobs_running)
# ---             incr pro_pos_1 1
# ---
# ---             # project 2
# ---             set xy_rows($pos2,$pro_pos_2,x) $x_time
# ---             set xy_rows($pos2,$pro_pos_2,y) $p2_p ;# $results($i,jobs_running)
# ---             incr pro_pos_2 1
# ---
# ---             # project 3
# ---             set xy_rows($pos3,$pro_pos_3,x) $x_time
# ---             set xy_rows($pos3,$pro_pos_3,y) $p3_p ;# $results($i,jobs_running)
# ---             incr pro_pos_3 1
# ---          }
       }
}



proc calculate_test_run_xy_rows { results_array_name row_array_name start_numb } {
   upvar $results_array_name results
   upvar $row_array_name xy_rows

   set pos1 $start_numb 
   set pos2 [ expr ( $start_numb + 1 ) ]
   set pos3 [ expr ( $start_numb + 2 ) ]
   set pos4 [ expr ( $start_numb + 3 ) ]
   set pos5 [ expr ( $start_numb + 4 ) ]
   set pos6 [ expr ( $start_numb + 5 ) ]

   set add_info " A"
   if { $start_numb != 0 } {
      set add_info " B"
   }


   #  1) test run
       if { $results(count) > 0 } {
          set xy_rows($pos1,drawmode) "lines"
          set xy_rows($pos1,title) "running jobs $add_info"

          set xy_rows($pos2,drawmode) "lines"
          set xy_rows($pos2,title) "pending jobs $add_info"

          set xy_rows($pos3,drawmode) "lines"
          set xy_rows($pos3,title) "jobs done $add_info"

          set xy_rows($pos4,drawmode) "lines"
          set xy_rows($pos4,title) "jobs subitted $add_info"

          set xy_rows($pos5,drawmode) "lines"
          set xy_rows($pos5,title) "total system slots $add_info"

          set xy_rows($pos6,drawmode) "lines"
          set xy_rows($pos6,title) "free system slots $add_info"


          set last $results(count)
          incr last -1

          set test_start $results(0,test_run_time)
          # core data: job_run_time
          for { set i 0 } { $i <= $last } { incr i 1 } {
             set x_time        [ expr ( $results($i,test_run_time) - $test_start) ]  ;# test run time in seconds
             
             #   x->time y->jobs_running                                 
             set xy_rows($pos1,$i,x) $x_time
             set xy_rows($pos1,$i,y) $results($i,jobs_running)

             #   x->time y->jobs_pending
             set xy_rows($pos2,$i,x) $x_time
             set xy_rows($pos2,$i,y) $results($i,jobs_pending)

             #   x->time y->jobs_done
             set xy_rows($pos3,$i,x) $x_time
             set xy_rows($pos3,$i,y) $results($i,jobs_done)

             #   x->time y->jobs_submitted
             set xy_rows($pos4,$i,x) $x_time
             set xy_rows($pos4,$i,y) $results($i,jobs_submitted)

             #   x->time y->total_slots
             set xy_rows($pos5,$i,x) $x_time
             set xy_rows($pos5,$i,y) $results($i,total_slots)

             #   x->time y->free_slots
             set xy_rows($pos6,$i,x) $x_time
             set xy_rows($pos6,$i,y) $results($i,free_slots)
          }
       }
   
}

proc create_reports { results_array job_array_name schedd_array_name} {
   global CHECK_OUTPUT CHECK_PROTOCOL_DIR check_name throughput_subdir
   global CHECK_CORE_EXECD CHECK_HOST CHECK_USER
   global end_job_count                 ;# number of jobs
   global enable_queues_job_count         ;# after with job, enable queues
   global nr_queues                       ;# nr of queues on each host
   global nr_slots
   global global_job_run_time            ;# job sleep parameter
   global FLUSH_SUBMIT_SEC              ;# -1 or 0,1,2,3 ...
   global FLUSH_FINISH_SEC             ;# -1 or 0,1,2,3 ...
   global run_throughput_test_SCHEDULE_INTERVAL        ;# 00:00:30 ...
   global ts_host_config

   upvar $job_array_name jobs
   upvar $results_array results
   upvar $schedd_array_name schedd

   set nr_of_execd_hosts [llength $CHECK_CORE_EXECD]
   incr nr_of_execd_hosts -1

   set have_local_spool_dir 0
   foreach elem $CHECK_CORE_EXECD {
      set spool_dir ""
      if { [info exists ts_host_config($elem,spooldir)] } {
         set spool_dir $ts_host_config($elem,spooldir)
      }
      puts $CHECK_OUTPUT "spooldir on host $elem: $spool_dir"
      if { $spool_dir != "" } {
         set have_local_spool_dir 1
      }
   }
  
   if { $have_local_spool_dir == 1 } {
      set prot_output_dir "$CHECK_PROTOCOL_DIR/$check_name/$throughput_subdir/local_spool/_${nr_of_execd_hosts}_execds/_${end_job_count}_jobs"

   } else {
      set prot_output_dir "$CHECK_PROTOCOL_DIR/$check_name/$throughput_subdir/_${nr_of_execd_hosts}_execds/_${end_job_count}_jobs"

   }

   puts $CHECK_OUTPUT "saving report in directory:"
   puts $CHECK_OUTPUT $prot_output_dir
   file mkdir $prot_output_dir

   set files [get_file_names $prot_output_dir "saved_run*"]
   # saved_run.x
   set run_nr 1
   foreach file $files {
      puts $CHECK_OUTPUT "file: $file"
      set act_run [file extension $file]
      set act_run [string range $act_run 1 end]
      puts $CHECK_OUTPUT "act-run: $act_run"
      if { [ string is integer $act_run ] } {
      if { $act_run >= $run_nr } {
         set run_nr $act_run
         incr run_nr 1
      }
      }
   } 
   set prot_output_file "${prot_output_dir}/saved_run.${run_nr}"
   puts $CHECK_OUTPUT "using filename:"
   puts $CHECK_OUTPUT $prot_output_file


   # execd configuration for each host
   set host_list $CHECK_CORE_EXECD
   lappend host_list "global"
   set h_list_array(host_list) $host_list
   spool_array_to_file $prot_output_file "execd list" h_list_array

   set nr_of_local_spool_directories 0
   foreach execd $host_list {
      get_exechost execd_array $execd
      spool_array_to_file $prot_output_file "execd $execd" execd_array
      unset execd_array

      get_config config_array $execd
      spool_array_to_file $prot_output_file "config execd $execd" config_array
      if { [info exists config_array(execd_spool_dir)] } {
         incr nr_of_local_spool_directories 1
      }
      unset config_array
   }
   
   # save scheduler configuration into file
   get_schedd_config schedd_config
   spool_array_to_file $prot_output_file "schedd config" schedd_config

   # set test configuration
   set test_config(end_job_count)           $end_job_count            ;# number of jobs
   set test_config(enable_queues_job_count) $enable_queues_job_count  ;# after with job, enable queues
   set test_config(nr_queues)               $nr_queues                ;# nr of queues on each host
   set test_config(nr_slots_per_queue)      $nr_slots                 ;# nr of slots per queue
   set test_config(global_job_run_time)     $global_job_run_time      ;# job sleep parameter
   set test_config(FLUSH_SUBMIT_SEC)        $FLUSH_SUBMIT_SEC         ;# -1 or 0,1,2,3 ...
   set test_config(FLUSH_FINISH_SEC)        $FLUSH_FINISH_SEC         ;# -1 or 0,1,2,3 ...
   set test_config(SCHEDULE_INTERVAL)       $run_throughput_test_SCHEDULE_INTERVAL        ;# 00:00:30 ...
   set test_config(gridengine_version)      [get_version_info]
   set test_config(test_date)               [exec date]
   
   spool_array_to_file $prot_output_file "test configuration" test_config

   # spool everything to file (without comment line)
   spool_array_to_file $prot_output_file "online data"    results 0
   spool_array_to_file $prot_output_file "job data"       jobs    0
   spool_array_to_file $prot_output_file "scheduler data" schedd  0

   catch { file delete ${prot_output_file}.old }

   # job results
   calculate_average_cluster_times results cluster_results
   puts $CHECK_OUTPUT "total run time     : $cluster_results(total_run_time)"
   puts $CHECK_OUTPUT "total jobs done    : $cluster_results(total_jobs_done)"
   puts $CHECK_OUTPUT "total submit time  : $cluster_results(total_submit_time)"
   puts $CHECK_OUTPUT "submits per second : $cluster_results(submits_per_second)"
   puts $CHECK_OUTPUT "jobs per second    : $cluster_results(jobs_per_second)"
   puts $CHECK_OUTPUT "avg. slots free    : $cluster_results(avg_slots_free)"
   puts $CHECK_OUTPUT "total slots        : $cluster_results(total_slots)"
   puts $CHECK_OUTPUT "utilization        : $cluster_results(utilization)"
   puts $CHECK_OUTPUT "job sleep time     : $cluster_results(jobs_sleep_time)"
   puts $CHECK_OUTPUT "queue enable value : $cluster_results(queue_enable_value)"
   puts $CHECK_OUTPUT "flush submit sec   : $cluster_results(flush_submit_sec)"
   puts $CHECK_OUTPUT "flush finish sec   : $cluster_results(flush_finish_sec)"
   puts $CHECK_OUTPUT "schedule interval  : $cluster_results(schedule_interval)"


   calculate_average_job_times jobs avg_values
   puts $CHECK_OUTPUT ""
   puts $CHECK_OUTPUT "avg. submit       (count=$avg_values(jobs_submit))   : $avg_values(avg_submit) "
   puts $CHECK_OUTPUT "avg. run/transfer (count=$avg_values(jobs_run))   : $avg_values(avg_run)    "

   calculate_average_schedd_times schedd avg_schedd_values
   puts $CHECK_OUTPUT ""
   puts $CHECK_OUTPUT "avg. schedd time (count=$avg_schedd_values(nr_of_schedd_runs))   : $avg_schedd_values(avg_schedd_time)"

   analyse_dump_data_file $prot_output_file 1
   compare_dump_directory $prot_output_dir
#   puts $CHECK_OUTPUT "do gzip $prot_output_file ..."
#   puts $CHECK_OUTPUT [start_remote_prog $CHECK_HOST $CHECK_USER gzip $prot_output_file prg_exit_state 60 0 "" 1 0 0]
   
   
}

proc calculate_average_cluster_times { results_array cluster_results_array { dump_file "" } } {
   global CHECK_OUTPUT enable_queues_job_count
   global FLUSH_SUBMIT_SEC FLUSH_FINISH_SEC run_throughput_test_SCHEDULE_INTERVAL
   upvar $results_array cluster
   upvar $cluster_results_array result

   set result(total_run_time)    0    ;#
   set result(total_jobs_done)   0    ;#
   set result(total_submit_time) 0    ;#
   set result(submits_per_second) 0   ;#
   set result(jobs_per_second) 0      ;#
   set result(utilization) 0          ;#
   set result(jobs_sleep_time)  0      ;#
   set result(queue_enable_value) $enable_queues_job_count    ;#
   set result(flush_submit_sec) $FLUSH_SUBMIT_SEC
   set result(flush_finish_sec) $FLUSH_FINISH_SEC
   set result(schedule_interval) $run_throughput_test_SCHEDULE_INTERVAL

   

   if { $cluster(count) > 0 } {
      set result(avg_slots_free) $cluster(0,total_slots)  ;# avg_slots_free
      set result(total_slots) $cluster(0,total_slots)     ;# total_slots
      set result(jobs_sleep_time) $cluster(0,job_run_time) ;#
   } else {
      set result(avg_slots_free) 0
      set result(total_slots) 0
      return -1
   }

   if { $dump_file != "" } {
      set dump_file [open $dump_file w]
      
      puts $dump_file "nr|jobs_done|jobs_running|jobs_pending|jobs_submitted|total_slots|free_slots|job_run_time|test_run_time"
   }

   
   set last $cluster(count)
   incr last -1

   # calculate
   set result(total_run_time)    [ expr ($cluster($last,test_run_time)  - $cluster(0,test_run_time) ) ]
   set result(total_jobs_done)   $cluster($last,jobs_done)

   # pass 1
   set highest_submit_count 0
   set last_time 0
   set second 0
   set sum_free_slots 0
   for { set i 0 } { $i <= $last } { incr i 1 } {
      if { $cluster($i,jobs_submitted) > $highest_submit_count } {
         set highest_submit_count $cluster($i,jobs_submitted)
      }
      if { $cluster($i,test_run_time) > $last_time } {
         incr second 1
         set last_time $cluster($i,test_run_time)
         set free_slots $cluster($i,free_slots)
         incr sum_free_slots $free_slots
      }
      # spool data to file
      if { $dump_file != "" } {
         set line "$i|$cluster($i,jobs_done)|$cluster($i,jobs_running)|$cluster($i,jobs_pending)|$cluster($i,jobs_submitted)|$cluster($i,total_slots)|$cluster($i,free_slots)|$cluster($i,job_run_time)|$cluster($i,test_run_time)"
         puts $dump_file $line
      }

   }
   if { $dump_file != "" } {
      close $dump_file
   }

   if { $second > 0 } {
      set result(avg_slots_free) [ expr ( $sum_free_slots.00 / $second  ) ]
   }

   # pass 2
   for { set i $last } { $i >= 0 } { incr i -1 } {
      if { $cluster($i,jobs_submitted) == $highest_submit_count } {
         # this is the last submit job
         set result(total_submit_time) [ expr ($cluster($i,test_run_time)  - $cluster(0,test_run_time) ) ]
      }
   }
   
   if { $result(total_submit_time) > 0 } { 
      set result(submits_per_second) [ expr ( ${highest_submit_count}.00 / $result(total_submit_time) ) ]
   }

   if { $result(total_run_time) > 0 } {
      set result(jobs_per_second) [ expr ( $result(total_jobs_done).00 / $result(total_run_time) ) ]
   }

   set one_p [ expr ( $result(total_slots).00 / 100  ) ]
   if { $one_p > 0 } {
      set result(utilization) [ expr ( ( 100.00 - ($result(avg_slots_free)+ 0.00) / $one_p )) ]
   }


#   puts $CHECK_OUTPUT ""
#   puts $CHECK_OUTPUT "total run time     : $result(total_run_time)"
#   puts $CHECK_OUTPUT "total jobs done    : $result(total_jobs_done)"
#   puts $CHECK_OUTPUT "total submit time  : $result(total_submit_time)"
#   puts $CHECK_OUTPUT "submits per second : $result(submits_per_second)"
#   puts $CHECK_OUTPUT "jobs per second    : $result(jobs_per_second)"
#   puts $CHECK_OUTPUT "avg. slots free    : $result(avg_slots_free)"
#   puts $CHECK_OUTPUT "total slots        : $result(total_slots)"
#   puts $CHECK_OUTPUT "utilization        : $result(utilization)"
#   puts $CHECK_OUTPUT "job sleep time     : $result(jobs_sleep_time)"
#   puts $CHECK_OUTPUT "queue enable value : $result(queue_enable_value)"
#   puts $CHECK_OUTPUT "flush submit sec   : $result(flush_submit_sec)"
#   puts $CHECK_OUTPUT "flush finish sec   : $result(flush_finish_sec)"
#   puts $CHECK_OUTPUT "schedule interval  : $result(schedule_interval)"
   return 0
}

proc calculate_average_job_times { job_array_name job_results_array { dump_file "" }} {
   global CHECK_OUTPUT
   upvar $job_array_name jobs
   upvar $job_results_array result
   
   set submit_sum 0
   set run_sum 0
   set submit_job_count  0
   set run_job_count 0
   set job 0
   if { $dump_file != "" } {
      set dump_file [open $dump_file w]
      puts $dump_file "nr|jobid|submit_time|run_time|state|submit_start|submit_finish|run_start|run_finish"
   }
   while { [info exists jobs($job,job_id) ] } {
      set submit_time 0
      set run_time 0
      if { $jobs($job,submit_end_time) > 0 && $jobs($job,submit_start_time) > 0 } {
         incr submit_job_count 1
         set submit_time [ expr ( $jobs($job,submit_end_time) - $jobs($job,submit_start_time) ) ]
      }
      if { $jobs($job,run_end_time) > 0 && $jobs($job,run_start_time) > 0 } {
         incr run_job_count 1
         set run_time    [ expr ( $jobs($job,run_end_time)    - $jobs($job,run_start_time)    ) ]
#         puts $CHECK_OUTPUT "job_run_time: $run_time"
      }
      set job_id $jobs($job,job_id)

      # add job times
      incr submit_sum $submit_time
      incr run_sum $run_time

      # spool data to file
      if { $dump_file != "" } {
         set line "$job|$jobs($job,job_id)|$submit_time|$run_time|$jobs($job,state)|$jobs($job,submit_start_time)|$jobs($job,submit_end_time)|$jobs($job,run_start_time)|$jobs($job,run_end_time)"
         puts $dump_file $line
      }
      incr job 1
   }
   if { $dump_file != "" } {
      close $dump_file
   }

   # calculate average
   set result(avg_submit)  0                       ;# avg submit time in seconds
   set result(avg_run)     0                       ;# avg run time in seconds
   set result(jobs_submit) $submit_job_count
   set result(jobs_run)    $run_job_count
   if { $submit_job_count > 0 } {
      set result(avg_submit) [ expr (  ( ${submit_sum}.00 ) / $submit_job_count ) ]
   }
   if { $run_job_count > 0 } {
      set result(avg_run)    [ expr (  ( ${run_sum}.00 )   / $run_job_count ) ]
   }
}


proc calculate_average_schedd_times { schedd_array_name schedd_results_array { dump_file "" }} {
   global CHECK_OUTPUT
   upvar $schedd_array_name schedd_array
   upvar $schedd_results_array result
   
   set schedd 0
   set schedd_time_sum 0
   if { $dump_file != "" } {
      set dump_file [open $dump_file w]
      puts $dump_file "nr|system_time|schedd_time|schedd_orders|data_line"
   }

   while { [info exists schedd_array($schedd,schedd_time) ] } {
      set schedd_id_run_time $schedd_array($schedd,schedd_time)

      # add schedd times
      set schedd_time_sum [ expr ( $schedd_time_sum + $schedd_id_run_time ) ]

      if { $dump_file != "" } {
         set line "$schedd|$schedd_array($schedd,system_time)|$schedd_array($schedd,schedd_time)|$schedd_array($schedd,schedd_orders)|$schedd_array($schedd,data_line)"
         puts $dump_file $line
      }

      incr schedd 1
   }

   if { $dump_file != "" } {
      close $dump_file
   }


   # calculate average
   set result(avg_schedd_time) 0
   set result(nr_of_schedd_runs) $schedd
   if { $schedd > 0 } {
      set result(avg_schedd_time) [ expr (  ( ($schedd_time_sum + 0.00 ) ) / $schedd ) ]
   }
}


proc show_current_system_status { array_name job_array_name schedd_array_name } {
   global CHECK_OUTPUT

   upvar $array_name data
   upvar $job_array_name jobs
   upvar $schedd_array_name schedd

   # we have one slot per queue !

   clear_screen
   puts $CHECK_OUTPUT "jobs_done        : $data(jobs_done)" 
   puts $CHECK_OUTPUT "jobs_running     : $data(jobs_running)"
#   puts $CHECK_OUTPUT "job ids running  : $data(job_ids_running)"
   puts $CHECK_OUTPUT "jobs_pending     : $data(jobs_pending)"
   puts $CHECK_OUTPUT "jobs_submitted   : $data(jobs_submitted)"
   puts $CHECK_OUTPUT "total slots      : $data(total_slots)"
   puts $CHECK_OUTPUT "free slots       : $data(free_slots)"
   puts $CHECK_OUTPUT "jobs run time    : $data(job_run_time)"
   puts $CHECK_OUTPUT "test run time    : $data(test_run_time)"
   puts $CHECK_OUTPUT "last schedd time : $schedd($schedd(count),schedd_time)"
   puts $CHECK_OUTPUT ""

   # check data
   if { [ expr ( $data(jobs_done) + $data(jobs_running) + $data(jobs_pending) )  ] != $data(jobs_submitted) } {
      add_proc_error "show_current_system_status" -1 "unexpected job count error"
   }
   flush $CHECK_OUTPUT
}

proc clean_current_system_status { results_array array_name job_array_name schedd_array_name } {
   
   global queue_list global_job_run_time nr_slots
   upvar $results_array results
   upvar $array_name data
   upvar $job_array_name jobs
   upvar $schedd_array_name schedd

   set data(jobs_done) 0
   set data(jobs_pending) 0
   set data(jobs_running) 0
   set data(job_ids_running) ""
   set data(jobs_submitted) 0
   set data(total_slots) [ expr ( [llength $queue_list] * $nr_slots ) ]
   set data(free_slots)  $data(total_slots)
   set data(job_run_time) $global_job_run_time
   set data(test_run_time) 0

   if { [ info exists jobs] } {
      unset jobs
   }
   if { [ info exists results] } {
      unset results
   }
   if { [ info exists schedd] } {
      unset results
   }
   set schedd(0,system_time) 0
   set schedd(0,schedd_time) 0
   set schedd(0,schedd_orders) 0
   set schedd(0,data_line) ""
   
   set schedd(count) 0
   set results(count) 0
}
