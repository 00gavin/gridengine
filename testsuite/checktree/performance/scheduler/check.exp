#!/vol2/TCL_TK/glinux/bin/expect --
# expect script 
#___INFO__MARK_BEGIN__
##########################################################################
#
#  The Contents of this file are made available subject to the terms of
#  the Sun Industry Standards Source License Version 1.2
#
#  Sun Microsystems Inc., March, 2001
#
#
#  Sun Industry Standards Source License Version 1.2
#  =================================================
#  The contents of this file are subject to the Sun Industry Standards
#  Source License Version 1.2 (the "License"); You may not use this file
#  except in compliance with the License. You may obtain a copy of the
#  License at http://gridengine.sunsource.net/Gridengine_SISSL_license.html
#
#  Software provided under this License is provided on an "AS IS" basis,
#  WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING,
#  WITHOUT LIMITATION, WARRANTIES THAT THE SOFTWARE IS FREE OF DEFECTS,
#  MERCHANTABLE, FIT FOR A PARTICULAR PURPOSE, OR NON-INFRINGING.
#  See the License for the specific provisions governing your rights and
#  obligations concerning the Software.
#
#  The Initial Developer of the Original Code is: Sun Microsystems, Inc.
#
#  Copyright: 2001 by Sun Microsystems, Inc.
#
#  All Rights Reserved.
#
##########################################################################
#___INFO__MARK_END__


# Define the global veriables to give them back
global check_name check_description check_needs check_functions check_errno check_errstr check_highest_level
global check_init_level_procedure

set check_init_level_procedure "scheduler_perf_init_level"
set check_name                "scheduler_perf"
set check_description(0)     "scheduler_perf job count (functional)"
set check_description(1)     "scheduler_perf job count (functional) without FLUSH_SUBMIT_SEC"
set check_description(300)  " 10 queues / 12000 jobs / FLUSH disabled"
set check_description(301)  "100 queues / 12000 jobs / FLUSH disabled"
set check_description(302)  " 10 queues / 24000 jobs / FLUSH disabled"
set check_description(303)  " 10 queues / 12000 jobs / FLUSH enabled"
set check_description(304)  "100 queues / 12000 jobs / FLUSH enabled"
set check_description(305)  " 10 queues / 12000 jobs / FLUSH enabled"
set check_description(200)  " 50 queues / 25000 jobs / FLUSH enabled"
set check_description(100)  " 50 queues / 2000  jobs / FLUSH disabled"
set check_description(101)  " 50 queues / 2000  jobs / FLUSH  0 sec"
set check_description(102)  " 50 queues / 2000  jobs / FLUSH 10 sec"


set check_needs               "init_core_system"      ;# dependencies of this check (name of other check)
set check_functions           "scheduler_perf_setup_queues"          ;# functions to call (in order)
lappend check_functions       "scheduler_perf_do_perform_test"
lappend check_functions       "scheduler_perf_make_analysis"
lappend check_functions       "scheduler_perf_cleanup_queues"
set check_highest_level       305

global nr_queues
global max_jobs
global pending_jobs
global queue_list
global host_list
global job_times
global stored_configuration
global start_time pending_time end_time
global submit_results
global schedule_results
global scan_time
global schedule_interval
#                                                             max. column:     |
#****** performance/init_level() ******
# 
#  NAME
#     init_level -- ??? 
#
#  SYNOPSIS
#     init_level { } 
#
#  FUNCTION
#     ??? 
#
#  INPUTS
#
#  RESULT
#     ??? 
#
#  EXAMPLE
#     ??? 
#
#  NOTES
#     ??? 
#
#  BUGS
#     ??? 
#
#  SEE ALSO
#     ???/???
#*******************************
proc scheduler_perf_init_level {} {
  global CHECK_ACT_LEVEL CHECK_CORE_EXECD CHECK_OUTPUT
  global nr_queues 
  global max_jobs schedule_results
  global pending_jobs schedule_interval
  global job_times submit_results
  global scan_time FLUSH_FINISH_SEC FLUSH_SUBMIT_SEC

  set submit_results ""
  set schedule_results ""
  set schedule_interval "00:00:30"
  
  switch -- $CHECK_ACT_LEVEL {
  "0"  { 
         set nr_queues 2
         set max_jobs 50
         set pending_jobs 25
         set job_times "5 6 1 2 8"
         set scan_time "1"
         set FLUSH_SUBMIT_SEC 0
         set FLUSH_FINISH_SEC 0
         return 0  
       }
  "1"  { 
         set nr_queues 2
         set max_jobs 50
         set pending_jobs 25
         set job_times "5 6 1 2 8"
         set scan_time "1"
         set FLUSH_SUBMIT_SEC -1
         set FLUSH_FINISH_SEC -1
         return 0  
       }
 

  "300"  { 
           set nr_queues 10
           set max_jobs 12000
           set pending_jobs 5000
           set job_times "15 16 60 2 18"
           set scan_time "5"
           set FLUSH_SUBMIT_SEC -1
           set FLUSH_FINISH_SEC -1
           return 0  
         }
  "301"  { 
           set nr_queues 100
           set max_jobs 12000
           set pending_jobs 5000
           set job_times "15 16 60 2 18"
           set scan_time "5"
           set FLUSH_SUBMIT_SEC -1
           set FLUSH_FINISH_SEC -1
           return 0  
         }
  "302"  { 
           set nr_queues 10
           set max_jobs 24000
           set pending_jobs 10000
           set job_times "15 16 60 2 18"
           set scan_time "5"
           set FLUSH_SUBMIT_SEC -1
           set FLUSH_FINISH_SEC -1
           return 0  
         }
  "303"  { 
           set nr_queues 10
           set max_jobs 12000
           set pending_jobs 5000
           set job_times "15 16 60 2 18"
           set scan_time "5"
           set FLUSH_SUBMIT_SEC 0
           set FLUSH_FINISH_SEC 0
           return 0  
         }
  "304"  { 
           set nr_queues 100
           set max_jobs 12000
           set pending_jobs 5000
           set job_times "15 16 60 2 18"
           set scan_time "5"
           set FLUSH_SUBMIT_SEC 0
           set FLUSH_FINISH_SEC 0
           return 0  
         }
  "305"  { 
           set nr_queues 10
           set max_jobs 24000
           set pending_jobs 10000
           set job_times "15 16 60 2 18"
           set scan_time "5"
           set FLUSH_SUBMIT_SEC 0
           set FLUSH_FINISH_SEC 0
           return 0  
         }

  "200"  { 
           set nr_queues 50
           set max_jobs 25000
           set pending_jobs 12500
           set job_times "15 16 60 12 18"
           set scan_time "10"
           set FLUSH_SUBMIT_SEC 0
           set FLUSH_FINISH_SEC 0

           return 0  
         }

    "100"  { 
           set nr_queues 50     ;# on each host 
           set max_jobs 2000
           set pending_jobs 10
           set job_times "2 15 30"
           set scan_time "10"
           set FLUSH_SUBMIT_SEC -1 
           set FLUSH_FINISH_SEC -1
           set schedule_interval "00:00:45"
           return 0  
          }
    "101"  { 
           set nr_queues 50     ;# on each host 
           set max_jobs 2000
           set pending_jobs 10
           set job_times "2 15 30"
           set scan_time "10"
           set FLUSH_SUBMIT_SEC 0
           set FLUSH_FINISH_SEC 0
           set schedule_interval "00:00:45"
           return 0  
          }
     "102" { 
           set nr_queues 50     ;# on each host 
           set max_jobs 2000
           set pending_jobs 10
           set job_times "2 15 30"
           set scan_time "10"
           set FLUSH_SUBMIT_SEC 10
           set FLUSH_FINISH_SEC 10 
           set schedule_interval "00:00:45"
           return 0  
          }
  }

  return -1
}

#                                                             max. column:     |
#****** performance/setup_queues() ******
# 
#  NAME
#     setup_queues -- ??? 
#
#  SYNOPSIS
#     setup_queues { } 
#
#  FUNCTION
#     ??? 
#
#  INPUTS
#
#  RESULT
#     ??? 
#
#  EXAMPLE
#     ??? 
#
#  NOTES
#     ??? 
#
#  BUGS
#     ??? 
#
#  SEE ALSO
#     ???/???
#*******************************
proc scheduler_perf_setup_queues {} {
   global CHECK_CORE_EXECD save_queue_values
   global nr_queues CHECK_CORE_MASTER
   global queue_list
   global host_list
   global stored_configuration schedule_interval
   global FLUSH_FINISH_SEC FLUSH_SUBMIT_SEC

  
   if {[llength $CHECK_CORE_EXECD] < 2 } {
      set_error -3 "need 2 execd hosts"
      return
   } 

   if { [info exists stored_configuration] } {
      unset stored_configuration
   }
   get_config stored_configuration

   set myconfig(loglevel)         "log_warning"
   set myconfig(load_report_time) "0:0:60"
   if { $FLUSH_SUBMIT_SEC == -1 && $FLUSH_FINISH_SEC == -1 } {
      set myconfig(schedd_params)    $stored_configuration(schedd_params)
   } else {
      set myconfig(schedd_params)    "$stored_configuration(schedd_params),FLUSH_SUBMIT_SEC=${FLUSH_SUBMIT_SEC},FLUSH_FINISH_SEC=${FLUSH_FINISH_SEC}"
   }
   set_config myconfig

   set my_schedd_config(schedule_interval)    "$schedule_interval"
   set my_schedd_config(job_load_adjustments) "none"
   set my_schedd_config(schedd_job_info)      "false"
   set_schedd_config my_schedd_config
  
   set queue_list ""
   set host_list ""
   set save_queue_values ""
   foreach elem $CHECK_CORE_EXECD {
      disable_queue $elem.q
      if { [string compare $elem $CHECK_CORE_MASTER] == 0 } { 
         continue;
      }
      lappend host_list $elem

      set change_array(slots) "0" 
      get_queue "$elem.q" "change_array"
      lappend save_queue_values [set change_array(slots)]
      unset change_array
      set change_array(slots) "1" 
      set_queue "$elem.q" "change_array"

      for {set i 0} { $i < $nr_queues } { incr i 1 } {
         set change_array(qname) "${elem}_m${i}"
         set change_array(hostname) "$elem"
         set change_array(slots) "1"
         set change_array(load_thresholds) "np_load_avg=3.75"
         
         add_queue change_array fast 
         lappend queue_list "${elem}_m${i}"
      }
   }
  
 
   set_error 0 "no errors"
}

#                                                             max. column:     |
#****** performance/cleanup_queues() ******
# 
#  NAME
#     cleanup_queues -- ??? 
#
#  SYNOPSIS
#     cleanup_queues { } 
#
#  FUNCTION
#     ??? 
#
#  INPUTS
#
#  RESULT
#     ??? 
#
#  EXAMPLE
#     ??? 
#
#  NOTES
#     ??? 
#
#  BUGS
#     ??? 
#
#  SEE ALSO
#     ???/???
#*******************************
proc scheduler_perf_cleanup_queues {} {
   global CHECK_CORE_EXECD save_queue_values
   global nr_queues CHECK_CORE_MASTER
   global host_list
   global stored_configuration

   if {[llength $CHECK_CORE_EXECD] < 2 } {
      set_error -3 "need 2 execd hosts"
      return
   } 

   set change_array(slots) "1"
   set i 0
   foreach elem $CHECK_CORE_EXECD {
      enable_queue $elem.q
      if { [string compare $elem $CHECK_CORE_MASTER] == 0 } { 
         continue;
      }

      set change_array(slots) [lindex $save_queue_values $i] 
      set_queue "$elem.q" "change_array"
      incr i 1
      for {set a 0} { $a < $nr_queues } { incr a 1 } {
         del_queue "${elem}_m${a}"
      }
   }
   reset_schedd_config
   set_config stored_configuration

   set_error 0 "no errors"
}

proc scheduler_perf_add_submit_results {} {
   global submit_results host_list CHECK_PROTOCOL_DIR

   foreach elem $host_list {
      set file_p [open "$CHECK_PROTOCOL_DIR/$elem.submit.log" "r" ]
      while { [gets $file_p line] >= 0 } {
         append submit_results "$line\n"
      }
      close $file_p
   }
}

#
#                                                             max. column:     |
#
#****** check/scheduler_perf_make_analysis() ******
#  NAME
#     scheduler_perf_make_analysis() -- ??? 
#
#  SYNOPSIS
#     scheduler_perf_make_analysis { } 
#
#  FUNCTION
#     ??? 
#
#  INPUTS
#
#  RESULT
#     ??? 
#
#  EXAMPLE
#     ??? 
#
#  NOTES
#     ??? 
#
#  BUGS
#     ??? 
#
#  SEE ALSO
#     ???/???
#*******************************
#
proc scheduler_perf_make_analysis {} {
   global start_time pending_time end_time
   global CHECK_PROTOCOL_DIR host_list submit_results 
   global schedule_results pending_jobs max_jobs job_times
   global CHECK_PRODUCT_ROOT CHECK_ARCH nr_queues
   global CHECK_CORE_EXECD

   if {[llength $CHECK_CORE_EXECD] < 2 } {
      set_error -3 "need 2 execd hosts"
      return
   } 


   set global_results ""
   append global_results "|Submit start time|$start_time|\n"
   append global_results "|Time queues enabled|$pending_time|\n"
   append global_results "|End of Test|$end_time|\n"
   append global_results "|Pending Jobs|$pending_jobs|\n"
   append global_results "|Max Jobs|$max_jobs|\n"
   append global_results "|Job times|$job_times|\n"
   set count 0
   set add 0
   foreach elem $job_times {
      incr count 1
      incr add $elem
   }  
   catch { set average [ expr ( $add / $count ) ] }
   append global_results "|average job time|$average|\n"
   append global_results "|Nr. of Queues on each host|$nr_queues|\n"
   append global_results "|Nr. of Submit hosts|[llength $host_list]|\n"
 
   set result ""
   catch { eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf -sconf" } result
   set help [split $result "\n"]
   foreach elem $help {
      append global_results "|qconf -sconf:|$elem|\n"
   }
   set result ""
   catch { eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qconf -ssconf" } result
   set help [split $result "\n"]
   foreach elem $help {
      append global_results "|qconf -ssconf:|$elem|\n"
   }



   set file_p [ open "$CHECK_PROTOCOL_DIR/schedule.txt" "a" ]
   puts $file_p $global_results
   puts $file_p "|Date&Time|Second|Time|Nr. Slots|Jobs Done|Running Jobs|Pending Jobs|Jobs Submitted|Highest ID Running|Last ID"
   set help [ split $schedule_results "\n" ]
   
   foreach line $help {
      puts $file_p $line
   } 
   close $file_p

   set file_p [ open "$CHECK_PROTOCOL_DIR/submit.txt" "a" ]
   puts $file_p $global_results
   puts $file_p "|Date&Time|Time|Submit run time|Job ID|Hostname"
   set help [ split $submit_results "\n" ]
   foreach line $help {
      if { [ string first "S|" $line ] == 0 } {
         set data [ split $line "|" ]
         set date [lindex $data 1]
         set time [lindex $data 2]
         set hostname [lindex $data 3] 
      }

      if { [ string first "your job" $line ] >= 0 } {
         set job_id [lindex $line 2]
      }

      if { [ string first "E|" $line ] == 0 } {
         set data [ split $line "|" ]
         set date2 [lindex $data 1]
         set time2 [lindex $data 2]


         scan $time "%d:%d:%d" time_h time_m time_s
         set time_h [ expr ( $time_h * 3600 ) ]
         set time_m [ expr ( $time_m * 60 ) ]
         set seconds1 [ expr ( $time_h + $time_m + $time_s ) ] 

         scan $time2 "%d:%d:%d" time_h time_m time_s
         set time_h [ expr ( $time_h * 3600 ) ]
         set time_m [ expr ( $time_m * 60 ) ]
         set seconds2 [ expr ( $time_h + $time_m + $time_s )  ]  

         set submit_run_time [ expr ( $seconds2 - $seconds1 )]
         puts $file_p "|$date $time|$time|$submit_run_time|$job_id|$hostname"
      }
   } 
   close $file_p
 

   set_error 0 "ok"
}

proc scheduler_perf_do_perform_test {} {
   global max_jobs CHECK_CORE_EXECD CHECK_PRODUCT_ROOT
   global pending_jobs CHECK_ARCH
   global CHECK_OUTPUT CHECK_PROTOCOL_DIR
   global queue_list
   global host_list nr_queues scan_time
   global start_time pending_time end_time schedule_results




   if {[llength $CHECK_CORE_EXECD] < 2 } {
      set_error -3 "need 2 execd hosts"
      return
   } 

   set submit_results ""
   set schedule_results ""
 

   set current_job_id [ submit_job "-e /dev/null -o /dev/null $CHECK_PRODUCT_ROOT/examples/jobs/sleeper.sh 10" ]
   wait_for_end_of_all_jobs 300 
   
   puts $CHECK_OUTPUT "current job id is $current_job_id"
   puts $CHECK_OUTPUT "disable all queues ..."  
   disable_queue $queue_list


   set start_time [eval exec "date +20%y-%m-%d_%H:%M:%S"]

   puts $CHECK_OUTPUT "now submitting $pending_jobs jobs ..."
   scheduler_perf_submit_jobs $current_job_id $pending_jobs $host_list   
   
 
   set last_job_id [ expr ( $current_job_id + $pending_jobs ) ] 
   puts $CHECK_OUTPUT "now waiting for job $last_job_id to get in pending state ..."
   
   set exit_code 1
   while { $exit_code != 0 } {
      puts $CHECK_OUTPUT "waiting for job $last_job_id ..." 
      set exit_code [catch { eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qstat -j $last_job_id" } result]
      sleep $scan_time

      set jobs_submitted 0
      foreach host $host_list {
         set catch_return [catch { eval exec "tail -1 $CHECK_PROTOCOL_DIR/$host.submitted" } jobs_sub]
         if { $catch_return == 0 } {
            incr jobs_submitted $jobs_sub
         } else {
            puts $CHECK_OUTPUT "submitted jobs file not found"
         }
      }
      if { $jobs_submitted > $pending_jobs } {
         set pending_jobs $jobs_submitted
         set last_job_id [ expr ( $current_job_id + $pending_jobs ) ] 
         set exit_code 1
      }
   }

   


   set pending_time [eval exec "date +20%y-%m-%d_%H:%M:%S"] 
   scheduler_perf_add_submit_results

 
   set jobs_2 [ expr ($max_jobs - $pending_jobs) ]
   puts $CHECK_OUTPUT "now submitting $jobs_2 jobs ..."
   scheduler_perf_submit_jobs $last_job_id $jobs_2 $host_list   


   puts $CHECK_OUTPUT "enable all queues ..."  
   enable_queue $queue_list

   

   set last_job_id [ expr ( $last_job_id + $jobs_2 ) ] 
   puts $CHECK_OUTPUT "last job id is $last_job_id"

   set exit_code 1
   set highest_run_job $current_job_id
   set nr_slots [llength $host_list]
   set nr_slots [ expr ( $nr_slots * $nr_queues ) ]
   puts $CHECK_OUTPUT "waiting for job $last_job_id ..." 
   set start_time_stamp [timestamp]
   while { $exit_code != 0 } {
      set exit_code [catch { eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qacct -j $last_job_id" } result]
      sleep $scan_time
      set time_now [ eval exec "date +%H:%M:%S" ]
      set date_now [ eval exec "date +%m/%d/20%y" ]
      set nr_running_jobs 0
      set qstat_return [catch { eval exec "$CHECK_PRODUCT_ROOT/bin/$CHECK_ARCH/qstat -s r" } result]
      
      if { $qstat_return == 0 } {
         if { [ string compare $result "" ] == 0 } {
            set nr_running_jobs 0
         }
         # split each line as listelement
         set help [split $result "\n"]
         #remove first two lines
         set help [lreplace $help 0 1]
         set nr_running_jobs [llength $help]
         foreach job $help {
            set job_id [ lindex $job 0 ]
            if { $highest_run_job < $job_id } {
               set highest_run_job $job_id
            } 
         }
      }
      if { $highest_run_job > $last_job_id } {
         set last_job_id $highest_run_job
         set exit_code 1
      }    
      set jobs_submitted $pending_jobs
      foreach host $host_list {
         catch { eval exec "tail -1 $CHECK_PROTOCOL_DIR/$host.submitted" } jobs_sub
         incr jobs_submitted $jobs_sub
      }
  
      set jobs_done [ expr ( $highest_run_job - $current_job_id - $nr_running_jobs  ) ] 
      set now_pending_jobs [ expr ( $jobs_submitted - $jobs_done - $nr_running_jobs )  ]

      set now_stamp [timestamp]
      set run_time_sec [ expr ( $now_stamp - $start_time_stamp) ]      

      puts $CHECK_OUTPUT "\|${date_now} ${time_now}\|${run_time_sec}\|${time_now}\|${nr_slots}\|${jobs_done}\|${nr_running_jobs}\|${now_pending_jobs}\|${jobs_submitted}\|${highest_run_job}\|${last_job_id}" 
      append schedule_results "\|${date_now} ${time_now}\|${run_time_sec}\|${time_now}\|${nr_slots}\|${jobs_done}\|${nr_running_jobs}\|${now_pending_jobs}\|${jobs_submitted}\|${highest_run_job}\|${last_job_id}\n" 

      set test_calc [ expr ( $jobs_done + $nr_running_jobs + $now_pending_jobs ) ]
#      puts $CHECK_OUTPUT "done_run_pend  = $test_calc"
#      puts $CHECK_OUTPUT "jobs_submitted = $jobs_submitted"
      if { $test_calc != $jobs_submitted } {
         add_proc_error "scheduler_perf_do_perform_test" "-1" "done_run_pend cont != jobs submitted count"
      }
   }
   wait_for_end_of_all_jobs 0
   set end_time [eval exec "date +20%y-%m-%d_%H:%M:%S"]
   
   was_job_running $last_job_id
   scheduler_perf_add_submit_results
   set_error 0 "ok"
}


proc scheduler_perf_submit_jobs { cur_job_id jobs hosts } {
   global CHECK_PROTOCOL_DIR CHECK_OUTPUT CHECK_USER
   global CHECK_TESTSUITE_ROOT CHECK_SCRIPT_FILE_DIR
   global CHECK_PRODUCT_ROOT job_times
   
    set max_job [ expr ( $cur_job_id + $jobs ) ]

    foreach elem $hosts {
       puts $CHECK_OUTPUT "starting submit until job id $max_job accurs on host $elem ..."
       set command "$CHECK_TESTSUITE_ROOT/$CHECK_SCRIPT_FILE_DIR/remote_submit_log.sh"
       set args "\"$CHECK_PRODUCT_ROOT\" \"$max_job\" \"$CHECK_PROTOCOL_DIR\" \"$job_times\""
       puts $CHECK_OUTPUT [start_remote_prog $elem $CHECK_USER $command $args prg_exit_state 300 1]
    }

}
