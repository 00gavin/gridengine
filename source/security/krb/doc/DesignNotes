
Here are the results of my trip to GENIAS on February 8-13.

The February 8-13 trip to GENIAS proved to very valuable.  Working
closely with Andre Alefeld of GENIAS, we were able to meet and exceed
all of the goals that I had established for the trip (see below).  Andre had
prepared by studying Kerberos in order to have a good understanding of
the problem that we are trying to solve.  GENIAS also provided access to
other engineers when their various areas of expertise were required.

Here were my goals for the trip:

1. Become familiar with the CODINE source code most likely to be affected by
the kerberization of GRD.

2. Identify any potential problem areas for kerberizing GRD.  This would
include identifying potential performance problems, identifying code which
could be difficult to kerberize, and determining the best method of introducing
kerberos calls into the code (#ifdefs, stub libraries, licensing - the short
term answer is likely different than the long term one).

3. Get a better idea of the scope of the GRD kerberization effort.  This would
also include an estimate of what Ken and I can reasonably expect to accomplish
in the near term.


One of the most important accomplishments of the trip was getting
familiar with some of the security work which had already taken place
at GENIAS. A graduate student had implemented some security features
into the CODINE product. Many of the difficult problems of kerberizing
GRD, such as where in the code to place the appropriate security calls,
were addressed in this implementation.  Although the security
enhancements done by the graduate student were not Kerberos-based,
there were enough similarities in the protocol and the design was such
that this proved to be a very good starting place for kerberizing GRD.
It became clear that the existence of this work was very significant,
because of the complexity and problems involved in kerberizing GRD.
Thankfully, these problems were encountered by the graduate student and
it appears from our review of his design and code that they were
successfully solved with the aid and support of the other GENIAS
engineers and developers.


1.0 Problems with Kerberizing GRD

Once you have a good understanding of the basics of Kerberos and how the
API library works, it appears from the sample client/server code that it
would be very easy to kerberize an application. This is not really the
case. The sample code deals with an extremely simplistic client/server
application. It is very easy to kerberize a simple client/server
application. Unfortunately, most existing client/server applications
aren't simple. Many of the problems with kerberizing an application
are not addressed in this simple example code.  For instance, a real
server will likely have multiple clients which must be tracked
individually.  This involves keeping some internal data structures on a
per-client basis which may or may not exist in the application.

Another difficult problem is that in an existing "real-life" server
application the communications protocol is likely implemented in a
separate layer than the application code.  This insulates the
application code from having to deal with the specifics of the
communication layer. This presents some real difficulties in implementing
security, because the security protocol needs information from both
levels.

Another significant problem with kerberizing GRD deals with tracking
clients.  In a typical client/server application using stream based
sockets to pass messages between the client and the server, the server
would initially authenticate the client either before or as part of the
first message sent from the client to the server.  All communications
(i.e. messages) between the client and the server would then be
encrypted using the secret session key known only to the client and the
server.  The server associates messages with the clients based on the
socket the message is read from.  If a message comes across the socket,
the server uses the secret key associated with the client to decrypt
the message.  If the socket goes down, this indicates that
communications between the client and the server have been disrupted
and the server can clean up any data structures that the client had.
The design of CODINE/GRD introduces a different communication model.
Instead of maintaining a socket per client, GRD servers and clients
communicate through a set of services that are part of a communication
library. The client and server actually communicate through one or more
communication daemons which dynamically manage socket connections. This
insulates the application from the details of socket management and
handles various problems associated with server communications such as
buffering data and running out of file descriptors.  It also makes it
difficult to know if a client is up or down or reachable at a given
time since there is no socket directly associated with the client.

One possible solution for handling the connectionless nature of CODINE/GRD
communications was to authenticate each individual message passed between the
client and the server. However, upon further investigation, this proved to be an
inadequate solution. One reason for this is that a simple transaction
consisting of a client sending a request to the server and getting back
the response generates two messages.  One from the client to the server
and one from the server back to the client.  It makes sense for the
server to authenticate the client, but the client should not have to
explicitly authenticate the server.

Even a simple transaction has an implied state. A request is sent from
the client, the server performs some service on behalf of the client,
and a response is sent back to the client.  Because the response is
tied to the request, there exists an implied state. The server must, at
minimum, authenticate the request, decrypt it, and encrypt the response
back to the client sufficiently that only the client can read the
response. This means that the server must at least maintain the state
of the client internally for the length of the transaction. An
outgrowth of the design for handling this case is that the server can
actually handle additional messages from the client without having to
reauthenticate each message.  Instead, each message after the first is
decrypted using the secret client/server session key.

2.0 GRD Kerberization Level of Effort Scope

There are at two levels of effort in Kerberizing GRD.  The first level
of effort is the authentication of GRD clients and servers.  It turns
out that the authentication of GRD clients and the authentication
between the GRD servers are both actually accomplished with the same
design and code.  The basic design for this first level of effort was
completed by Shannon Davidson and Andre Alefeld as part of the February
8-13 trip to GENIAS.  The second level of effort in kerberizing GRD is
the acquisition of Kerberos tickets on behalf of the client's job on
the execution host.  This involves issues such as acquiring
ticket-granting-tickets on behalf of a client, handling/preventing
ticket expirations, storing tickets for future use, and forwarding
tickets to the execution host.  There are also a number of design and
performance related issues associated with the second level of
kerberizing GRD.  Some of these issues were identified during the
February 8-13 trip, but the actual design work has not yet been
completed.

2.1 GRD Kerberization - First Level of Effort

First Level Kerberization is handled by replacing the generic
send_message and receive_message routines in the commd library with
kerberized versions.  The kerberized versions of the routines will
maintain the state of the connection and take care of the
authentication of clients, as well as encrypting and decrypting
messages passed between clients and servers.  Handling authentication
at this level means that any code using the standard commd library will
automatically have authentication.  These routines will ensure that a
user is who he says he is.  Higher level routines are responsible for
determining if that user is actually an authorized user of GRD. These
routines will behave differently when acting on behalf of a client or
server. In this model, the qmaster acts as the server, and all other
CODINE/GRD daemons and client programs act as clients. When acting as a
server, these routines will maintain a connection list which tracks the
clients. When a client first connects to a server, the client will be
authenticated.  If authentication fails, a failure message will be sent
back to the client indicating the failure.  If the client is not a
CODINE/GRD daemon the failure message will be displayed on the screen.
If the client is successfully authenticated, a connection entry will be
created and added to the connection list.  The connection entry
contains enough information to uniquely identify the client based on
information received in the receive_message routine.  All later
messages received from or sent to this client will be encrypted.  If
the connection is idle for a period of time (i.e. no messages sent or
received on the connection), the connection entry will be removed from
the connection list.  A specific routine will  be written which will
check for connections which have "timed-out" and "clean them up".  This
routine will be called from the send_message and/or receive_message
routines and may also be called separately from within a chk_to_do
routine in a CODINE/GRD daemon.

2.1.1 GRD Kerberization Level One Design

sec_krb_init

	call krb5_init
	if we are a codine daemon
		setup connection lists
		set internal is_codine_deamon flag
	endif
	set connection ID to 0

	if (is_codine_deamon)
		get TGT from keytab file
	endif

	if (!qmaster)
		go get ticket for the qmaster/codine service
	endif


sec_krb_send_message

	if (!qmaster && !connected)
		build an AP_REQ authentication packet AP_REQ
		(krb5_mk_req)
		
	endif
	
	if (qmaster)
		lookup auth_context using commd triple
	else
		use the local auth_context
	endif
	
	if (!qmaster)
		put connection ID in the buffer
	endif
	
	call krb5_mk_priv to encrypt message
	
	call send_message to send [ AP_REQ + ] message
	
sec_krb_receive_message

	call recv_message to receive message
	
	if (*tag == TAG_AUTHENTICATE)
	
		if (qmaster)
		
			call krb5_rd_req to authenticate client
	
			if authentication fails
			
				send TAG_AUTHENTICATE message back to
					the client
				return

			endif

		else (is_a_daemon)
		
			set reconnect flag
			return
		
		else /* its a normal client */
		
			print TAG_AUTHENTICATE message to stderr
			set reconnect flag
			return
				
		endif		
		
		if (qmaster)
		
			get connection ID
			look up connection ID in connection list
			get auth_context from connetion list
		else
			get connection ID from msg
			compare connection ID to connection ID in msg
			set auth_context to local auth_context
		endif
		
		decrypt message
		
		if decryption fails
			send TAG_AUTHENTICATE message back to client
			return
		endif
		
		return message


2.1.2 Data Structures

	connection list
		list of connection entry for each client
	
	connection entry
		connection ID
		commd host triple <host, commproc, ID>
		auth_context
	
	global client/server data
		is_codine_deamon flag
		auth_context (client)

2.1.3 Design Notes

	Q. Is there a unique ID in the auth_context or available from the
	KDC which could be used as the connection ID?  It would need to
	be unique for every client and also unique for each
	instantiation of a client.  If there is no unique ID that we
	can get from the KDC, then we may need to use a transaction
	when authenticating the client in order to get back a
	connection ID from the server.

	A.
	
	Q. Do we need to maintain an auth_context for each client?
	
	A. It appears that we need to maintain an auth_context for each
	client for the life of the connection in the connection entry.
	The Kerberos libaries maintain certain information such as the
	sequence number, etc. in this data structure.

	Q. Why is there a connection ID?
	
	A. The connection ID is used to uniquely identify a client
	connection by the server.  Since the CODINE communication
	mechanism is basically connectionless there is nothing like a
	socket to uniquely identify a client.  A client can be
	identified using the commd triple which consists of the host,
	process name, and ID, but this would not be unique for cycled
	processes.  The connection ID can either be assigned by the KDC
	(if possible - see the first question) or assigned by the server
	itself during the initial authentication process.  Assignment
	by the server guarrantees uniqueness of all clients regardless

	Q. Is there any way to avoid maintaining a connection list in
	the qmaster?

	A. It doesn't appear so.  The connection list is needed so that
	the server will know how to encrypt any messages going back
	from the server to the client.  The only way to make this
	association from with the sec_krb_send_message routine is to
	map the parameters on the send_msg routine to a client in the
	connection list and then use the auth_context from the
	connection entry to encrypt the message.

	Q. What happens when the qmaster is cycled?

	A. The connection list is not spooled to disk, so when the
	qmaster is cycled, all clients must reauthenticate. If the
	qmaster receives a message from an unauthenticated client, the
	message will be thrown away and an error message will be sent
	back to the client.  (Would it make sense to return the
	original offending message back to the client where it could be
	retried?) This reauthentication could be handled in one of two
	ways. The first method is that is a message ever fails then the
	client must reauthenticate using an authentication
	transaction.  The response of the authentication request would
	contain the connection ID assigned by the server to the
	client.  Another possibility would be to include the
	reauthentication information information (AP_REQ) in every
	message sent from the client to the server. If the client was
	already authenticated in the server this portion of the message
	would be ignored by the server. If the client was not already
	authenticated by the server, he would be reauthenticated by the
	server.  This would also handle cases where messages destined
	for the qmaster are spooled in the commd while the qmaster is
	down.  Since each message would include authentication info,
	the messages would not have to be thrown away when the qmaster
	comes back up.

	Q. What happens when other CODINE/GRD deamons are cycled?

	A. When a CODINE/GRD daemon other than the qmaster is cycled
	and comes back up, it will initially attempt to contact the
	qmaster.  Any initial message sent to the qmaster will include
	the authentication info (AP_REQ).  Any messages queued in the
	commd will be lost because they will have been encrypted with
	an old session key.  (Is this a problem?)

	Q. What happens when a client is cycled?

	A. Same as CODINE/GRD daemon.

	Q. Can the other CODINE/GRD deamons serve as server?  This may
	be needed for the plans that GENIAS has for enhanced parallel
	job support.
	
	A. We will look into this further during implementation.  If
	possible, we will construct the code such that any CODINE/GRD
	daemon can act as a client if a message is received with the
	authentication information (AP_REQ) attached.

	Q. If a client receives a message that it cannot decrypt what
	should it do?
	
	A. If the client is a CODINE/GRD the message should be thrown
	away and an error message logged.  If the client is a general
	purpose client acting on behalf of a user, an error message
	should be displayed to the user.

	Q. How do we make sure that the user doesn't authenticate
	himself to the security routines and then simply indicate that
	he is someone else to the higher level routines?

	A. The higher level routines (i.e. those which call
	receive_message) need to call some security routine to verify
	that the user is who he says he is.  This is necessary because
	the higher level routines currently just check the user ID
	which is passed in the message.  This is not adequate since a
	knowledgeable user could pass through the lower level security
	routines as himself while putting a zero user ID into the
	message and passing himself off as root in the higher level
	routines.  There needs to be a test in the higher level
	routines to verify that the user authenticated himself as the
	same user that he indicated he was in the higher level
	message.  This would need to be done in the code which is
	calling the receive_message routine.  A routine needs to be
	written which verifies that the client is a particular user.
	The routine could be called sec_krb_verify_client_user and
	would be passed the user ID (or user name) and the commd triple
	<host, commproc, id>.  The routine would look up the user in
	the connection list, compare to the passed user ID, and return
	true or false.

2.2 GRD Kerberization - Second Level of Effort

Second level GRD kerberization will affect a number of different pieces
of code.  It will probably involve changes in the job submittal client
modules (qsub, qmon4), the queue master (cod_qmaster), the execution
daemon (cod_execd), and possibly the job shepherd process
(cod_shepherd).  It will also mean changes to, at a minimum, the job
structure and the message data structures used to pass job information
between the various modules.

A job submitted to GRD needs to have a TGT on the execution host.  This
is necessary because certain applications that the job may need to
access (such as PVM) will need valid Kerberos tickets in order to work. 
A valid TGT should be provided, since we don't know which services will
be needed by the job.  A valid TGT on the execution host for the user of
the job will allow processes running under the job to get tickets for
whatever services the job requires. 

A number of steps are involved in order to get a valid TGT on the
execution host of the job.  In general, a TGT is valid on a particular
host or set of hosts. (It is possible to get a TGT that is valid on any
host in the Kerberos domain, but this is not recommended.) First, the
qsub or qmon4 client program gets a forwardable TGT for the host where
the qmaster is executing.  This TGT is passed along with the job
request to the qmaster.  The qmaster stores this TGT in the job entry.
After the decision to run the job on a particular host is made, the
qmaster uses the TGT in the job entry to acquire a TGT which is valid
on the execution host and then passes that TGT to the execution daemon
along with the job request.  The cod_execd or the cod_shepherd then
stores that TGT in the user's credentials cache and starts the job.
The job then has access to a valid TGT on the execution host.

A potential performance problem of getting a TGT on the execution host
of the job occurs when the cod_qmaster has to get a TGT which is valid
on the execution host.  This is a problem because the cod_qmaster must
contact the KDC and wait for a response before it can send the job to
the execution host.  If this transaction is executed synchronously, the
qmaster will be blocked for a period of time (maybe 100 ms average) for
each job.  This should certainly be avoided if possible.  One option
would be to use an asynchronous request, but this has the disadvantage
of significantly complicating the code due to handling the asynchronous
request and having an additional job state (i.e. WAITING_FOR_TGT) for
each outstanding job.  We would also have to investigate if this is
even possible using the Kerberos API C library.  A more attractive
solution to this performance problem is to get a TGT in the client
(qsub or qmon4) which is valid for any host but to prevent this TGT
from being written to the user's credentials cache (Hopefully, not
making this TGT available in the user's credential cache would address
any security concerns of a wildcard TGT).  Then the wild-card TGT could
be passed to the qmaster who would store it in the job entry and pass
it to the execution host when the job executes.  The cod_execd or
cod_shepherd could use this wildcard TGT to get a specific TGT valid on
the execution host and then destroy the original wild-card TGT.

2.2.1 GRD Kerberization Level Two Design

2.2.2 Data Structures

2.2.3 Design Notes

	Q. How do we prevent a job's tickets from expiring while the
	job is queued?

	A. If this is a requirement, then the qmaster (or some other
	external process such as the scheduler) will need to
	occasionally go through all of the job entries and look for
	TGTs which are about to expire and contact the KDC to request a
	new TGT for that job.  Of course, contacting the KDC will
	impose some overhead and care should be taken that this does
	not cause performance problems.  GRD should
	also continue to keep the TGT in the qmaster valid for as
	long as the job is executing, just in case we have to restart
	the job at a later time.  It might also make sense that when
	the shepherd gets a TGT for the job that it gets a TGT which is
	valid for a reasonably long period of time.

	Q. How can we prevent a job's tickets from expiring while the job
	is executing?
	
	A. The cod_shepherd could continually renew the TGT of the
	client on a regular basis.  The cod_shepherd could do this
	directly or spawn a separate process to do it.  When the TGT is
	renewed the new TGT would be placed in the user's credential
	cache making it available to processes executing as part of the
	user's job. (Thanks to Fritz for this suggestion.)
